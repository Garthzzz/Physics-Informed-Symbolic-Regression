{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataGen - Physics-SR Framework v4.1 Benchmark\n",
    "\n",
    "## Benchmark Data Generation Module\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (AI Feynman Benchmark Integration)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This notebook generates synthetic test datasets for benchmarking the Physics-SR Framework v4.1.\n",
    "\n",
    "**Test Equations (AI Feynman Benchmark):**\n",
    "\n",
    "| # | Name | AI Feynman ID | Equation | Type | Tests |\n",
    "|---|------|---------------|----------|------|-------|\n",
    "| 1 | Coulomb | I.12.2 | $F = k \\cdot q_1 \\cdot q_2 / r^2$ | Rational | Inverse-square law |\n",
    "| 2 | Cosines | I.29.16 | $x = \\sqrt{x_1^2 + x_2^2 - 2x_1 x_2 \\cos(\\theta_1 - \\theta_2)}$ | Nested Trig | Structure parsing |\n",
    "| 3 | Barometric | I.40.1 | $n = n_0 \\exp(-mgx/k_B T)$ | Exponential | High-dim discovery |\n",
    "| 4 | DotProduct | I.11.19 | $A = x_1 y_1 + x_2 y_2 + x_3 y_3$ | Polynomial | Interaction discovery |\n",
    "\n",
    "**Generated Configurations:**\n",
    "- Sample sizes: 250, 500, 750 (core: 500 only)\n",
    "- Noise levels: 0%, 5%\n",
    "- Dummy features: 0, 5\n",
    "\n",
    "### Output\n",
    "\n",
    "Datasets saved to `data/` directory as `.npz` files.\n",
    "\n",
    "### Changelog from v3.0\n",
    "\n",
    "- Replaced Newton, IdealGas, Damped equations with AI Feynman benchmark equations\n",
    "- Added `ai_feynman_id` attribute to all equation classes\n",
    "- Updated data types to Float32 for memory optimization\n",
    "- Enhanced metadata storage for v4.1 pipeline compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ENVIRONMENT RESET AND FRESH CLONE\n",
    "# ==============================================================================\n",
    "# This cell only resets when necessary (not when already in valid repo)\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    import shutil\n",
    "    import gc\n",
    "    \n",
    "    repo_path = '/content/Physics-Informed-Symbolic-Regression'\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Only reset if NOT already inside a valid repo\n",
    "    if not current_dir.startswith(repo_path) or not os.path.exists(repo_path + '/.git'):\n",
    "        os.chdir('/content')\n",
    "        gc.collect()\n",
    "        \n",
    "        if os.path.exists(repo_path):\n",
    "            shutil.rmtree(repo_path)\n",
    "            print(\"[OK] Removed existing repository.\")\n",
    "        \n",
    "        !git clone https://github.com/Garthzzz/Physics-Informed-Symbolic-Regression.git\n",
    "        \n",
    "        if os.path.exists(repo_path + '/.git'):\n",
    "            os.chdir(repo_path + '/benchmark')\n",
    "            print(f\"[OK] Working directory: {os.getcwd()}\")\n",
    "        else:\n",
    "            print(\"[FAIL] Clone incomplete!\")\n",
    "        \n",
    "        print(\"[OK] Environment reset complete.\")\n",
    "    else:\n",
    "        print(\"[SKIP] Already in valid repository.\")\n",
    "else:\n",
    "    print(\"[INFO] Not in Colab environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DataGen.ipynb - Benchmark Data Generation\n",
    "==========================================\n",
    "\n",
    "Physics-SR Framework v4.1 Benchmark Suite\n",
    "\n",
    "This module provides:\n",
    "- BaseTestEquation: Abstract base class for test equations\n",
    "- CoulombEquation: Electrostatic force (AI Feynman I.12.2)\n",
    "- LawOfCosinesEquation: Wave interference (AI Feynman I.29.16)\n",
    "- BarometricEquation: Atmospheric pressure (AI Feynman I.40.1)\n",
    "- DotProductEquation: Vector dot product (AI Feynman I.11.19)\n",
    "- BenchmarkDataGenerator: Data generation and management\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "Version: 4.1\n",
    "\"\"\"\n",
    "\n",
    "print(\"DataGen: Initializing benchmark data generation module...\")\n",
    "print(\"Version: 4.1 (AI Feynman Benchmark)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORTS\n",
    "# ==============================================================================\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"DataGen: All imports successful.\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURATION CONSTANTS\n",
    "# ==============================================================================\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Data generation parameters\n",
    "DEFAULT_N_SAMPLES = 500\n",
    "SAMPLE_SIZES = [250, 500, 750]\n",
    "NOISE_LEVELS = [0.0, 0.05]\n",
    "DUMMY_COUNTS = [0, 5]\n",
    "\n",
    "# Output directory - environment aware\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colab: running from repo root\n",
    "    DATA_DIR = Path('/content/Physics-Informed-Symbolic-Regression/benchmark/data')\n",
    "else:\n",
    "    # Local: running from benchmark directory\n",
    "    DATA_DIR = Path('data')\n",
    "\n",
    "# Numerical stability thresholds\n",
    "Y_MIN_THRESHOLD = 1e-6\n",
    "Y_MAX_THRESHOLD = 1e8\n",
    "EPS = 1e-10\n",
    "\n",
    "# AI Feynman standard variable range\n",
    "AI_FEYNMAN_RANGE = (1.0, 5.0)\n",
    "\n",
    "print(\"Configuration constants defined.\")\n",
    "print(f\"  Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "print(f\"  Sample sizes: {SAMPLE_SIZES}\")\n",
    "print(f\"  Noise levels: {NOISE_LEVELS}\")\n",
    "print(f\"  Dummy counts: {DUMMY_COUNTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# USERINPUTS DATACLASS\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class UserInputs:\n",
    "    \"\"\"\n",
    "    User-defined inputs required for the Physics-SR Framework.\n",
    "    \n",
    "    This dataclass encapsulates all physics-informed prior knowledge\n",
    "    that users provide to guide the symbolic regression process.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    variable_dimensions : Dict[str, List[float]]\n",
    "        Dictionary mapping variable names to dimensional exponents [M, L, T, Theta].\n",
    "        M = Mass, L = Length, T = Time, Theta = Temperature.\n",
    "    target_dimensions : List[float]\n",
    "        Dimensional exponents [M, L, T, Theta] for the target variable.\n",
    "    physical_bounds : Dict[str, Dict[str, Optional[float]]]\n",
    "        Physical constraints: {var_name: {'min': float, 'max': float}}\n",
    "    variable_mapping : Optional[Dict[str, str]]\n",
    "        Maps column names to physical variable names.\n",
    "    unit_conversions : Optional[Dict[str, float]]\n",
    "        Conversion factors to SI units.\n",
    "    \"\"\"\n",
    "    \n",
    "    variable_dimensions: Dict[str, List[float]]\n",
    "    target_dimensions: List[float]\n",
    "    physical_bounds: Dict[str, Dict[str, Optional[float]]]\n",
    "    variable_mapping: Optional[Dict[str, str]] = None\n",
    "    unit_conversions: Optional[Dict[str, float]] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate inputs after initialization.\"\"\"\n",
    "        for var_name, dims in self.variable_dimensions.items():\n",
    "            if len(dims) != 4:\n",
    "                raise ValueError(\n",
    "                    f\"Variable '{var_name}' has {len(dims)} dimensional exponents, \"\n",
    "                    f\"expected 4 [M, L, T, Theta]\"\n",
    "                )\n",
    "        if len(self.target_dimensions) != 4:\n",
    "            raise ValueError(\n",
    "                f\"Target dimensions has {len(self.target_dimensions)} exponents, \"\n",
    "                f\"expected 4 [M, L, T, Theta]\"\n",
    "            )\n",
    "    \n",
    "    def get_variable_names(self) -> List[str]:\n",
    "        \"\"\"Return list of variable names.\"\"\"\n",
    "        return list(self.variable_dimensions.keys())\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"Convert to dictionary for serialization.\"\"\"\n",
    "        return {\n",
    "            'variable_dimensions': self.variable_dimensions,\n",
    "            'target_dimensions': self.target_dimensions,\n",
    "            'physical_bounds': self.physical_bounds,\n",
    "            'variable_mapping': self.variable_mapping,\n",
    "            'unit_conversions': self.unit_conversions\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, d: Dict) -> 'UserInputs':\n",
    "        \"\"\"Create from dictionary.\"\"\"\n",
    "        return cls(\n",
    "            variable_dimensions=d['variable_dimensions'],\n",
    "            target_dimensions=d['target_dimensions'],\n",
    "            physical_bounds=d['physical_bounds'],\n",
    "            variable_mapping=d.get('variable_mapping'),\n",
    "            unit_conversions=d.get('unit_conversions')\n",
    "        )\n",
    "\n",
    "print(\"UserInputs dataclass defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Base Test Equation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BASE TEST EQUATION CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class BaseTestEquation(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for AI Feynman benchmark test equations.\n",
    "    \n",
    "    All test equations must implement the methods defined here.\n",
    "    This provides a consistent interface for data generation.\n",
    "    \n",
    "    Class Attributes\n",
    "    ----------------\n",
    "    name : str\n",
    "        Short identifier (e.g., 'coulomb')\n",
    "    full_name : str\n",
    "        Full descriptive name (e.g., \"Coulomb's Law\")\n",
    "    equation_str : str\n",
    "        Human-readable equation string\n",
    "    equation_type : str\n",
    "        Type classification ('rational', 'nested_trigonometric', etc.)\n",
    "    ai_feynman_id : str\n",
    "        AI Feynman benchmark ID (e.g., 'I.12.2')\n",
    "    true_feature_names : List[str]\n",
    "        Features that appear in the true equation\n",
    "    dummy_feature_pool : List[str]\n",
    "        Available dummy (irrelevant) features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class attributes to be defined by subclasses\n",
    "    name: str = \"base\"\n",
    "    full_name: str = \"Base Equation\"\n",
    "    equation_str: str = \"y = f(x)\"\n",
    "    equation_type: str = \"abstract\"\n",
    "    ai_feynman_id: str = \"N/A\"\n",
    "    \n",
    "    true_feature_names: List[str] = []\n",
    "    dummy_feature_pool: List[str] = []\n",
    "    \n",
    "    # Internal storage\n",
    "    _dimensions: Dict[str, List[float]] = {}\n",
    "    _target_dims: List[float] = [0, 0, 0, 0]\n",
    "    _ranges: Dict[str, Tuple[float, float]] = {}\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_true_features(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        seed: int\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate values for true features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of samples to generate\n",
    "        seed : int\n",
    "            Random seed for reproducibility\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, np.ndarray]\n",
    "            Dictionary mapping feature names to value arrays\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def generate_dummy_features(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        n_dummy: int, \n",
    "        seed: int\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate values for dummy (irrelevant) features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of samples\n",
    "        n_dummy : int\n",
    "            Number of dummy features to generate\n",
    "        seed : int\n",
    "            Random seed (offset by 1000 from true features)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, np.ndarray]\n",
    "            Dictionary mapping dummy feature names to value arrays\n",
    "        \"\"\"\n",
    "        if n_dummy <= 0:\n",
    "            return {}\n",
    "        \n",
    "        np.random.seed(seed + 1000)\n",
    "        selected = self.dummy_feature_pool[:min(n_dummy, len(self.dummy_feature_pool))]\n",
    "        return {\n",
    "            name: np.random.uniform(*self._ranges[name], n_samples)\n",
    "            for name in selected\n",
    "        }\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_target(\n",
    "        self, \n",
    "        features: Dict[str, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute target variable from true features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features : Dict[str, np.ndarray]\n",
    "            Dictionary of feature arrays\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Target variable values\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def add_noise(\n",
    "        self, \n",
    "        y: np.ndarray, \n",
    "        noise_level: float, \n",
    "        seed: int,\n",
    "        noise_type: str = 'multiplicative'\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Add noise to target variable.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.ndarray\n",
    "            Clean target values\n",
    "        noise_level : float\n",
    "            Noise standard deviation (relative for multiplicative)\n",
    "        seed : int\n",
    "            Random seed (offset by 2000)\n",
    "        noise_type : str\n",
    "            'multiplicative' (log-normal) or 'additive' (Gaussian)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Noisy target values\n",
    "        \"\"\"\n",
    "        if noise_level <= 0:\n",
    "            return y.copy()\n",
    "        \n",
    "        np.random.seed(seed + 2000)\n",
    "        \n",
    "        if noise_type == 'multiplicative':\n",
    "            # Log-normal noise (appropriate for positive targets)\n",
    "            noise = np.exp(np.random.normal(0, noise_level, len(y)))\n",
    "            return y * noise\n",
    "        else:\n",
    "            # Additive Gaussian noise (relative to target std)\n",
    "            noise = np.random.normal(0, noise_level * np.std(y), len(y))\n",
    "            return y + noise\n",
    "    \n",
    "    def get_variable_dimensions(\n",
    "        self, \n",
    "        feature_names: List[str]\n",
    "    ) -> Dict[str, List[float]]:\n",
    "        \"\"\"Return dimensional exponents [M, L, T, Theta] for given features.\"\"\"\n",
    "        return {name: self._dimensions.get(name, [0, 0, 0, 0]) \n",
    "                for name in feature_names}\n",
    "    \n",
    "    def get_target_dimensions(self) -> List[float]:\n",
    "        \"\"\"Return dimensional exponents [M, L, T, Theta] for target.\"\"\"\n",
    "        return self._target_dims.copy()\n",
    "    \n",
    "    def get_physical_bounds(self) -> Dict[str, Dict[str, Optional[float]]]:\n",
    "        \"\"\"Return physical bounds for all variables.\"\"\"\n",
    "        bounds = {'target': {'min': None, 'max': None}}\n",
    "        for name, (low, high) in self._ranges.items():\n",
    "            bounds[name] = {'min': low * 0.1, 'max': high * 10}\n",
    "        return bounds\n",
    "    \n",
    "    def create_user_inputs(self, feature_names: List[str]) -> UserInputs:\n",
    "        \"\"\"Create UserInputs object for this equation.\"\"\"\n",
    "        return UserInputs(\n",
    "            variable_dimensions=self.get_variable_dimensions(feature_names),\n",
    "            target_dimensions=self.get_target_dimensions(),\n",
    "            physical_bounds=self.get_physical_bounds()\n",
    "        )\n",
    "    \n",
    "    def get_ground_truth(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return ground truth information for evaluation.\"\"\"\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'full_name': self.full_name,\n",
    "            'equation': self.equation_str,\n",
    "            'active_features': self.true_feature_names.copy(),\n",
    "            'equation_type': self.equation_type,\n",
    "            'ai_feynman_id': self.ai_feynman_id\n",
    "        }\n",
    "    \n",
    "    def generate_dataset(\n",
    "        self,\n",
    "        n_samples: int,\n",
    "        noise_level: float,\n",
    "        n_dummy: int,\n",
    "        seed: int\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate complete dataset with all metadata.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of samples\n",
    "        noise_level : float\n",
    "            Noise level (0.0 to 0.1)\n",
    "        n_dummy : int\n",
    "            Number of dummy features\n",
    "        seed : int\n",
    "            Random seed\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Complete dataset dictionary for .npz storage\n",
    "        \"\"\"\n",
    "        # Generate features\n",
    "        true_features = self.generate_true_features(n_samples, seed)\n",
    "        dummy_features = self.generate_dummy_features(n_samples, n_dummy, seed)\n",
    "        \n",
    "        all_features = {**true_features, **dummy_features}\n",
    "        \n",
    "        true_names = list(true_features.keys())\n",
    "        dummy_names = list(dummy_features.keys())\n",
    "        feature_names = true_names + dummy_names\n",
    "        \n",
    "        # Assemble feature matrix\n",
    "        X = np.column_stack([all_features[name] for name in feature_names])\n",
    "        \n",
    "        # Compute target\n",
    "        y_true = self.compute_target(true_features)\n",
    "        y = self.add_noise(y_true, noise_level, seed)\n",
    "        \n",
    "        # Create UserInputs for dimensional analysis\n",
    "        user_inputs = self.create_user_inputs(feature_names)\n",
    "        ground_truth = self.get_ground_truth()\n",
    "        \n",
    "        return {\n",
    "            # Data arrays (Float32 for v4.1 memory optimization)\n",
    "            'X': X.astype(np.float32),\n",
    "            'y': y.astype(np.float32),\n",
    "            'y_true': y_true.astype(np.float32),\n",
    "            \n",
    "            # Feature metadata\n",
    "            'feature_names': np.array(feature_names),\n",
    "            'true_features': np.array(true_names),\n",
    "            'dummy_features': np.array(dummy_names),\n",
    "            \n",
    "            # Equation metadata\n",
    "            'equation_name': self.name,\n",
    "            'equation_str': self.equation_str,\n",
    "            'equation_type': self.equation_type,\n",
    "            'ai_feynman_id': self.ai_feynman_id,\n",
    "            \n",
    "            # Experiment parameters\n",
    "            'n_samples': n_samples,\n",
    "            'noise_level': noise_level,\n",
    "            'n_dummy': n_dummy,\n",
    "            'seed': seed,\n",
    "            \n",
    "            # Dimensional information (for UserInputs)\n",
    "            'variable_dimensions': user_inputs.variable_dimensions,\n",
    "            'target_dimensions': np.array(user_inputs.target_dimensions),\n",
    "            'physical_bounds': user_inputs.physical_bounds,\n",
    "            \n",
    "            # Ground truth for evaluation\n",
    "            'ground_truth': ground_truth\n",
    "        }\n",
    "\n",
    "print(\"BaseTestEquation class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: AI Feynman Test Equation Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EQUATION 1: COULOMB'S LAW OF ELECTROSTATIC FORCE (AI FEYNMAN I.12.2)\n",
    "# ==============================================================================\n",
    "\n",
    "class CoulombEquation(BaseTestEquation):\n",
    "    \"\"\"\n",
    "    Coulomb's Law of Electrostatic Force (AI Feynman I.12.2).\n",
    "    \n",
    "    Reference:\n",
    "        Coulomb, C. A., 1785: Premier memoire sur l'electricite et le magnetisme.\n",
    "        Feynman Lectures on Physics, Vol. II, Chapter 4.\n",
    "        AI Feynman Benchmark I.12.2\n",
    "    \n",
    "    Equation:\n",
    "        F = k * q1 * q2 / r^2\n",
    "    \n",
    "    Variables:\n",
    "        q1, q2: Electric charges (C)\n",
    "        r: Distance between charges (m)\n",
    "        F: Electrostatic force (N)\n",
    "        k: Coulomb constant = 8.99e9 N*m^2/C^2\n",
    "    \n",
    "    Tests:\n",
    "        - Inverse-square law detection\n",
    "        - Rational function discovery\n",
    "        - Dimensional analysis (distinct dimensions)\n",
    "    \n",
    "    Expected y range: [0.01, 1000] N (numerically stable)\n",
    "    \"\"\"\n",
    "    \n",
    "    name = \"coulomb\"\n",
    "    full_name = \"Coulomb's Law of Electrostatic Force\"\n",
    "    equation_str = \"F = k * q1 * q2 / r^2\"\n",
    "    equation_type = \"rational\"\n",
    "    ai_feynman_id = \"I.12.2\"\n",
    "    \n",
    "    true_feature_names = ['q1', 'q2', 'r']\n",
    "    dummy_feature_pool = ['v1', 'v2', 'T', 'm', 'epsilon']\n",
    "    \n",
    "    # Coulomb constant\n",
    "    K = 8.99e9  # N*m^2/C^2\n",
    "    \n",
    "    # Dimensional exponents [M, L, T, Theta]\n",
    "    # Using standard SI: Coulomb = A*s, approximated as [0, 0, 1, 0]\n",
    "    _dimensions = {\n",
    "        'q1':      [0, 0, 1, 0],     # Charge (A*s approximation)\n",
    "        'q2':      [0, 0, 1, 0],\n",
    "        'r':       [0, 1, 0, 0],     # Length\n",
    "        'v1':      [0, 1, -1, 0],    # Velocity\n",
    "        'v2':      [0, 1, -1, 0],\n",
    "        'T':       [0, 0, 0, 1],     # Temperature\n",
    "        'm':       [1, 0, 0, 0],     # Mass\n",
    "        'epsilon': [0, 0, 0, 0],     # Dimensionless\n",
    "    }\n",
    "    \n",
    "    _target_dims = [1, 1, -2, 0]  # Force: N = kg*m/s^2\n",
    "    \n",
    "    # Ranges designed for numerical stability: y in [0.01, 1000] N\n",
    "    _ranges = {\n",
    "        'q1':      (1e-6, 1e-4),      # 1 - 100 microCoulombs\n",
    "        'q2':      (1e-6, 1e-4),\n",
    "        'r':       (0.1, 10.0),       # 0.1 - 10 meters\n",
    "        'v1':      (0.0, 100.0),\n",
    "        'v2':      (0.0, 100.0),\n",
    "        'T':       (200.0, 400.0),\n",
    "        'm':       (0.01, 10.0),\n",
    "        'epsilon': (1.0, 10.0),\n",
    "    }\n",
    "    \n",
    "    def generate_true_features(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        seed: int\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Generate electric charges and distance.\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        return {\n",
    "            'q1': np.random.uniform(*self._ranges['q1'], n_samples),\n",
    "            'q2': np.random.uniform(*self._ranges['q2'], n_samples),\n",
    "            'r':  np.random.uniform(*self._ranges['r'], n_samples),\n",
    "        }\n",
    "    \n",
    "    def compute_target(\n",
    "        self, \n",
    "        features: Dict[str, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Compute electrostatic force using Coulomb's law.\"\"\"\n",
    "        q1 = features['q1']\n",
    "        q2 = features['q2']\n",
    "        r = features['r']\n",
    "        return self.K * q1 * q2 / (r ** 2)\n",
    "    \n",
    "    def get_physical_bounds(self) -> Dict[str, Dict[str, Optional[float]]]:\n",
    "        \"\"\"Return physical bounds for all variables.\"\"\"\n",
    "        bounds = {'target': {'min': 0.0, 'max': None}}\n",
    "        for name, (low, high) in self._ranges.items():\n",
    "            bounds[name] = {'min': 0.0, 'max': high * 10}\n",
    "        return bounds\n",
    "\n",
    "print(\"CoulombEquation class defined (AI Feynman I.12.2).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EQUATION 2: LAW OF COSINES / WAVE INTERFERENCE (AI FEYNMAN I.29.16)\n",
    "# ==============================================================================\n",
    "\n",
    "class LawOfCosinesEquation(BaseTestEquation):\n",
    "    \"\"\"\n",
    "    Law of Cosines / Wave Interference (AI Feynman I.29.16).\n",
    "    \n",
    "    Reference:\n",
    "        Feynman Lectures on Physics, Vol. I, Chapter 29.\n",
    "        AI Feynman Benchmark I.29.16\n",
    "    \n",
    "    Equation:\n",
    "        x = sqrt(x1^2 + x2^2 - 2*x1*x2*cos(theta1 - theta2))\n",
    "    \n",
    "    Tests:\n",
    "        - Trigonometric operator detection (cos)\n",
    "        - Square root detection (sqrt)\n",
    "        - Angle difference pattern (translational symmetry)\n",
    "        - Nested function structure\n",
    "        - v4.0 Structure-Guided Library benefit\n",
    "    \n",
    "    Variables:\n",
    "        x1, x2: Amplitudes (length)\n",
    "        theta1, theta2: Phase angles (dimensionless)\n",
    "        x: Resultant amplitude (length)\n",
    "    \"\"\"\n",
    "    \n",
    "    name = \"cosines\"\n",
    "    full_name = \"Law of Cosines (Wave Interference)\"\n",
    "    equation_str = \"x = sqrt(x1^2 + x2^2 - 2*x1*x2*cos(theta1 - theta2))\"\n",
    "    equation_type = \"nested_trigonometric\"\n",
    "    ai_feynman_id = \"I.29.16\"\n",
    "    \n",
    "    true_feature_names = ['x1', 'x2', 'theta1', 'theta2']\n",
    "    dummy_feature_pool = ['omega', 't', 'k', 'A', 'phi']\n",
    "    \n",
    "    _dimensions = {\n",
    "        'x1':     [0, 1, 0, 0],     # Amplitude (length)\n",
    "        'x2':     [0, 1, 0, 0],\n",
    "        'theta1': [0, 0, 0, 0],     # Angle (dimensionless)\n",
    "        'theta2': [0, 0, 0, 0],\n",
    "        'omega':  [0, 0, -1, 0],    # Angular frequency\n",
    "        't':      [0, 0, 1, 0],     # Time\n",
    "        'k':      [0, -1, 0, 0],    # Wave number\n",
    "        'A':      [0, 1, 0, 0],     # Reference amplitude\n",
    "        'phi':    [0, 0, 0, 0],     # Phase angle\n",
    "    }\n",
    "    \n",
    "    _target_dims = [0, 1, 0, 0]  # Resultant amplitude (length)\n",
    "    \n",
    "    # Following AI Feynman standard: all variables in [1, 5]\n",
    "    _ranges = {\n",
    "        'x1':     (1.0, 5.0),\n",
    "        'x2':     (1.0, 5.0),\n",
    "        'theta1': (0.0, 2 * np.pi),  # Full range for angles\n",
    "        'theta2': (0.0, 2 * np.pi),\n",
    "        'omega':  (0.1, 10.0),\n",
    "        't':      (0.0, 10.0),\n",
    "        'k':      (0.1, 5.0),\n",
    "        'A':      (0.5, 5.0),\n",
    "        'phi':    (0.0, np.pi),\n",
    "    }\n",
    "    \n",
    "    def generate_true_features(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        seed: int\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Generate amplitudes and phase angles.\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        return {\n",
    "            'x1':     np.random.uniform(*self._ranges['x1'], n_samples),\n",
    "            'x2':     np.random.uniform(*self._ranges['x2'], n_samples),\n",
    "            'theta1': np.random.uniform(*self._ranges['theta1'], n_samples),\n",
    "            'theta2': np.random.uniform(*self._ranges['theta2'], n_samples),\n",
    "        }\n",
    "    \n",
    "    def compute_target(\n",
    "        self, \n",
    "        features: Dict[str, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Compute resultant amplitude using law of cosines.\"\"\"\n",
    "        x1 = features['x1']\n",
    "        x2 = features['x2']\n",
    "        theta1 = features['theta1']\n",
    "        theta2 = features['theta2']\n",
    "        \n",
    "        # Law of cosines: c^2 = a^2 + b^2 - 2ab*cos(C)\n",
    "        arg = x1**2 + x2**2 - 2 * x1 * x2 * np.cos(theta1 - theta2)\n",
    "        \n",
    "        # Ensure non-negative before sqrt (numerical safety)\n",
    "        arg = np.maximum(arg, EPS)\n",
    "        \n",
    "        return np.sqrt(arg)\n",
    "    \n",
    "    def get_physical_bounds(self) -> Dict[str, Dict[str, Optional[float]]]:\n",
    "        \"\"\"Return physical bounds for all variables.\"\"\"\n",
    "        bounds = {'target': {'min': 0.0, 'max': None}}\n",
    "        for name, (low, high) in self._ranges.items():\n",
    "            if 'theta' in name or name == 'phi':\n",
    "                bounds[name] = {'min': 0.0, 'max': 2 * np.pi}\n",
    "            else:\n",
    "                bounds[name] = {'min': 0.0, 'max': high * 10}\n",
    "        return bounds\n",
    "\n",
    "print(\"LawOfCosinesEquation class defined (AI Feynman I.29.16).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EQUATION 3: BAROMETRIC FORMULA (AI FEYNMAN I.40.1)\n",
    "# ==============================================================================\n",
    "\n",
    "class BarometricEquation(BaseTestEquation):\n",
    "    \"\"\"\n",
    "    Barometric Formula (AI Feynman I.40.1).\n",
    "    \n",
    "    Reference:\n",
    "        Feynman Lectures on Physics, Vol. I, Chapter 40.\n",
    "        AI Feynman Benchmark I.40.1\n",
    "    \n",
    "    Equation:\n",
    "        n = n0 * exp(-m * g * x / (k_b * T))\n",
    "    \n",
    "    Tests:\n",
    "        - Exponential operator detection (exp)\n",
    "        - Multi-variable quotient inside exp\n",
    "        - High-dimensional discovery (6 true variables)\n",
    "        - Dimensional analysis benefit (many variables)\n",
    "    \n",
    "    Note: Eureqa failed to solve this equation in the AI Feynman study.\n",
    "    \n",
    "    Variables:\n",
    "        n0: Reference number density (dimensionless in normalized form)\n",
    "        m: Particle mass\n",
    "        g: Gravitational acceleration\n",
    "        x: Height\n",
    "        k_b: Boltzmann constant\n",
    "        T: Temperature\n",
    "        n: Number density\n",
    "    \"\"\"\n",
    "    \n",
    "    name = \"barometric\"\n",
    "    full_name = \"Barometric Formula (Isothermal Atmosphere)\"\n",
    "    equation_str = \"n = n0 * exp(-m * g * x / (k_b * T))\"\n",
    "    equation_type = \"exponential\"\n",
    "    ai_feynman_id = \"I.40.1\"\n",
    "    \n",
    "    true_feature_names = ['n0', 'm', 'g', 'x', 'k_b', 'T']\n",
    "    dummy_feature_pool = ['rho', 'P', 'V', 'R', 'mu']\n",
    "    \n",
    "    _dimensions = {\n",
    "        # True features (using normalized/dimensionless in AI Feynman style)\n",
    "        'n0':  [0, 0, 0, 0],     # Reference density (normalized)\n",
    "        'm':   [0, 0, 0, 0],     # Particle mass (normalized)\n",
    "        'g':   [0, 0, 0, 0],     # Gravitational accel (normalized)\n",
    "        'x':   [0, 0, 0, 0],     # Height (normalized)\n",
    "        'k_b': [0, 0, 0, 0],     # Boltzmann constant (normalized)\n",
    "        'T':   [0, 0, 0, 0],     # Temperature (normalized)\n",
    "        # Dummy features\n",
    "        'rho': [1, -3, 0, 0],    # Density\n",
    "        'P':   [1, -1, -2, 0],   # Pressure\n",
    "        'V':   [0, 3, 0, 0],     # Volume\n",
    "        'R':   [0, 0, 0, 0],     # Gas constant (normalized)\n",
    "        'mu':  [1, -1, -1, 0],   # Viscosity\n",
    "    }\n",
    "    \n",
    "    _target_dims = [0, 0, 0, 0]  # Number density (normalized/dimensionless)\n",
    "    \n",
    "    # AI Feynman standard: all variables in [1, 5]\n",
    "    _ranges = {\n",
    "        'n0':  (1.0, 5.0),\n",
    "        'm':   (1.0, 5.0),\n",
    "        'g':   (1.0, 5.0),\n",
    "        'x':   (1.0, 5.0),\n",
    "        'k_b': (1.0, 5.0),\n",
    "        'T':   (1.0, 5.0),\n",
    "        'rho': (0.5, 5.0),\n",
    "        'P':   (1.0, 10.0),\n",
    "        'V':   (0.5, 5.0),\n",
    "        'R':   (1.0, 5.0),\n",
    "        'mu':  (0.1, 2.0),\n",
    "    }\n",
    "    \n",
    "    def generate_true_features(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        seed: int\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Generate all 6 true features.\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        return {\n",
    "            'n0':  np.random.uniform(*self._ranges['n0'], n_samples),\n",
    "            'm':   np.random.uniform(*self._ranges['m'], n_samples),\n",
    "            'g':   np.random.uniform(*self._ranges['g'], n_samples),\n",
    "            'x':   np.random.uniform(*self._ranges['x'], n_samples),\n",
    "            'k_b': np.random.uniform(*self._ranges['k_b'], n_samples),\n",
    "            'T':   np.random.uniform(*self._ranges['T'], n_samples),\n",
    "        }\n",
    "    \n",
    "    def compute_target(\n",
    "        self, \n",
    "        features: Dict[str, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Compute number density using barometric formula.\"\"\"\n",
    "        n0 = features['n0']\n",
    "        m = features['m']\n",
    "        g = features['g']\n",
    "        x = features['x']\n",
    "        k_b = features['k_b']\n",
    "        T = features['T']\n",
    "        \n",
    "        # n = n0 * exp(-m * g * x / (k_b * T))\n",
    "        exponent = -m * g * x / (k_b * T)\n",
    "        \n",
    "        # Clip exponent to prevent overflow/underflow\n",
    "        exponent = np.clip(exponent, -20, 20)\n",
    "        \n",
    "        return n0 * np.exp(exponent)\n",
    "    \n",
    "    def get_physical_bounds(self) -> Dict[str, Dict[str, Optional[float]]]:\n",
    "        \"\"\"Return physical bounds for all variables.\"\"\"\n",
    "        bounds = {'target': {'min': 0.0, 'max': None}}\n",
    "        for name, (low, high) in self._ranges.items():\n",
    "            bounds[name] = {'min': 0.0, 'max': high * 10}\n",
    "        return bounds\n",
    "\n",
    "print(\"BarometricEquation class defined (AI Feynman I.40.1).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EQUATION 4: DOT PRODUCT OF TWO 3D VECTORS (AI FEYNMAN I.11.19)\n",
    "# ==============================================================================\n",
    "\n",
    "class DotProductEquation(BaseTestEquation):\n",
    "    \"\"\"\n",
    "    Dot Product of Two 3D Vectors (AI Feynman I.11.19).\n",
    "    \n",
    "    Reference:\n",
    "        Feynman Lectures on Physics, Vol. I, Chapter 11.\n",
    "        AI Feynman Benchmark I.11.19\n",
    "    \n",
    "    Equation:\n",
    "        A = x1*y1 + x2*y2 + x3*y3\n",
    "    \n",
    "    Tests:\n",
    "        - Variable interaction discovery (iRF Stage 1.4)\n",
    "        - Correct pairing identification\n",
    "        - 15 possible pairwise interactions, only 3 correct\n",
    "        - Pure polynomial form\n",
    "    \n",
    "    Variables:\n",
    "        x1, x2, x3: Components of vector x (length)\n",
    "        y1, y2, y3: Components of vector y (length)\n",
    "        A: Dot product result (length^2)\n",
    "    \"\"\"\n",
    "    \n",
    "    name = \"dotproduct\"\n",
    "    full_name = \"Dot Product (3D Vector)\"\n",
    "    equation_str = \"A = x1*y1 + x2*y2 + x3*y3\"\n",
    "    equation_type = \"polynomial_interaction\"\n",
    "    ai_feynman_id = \"I.11.19\"\n",
    "    \n",
    "    true_feature_names = ['x1', 'x2', 'x3', 'y1', 'y2', 'y3']\n",
    "    dummy_feature_pool = ['z1', 'z2', 'z3', 'w1', 'w2']\n",
    "    \n",
    "    _dimensions = {\n",
    "        # All components have same dimension (length)\n",
    "        'x1': [0, 1, 0, 0],\n",
    "        'x2': [0, 1, 0, 0],\n",
    "        'x3': [0, 1, 0, 0],\n",
    "        'y1': [0, 1, 0, 0],\n",
    "        'y2': [0, 1, 0, 0],\n",
    "        'y3': [0, 1, 0, 0],\n",
    "        'z1': [0, 1, 0, 0],\n",
    "        'z2': [0, 1, 0, 0],\n",
    "        'z3': [0, 1, 0, 0],\n",
    "        'w1': [0, 1, 0, 0],\n",
    "        'w2': [0, 1, 0, 0],\n",
    "    }\n",
    "    \n",
    "    _target_dims = [0, 2, 0, 0]  # Dot product: length^2\n",
    "    \n",
    "    # AI Feynman standard: all variables in [1, 5]\n",
    "    _ranges = {\n",
    "        'x1': (1.0, 5.0),\n",
    "        'x2': (1.0, 5.0),\n",
    "        'x3': (1.0, 5.0),\n",
    "        'y1': (1.0, 5.0),\n",
    "        'y2': (1.0, 5.0),\n",
    "        'y3': (1.0, 5.0),\n",
    "        'z1': (1.0, 5.0),\n",
    "        'z2': (1.0, 5.0),\n",
    "        'z3': (1.0, 5.0),\n",
    "        'w1': (1.0, 5.0),\n",
    "        'w2': (1.0, 5.0),\n",
    "    }\n",
    "    \n",
    "    def generate_true_features(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        seed: int\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Generate all 6 vector components.\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        return {\n",
    "            'x1': np.random.uniform(*self._ranges['x1'], n_samples),\n",
    "            'x2': np.random.uniform(*self._ranges['x2'], n_samples),\n",
    "            'x3': np.random.uniform(*self._ranges['x3'], n_samples),\n",
    "            'y1': np.random.uniform(*self._ranges['y1'], n_samples),\n",
    "            'y2': np.random.uniform(*self._ranges['y2'], n_samples),\n",
    "            'y3': np.random.uniform(*self._ranges['y3'], n_samples),\n",
    "        }\n",
    "    \n",
    "    def compute_target(\n",
    "        self, \n",
    "        features: Dict[str, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Compute dot product.\"\"\"\n",
    "        x1, x2, x3 = features['x1'], features['x2'], features['x3']\n",
    "        y1, y2, y3 = features['y1'], features['y2'], features['y3']\n",
    "        \n",
    "        return x1 * y1 + x2 * y2 + x3 * y3\n",
    "    \n",
    "    def get_physical_bounds(self) -> Dict[str, Dict[str, Optional[float]]]:\n",
    "        \"\"\"Return physical bounds for all variables.\"\"\"\n",
    "        bounds = {'target': {'min': 0.0, 'max': None}}\n",
    "        for name, (low, high) in self._ranges.items():\n",
    "            bounds[name] = {'min': 0.0, 'max': high * 10}\n",
    "        return bounds\n",
    "\n",
    "print(\"DotProductEquation class defined (AI Feynman I.11.19).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EQUATION REGISTRY\n",
    "# ==============================================================================\n",
    "\n",
    "EQUATION_REGISTRY = {\n",
    "    'coulomb': CoulombEquation,\n",
    "    'cosines': LawOfCosinesEquation,\n",
    "    'barometric': BarometricEquation,\n",
    "    'dotproduct': DotProductEquation,\n",
    "}\n",
    "\n",
    "# Ground truth reference dictionary\n",
    "GROUND_TRUTH_REGISTRY = {\n",
    "    'coulomb': {\n",
    "        'equation': 'F = k * q1 * q2 / r**2',\n",
    "        'active_features': ['q1', 'q2', 'r'],\n",
    "        'type': 'rational',\n",
    "        'ai_feynman_id': 'I.12.2',\n",
    "    },\n",
    "    'cosines': {\n",
    "        'equation': 'x = sqrt(x1**2 + x2**2 - 2*x1*x2*cos(theta1 - theta2))',\n",
    "        'active_features': ['x1', 'x2', 'theta1', 'theta2'],\n",
    "        'type': 'nested_trigonometric',\n",
    "        'ai_feynman_id': 'I.29.16',\n",
    "    },\n",
    "    'barometric': {\n",
    "        'equation': 'n = n0 * exp(-m*g*x/(k_b*T))',\n",
    "        'active_features': ['n0', 'm', 'g', 'x', 'k_b', 'T'],\n",
    "        'type': 'exponential',\n",
    "        'ai_feynman_id': 'I.40.1',\n",
    "    },\n",
    "    'dotproduct': {\n",
    "        'equation': 'A = x1*y1 + x2*y2 + x3*y3',\n",
    "        'active_features': ['x1', 'x2', 'x3', 'y1', 'y2', 'y3'],\n",
    "        'type': 'polynomial_interaction',\n",
    "        'ai_feynman_id': 'I.11.19',\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def get_equation(name: str) -> BaseTestEquation:\n",
    "    \"\"\"\n",
    "    Get equation instance by name.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Equation name (coulomb, cosines, barometric, dotproduct)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    BaseTestEquation\n",
    "        Equation instance\n",
    "    \"\"\"\n",
    "    if name not in EQUATION_REGISTRY:\n",
    "        raise ValueError(\n",
    "            f\"Unknown equation: {name}. \"\n",
    "            f\"Available: {list(EQUATION_REGISTRY.keys())}\"\n",
    "        )\n",
    "    return EQUATION_REGISTRY[name]()\n",
    "\n",
    "\n",
    "print(\"Equation registry defined.\")\n",
    "print(f\"Available equations: {list(EQUATION_REGISTRY.keys())}\")\n",
    "print()\n",
    "print(\"AI Feynman Benchmark IDs:\")\n",
    "for name, info in GROUND_TRUTH_REGISTRY.items():\n",
    "    print(f\"  {name}: {info['ai_feynman_id']} ({info['type']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EXPERIMENT CONFIGURATION FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def get_core_experiment_configs() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate configurations for core experiments.\n",
    "    \n",
    "    Core experiments: 4 equations x 2 noise x 2 dummy x 2 dims = 32 dataset configs\n",
    "    With 3 methods each = 96 total experiments\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict[str, Any]]\n",
    "        List of experiment configurations\n",
    "    \"\"\"\n",
    "    configs = []\n",
    "    equations = list(EQUATION_REGISTRY.keys())\n",
    "    \n",
    "    for eq_name in equations:\n",
    "        for noise in [0.0, 0.05]:\n",
    "            for n_dummy in [0, 5]:\n",
    "                for with_dims in [True, False]:\n",
    "                    configs.append({\n",
    "                        'equation_name': eq_name,\n",
    "                        'n_samples': 500,\n",
    "                        'noise_level': noise,\n",
    "                        'n_dummy': n_dummy,\n",
    "                        'with_dims': with_dims,\n",
    "                    })\n",
    "    \n",
    "    return configs\n",
    "\n",
    "\n",
    "def get_supplementary_experiment_configs() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate configurations for supplementary experiments.\n",
    "    \n",
    "    Supplementary experiments: 4 equations x 2 sample sizes = 8 configs\n",
    "    Physics-SR only, with noise and dummy features\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict[str, Any]]\n",
    "        List of experiment configurations\n",
    "    \"\"\"\n",
    "    configs = []\n",
    "    equations = list(EQUATION_REGISTRY.keys())\n",
    "    \n",
    "    for eq_name in equations:\n",
    "        for n_samples in [250, 750]:\n",
    "            configs.append({\n",
    "                'equation_name': eq_name,\n",
    "                'n_samples': n_samples,\n",
    "                'noise_level': 0.05,\n",
    "                'n_dummy': 5,\n",
    "                'with_dims': True,\n",
    "            })\n",
    "    \n",
    "    return configs\n",
    "\n",
    "\n",
    "print(\"Experiment configuration functions defined.\")\n",
    "print(f\"  Core configs: {len(get_core_experiment_configs())}\")\n",
    "print(f\"  Supplementary configs: {len(get_supplementary_experiment_configs())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Benchmark Data Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BENCHMARK DATA GENERATOR\n",
    "# ==============================================================================\n",
    "\n",
    "class BenchmarkDataGenerator:\n",
    "    \"\"\"\n",
    "    Generate and manage benchmark datasets for Physics-SR Framework v4.1.\n",
    "    \n",
    "    This class handles:\n",
    "    - Dataset generation from equation objects\n",
    "    - Saving/loading .npz files with pickled nested structures\n",
    "    - Generating all experiment configurations\n",
    "    - Dataset verification and statistics\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    output_dir : Path\n",
    "        Directory for saving generated datasets\n",
    "    equations : Dict[str, BaseTestEquation]\n",
    "        Registry of available equation instances\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: Union[str, Path] = \"data\"):\n",
    "        \"\"\"\n",
    "        Initialize the data generator.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        output_dir : Union[str, Path]\n",
    "            Directory for saving datasets\n",
    "        \"\"\"\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Instantiate all equation classes\n",
    "        self.equations = {\n",
    "            name: cls() for name, cls in EQUATION_REGISTRY.items()\n",
    "        }\n",
    "        \n",
    "        print(f\"BenchmarkDataGenerator initialized.\")\n",
    "        print(f\"  Output directory: {self.output_dir}\")\n",
    "        print(f\"  Available equations: {list(self.equations.keys())}\")\n",
    "    \n",
    "    def generate_filename(\n",
    "        self,\n",
    "        equation_name: str,\n",
    "        n_samples: int,\n",
    "        noise_level: float,\n",
    "        n_dummy: int\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate standardized filename for dataset.\n",
    "        \n",
    "        Format: eq{N}_{name}_n{samples}_noise{level}_dummy{count}.npz\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        equation_name : str\n",
    "            Name of the equation\n",
    "        n_samples : int\n",
    "            Number of samples\n",
    "        noise_level : float\n",
    "            Noise level (e.g., 0.05)\n",
    "        n_dummy : int\n",
    "            Number of dummy features\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Standardized filename\n",
    "        \"\"\"\n",
    "        eq_names = list(EQUATION_REGISTRY.keys())\n",
    "        eq_num = eq_names.index(equation_name) + 1\n",
    "        return f\"eq{eq_num}_{equation_name}_n{n_samples}_noise{noise_level:.2f}_dummy{n_dummy}.npz\"\n",
    "    \n",
    "    def generate_dataset(\n",
    "        self,\n",
    "        equation_name: str,\n",
    "        n_samples: int = DEFAULT_N_SAMPLES,\n",
    "        noise_level: float = 0.0,\n",
    "        n_dummy: int = 0,\n",
    "        seed: int = RANDOM_SEED\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate a single test dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        equation_name : str\n",
    "            Name of the equation ('coulomb', 'cosines', 'barometric', 'dotproduct')\n",
    "        n_samples : int\n",
    "            Number of samples to generate\n",
    "        noise_level : float\n",
    "            Noise level (0.0 to 0.1)\n",
    "        n_dummy : int\n",
    "            Number of dummy features to include\n",
    "        seed : int\n",
    "            Random seed for reproducibility\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Generated dataset with all metadata\n",
    "        \"\"\"\n",
    "        if equation_name not in self.equations:\n",
    "            raise ValueError(\n",
    "                f\"Unknown equation: {equation_name}. \"\n",
    "                f\"Available: {list(self.equations.keys())}\"\n",
    "            )\n",
    "        \n",
    "        equation = self.equations[equation_name]\n",
    "        data = equation.generate_dataset(n_samples, noise_level, n_dummy, seed)\n",
    "        \n",
    "        # Add additional metadata\n",
    "        eq_names = list(EQUATION_REGISTRY.keys())\n",
    "        data['equation_index'] = eq_names.index(equation_name) + 1\n",
    "        data['full_name'] = equation.full_name\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def save_dataset(\n",
    "        self,\n",
    "        data: Dict[str, Any],\n",
    "        filename: Optional[str] = None\n",
    "    ) -> Path:\n",
    "        \"\"\"\n",
    "        Save dataset to .npz file.\n",
    "        \n",
    "        Uses pickle serialization for complex nested dict structures\n",
    "        (variable_dimensions, physical_bounds, ground_truth).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Dict[str, Any]\n",
    "            Dataset dictionary to save\n",
    "        filename : Optional[str]\n",
    "            Output filename (auto-generated if None)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Path\n",
    "            Path to saved file\n",
    "        \"\"\"\n",
    "        if filename is None:\n",
    "            filename = self.generate_filename(\n",
    "                data['equation_name'],\n",
    "                data['n_samples'],\n",
    "                data['noise_level'],\n",
    "                data['n_dummy']\n",
    "            )\n",
    "        \n",
    "        filepath = self.output_dir / filename\n",
    "        \n",
    "        # Prepare data for saving\n",
    "        save_data = {}\n",
    "        for key, value in data.items():\n",
    "            if key in ['variable_dimensions', 'physical_bounds', 'ground_truth']:\n",
    "                # Use pickle for complex nested dict structures\n",
    "                save_data[key + '_pkl'] = np.frombuffer(\n",
    "                    pickle.dumps(value), dtype=np.uint8\n",
    "                )\n",
    "            elif isinstance(value, np.ndarray):\n",
    "                save_data[key] = value\n",
    "            elif isinstance(value, (list, tuple)):\n",
    "                save_data[key] = np.array(value)\n",
    "            else:\n",
    "                save_data[key] = value\n",
    "        \n",
    "        np.savez_compressed(filepath, **save_data)\n",
    "        return filepath\n",
    "    \n",
    "    def load_dataset(self, filename: Union[str, Path]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Load dataset from .npz file.\n",
    "        \n",
    "        Automatically unpickles nested dict structures.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : Union[str, Path]\n",
    "            Filename to load\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Loaded dataset\n",
    "        \"\"\"\n",
    "        filepath = self.output_dir / filename\n",
    "        \n",
    "        with np.load(filepath, allow_pickle=True) as npz:\n",
    "            data = {}\n",
    "            for key in npz.files:\n",
    "                if key.endswith('_pkl'):\n",
    "                    # Unpickle nested dict structures\n",
    "                    original_key = key[:-4]\n",
    "                    data[original_key] = pickle.loads(npz[key].tobytes())\n",
    "                else:\n",
    "                    value = npz[key]\n",
    "                    # Convert 0-d arrays to scalars\n",
    "                    if value.ndim == 0:\n",
    "                        data[key] = value.item()\n",
    "                    else:\n",
    "                        data[key] = value\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def generate_all_datasets(\n",
    "        self,\n",
    "        equations: Optional[List[str]] = None,\n",
    "        sample_sizes: Optional[List[int]] = None,\n",
    "        noise_levels: Optional[List[float]] = None,\n",
    "        dummy_counts: Optional[List[int]] = None,\n",
    "        seed: int = RANDOM_SEED,\n",
    "        verbose: bool = True\n",
    "    ) -> List[Path]:\n",
    "        \"\"\"\n",
    "        Generate all datasets for benchmark suite.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        equations : Optional[List[str]]\n",
    "            List of equation names (all if None)\n",
    "        sample_sizes : Optional[List[int]]\n",
    "            List of sample sizes (default [500])\n",
    "        noise_levels : Optional[List[float]]\n",
    "            List of noise levels (default [0.0, 0.05])\n",
    "        dummy_counts : Optional[List[int]]\n",
    "            List of dummy feature counts (default [0, 5])\n",
    "        seed : int\n",
    "            Random seed for reproducibility\n",
    "        verbose : bool\n",
    "            Print progress messages\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        List[Path]\n",
    "            List of paths to generated files\n",
    "        \"\"\"\n",
    "        if equations is None:\n",
    "            equations = list(EQUATION_REGISTRY.keys())\n",
    "        if sample_sizes is None:\n",
    "            sample_sizes = [500]\n",
    "        if noise_levels is None:\n",
    "            noise_levels = NOISE_LEVELS\n",
    "        if dummy_counts is None:\n",
    "            dummy_counts = DUMMY_COUNTS\n",
    "        \n",
    "        total = len(equations) * len(sample_sizes) * len(noise_levels) * len(dummy_counts)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Generating {total} datasets...\")\n",
    "            print(f\"  Equations: {equations}\")\n",
    "            print(f\"  Sample sizes: {sample_sizes}\")\n",
    "            print(f\"  Noise levels: {noise_levels}\")\n",
    "            print(f\"  Dummy counts: {dummy_counts}\")\n",
    "            print()\n",
    "        \n",
    "        generated_files = []\n",
    "        count = 0\n",
    "        \n",
    "        for eq_name in equations:\n",
    "            for n_samples in sample_sizes:\n",
    "                for noise in noise_levels:\n",
    "                    for n_dummy in dummy_counts:\n",
    "                        data = self.generate_dataset(\n",
    "                            equation_name=eq_name,\n",
    "                            n_samples=n_samples,\n",
    "                            noise_level=noise,\n",
    "                            n_dummy=n_dummy,\n",
    "                            seed=seed\n",
    "                        )\n",
    "                        \n",
    "                        # Validate y range\n",
    "                        self._validate_y_range(data['y'], eq_name)\n",
    "                        \n",
    "                        filepath = self.save_dataset(data)\n",
    "                        generated_files.append(filepath)\n",
    "                        \n",
    "                        count += 1\n",
    "                        if verbose:\n",
    "                            print(f\"  [{count}/{total}] Generated: {filepath.name}\")\n",
    "        \n",
    "        if verbose:\n",
    "            print()\n",
    "            print(f\"Generation complete. {len(generated_files)} files created.\")\n",
    "        \n",
    "        return generated_files\n",
    "    \n",
    "    def _validate_y_range(\n",
    "        self, \n",
    "        y: np.ndarray, \n",
    "        eq_name: str,\n",
    "        min_abs: float = Y_MIN_THRESHOLD,\n",
    "        max_abs: float = Y_MAX_THRESHOLD\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Validate that y values are in numerically stable range.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.ndarray\n",
    "            Target values\n",
    "        eq_name : str\n",
    "            Equation name for logging\n",
    "        min_abs : float\n",
    "            Minimum acceptable |y| value\n",
    "        max_abs : float\n",
    "            Maximum acceptable |y| value\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if y is in valid range\n",
    "        \"\"\"\n",
    "        y_nonzero = y[y != 0]\n",
    "        if len(y_nonzero) == 0:\n",
    "            print(f\"    [WARNING] {eq_name}: All y values are zero!\")\n",
    "            return False\n",
    "        \n",
    "        y_abs = np.abs(y_nonzero)\n",
    "        y_min, y_max = y_abs.min(), y_abs.max()\n",
    "        \n",
    "        if y_min < min_abs:\n",
    "            print(f\"    [WARNING] {eq_name}: y_min ({y_min:.2e}) < {min_abs:.0e}\")\n",
    "            return False\n",
    "        if y_max > max_abs:\n",
    "            print(f\"    [WARNING] {eq_name}: y_max ({y_max:.2e}) > {max_abs:.0e}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def verify_dataset(self, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Verify dataset integrity and compute statistics.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            Filename to verify\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Verification results\n",
    "        \"\"\"\n",
    "        data = self.load_dataset(filename)\n",
    "        \n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "        y_true = data['y_true']\n",
    "        \n",
    "        # Compute statistics\n",
    "        stats = {\n",
    "            'n_samples': X.shape[0],\n",
    "            'n_features': X.shape[1],\n",
    "            'n_true_features': len(data['true_features']),\n",
    "            'n_dummy_features': len(data['dummy_features']),\n",
    "            'y_min': float(np.min(y)),\n",
    "            'y_max': float(np.max(y)),\n",
    "            'y_mean': float(np.mean(y)),\n",
    "            'y_std': float(np.std(y)),\n",
    "            'y_has_nan': bool(np.any(np.isnan(y))),\n",
    "            'y_has_inf': bool(np.any(np.isinf(y))),\n",
    "            'noise_actual': float(np.std(y - y_true) / (np.std(y_true) + EPS)),\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def list_datasets(self) -> List[Path]:\n",
    "        \"\"\"List all datasets in output directory.\"\"\"\n",
    "        return sorted(self.output_dir.glob(\"*.npz\"))\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print summary of available datasets.\"\"\"\n",
    "        datasets = self.list_datasets()\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" DATASET SUMMARY\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Output directory: {self.output_dir}\")\n",
    "        print(f\"Total datasets: {len(datasets)}\")\n",
    "        print()\n",
    "        \n",
    "        if len(datasets) == 0:\n",
    "            print(\"No datasets found.\")\n",
    "            return\n",
    "        \n",
    "        by_equation = {}\n",
    "        for path in datasets:\n",
    "            parts = path.stem.split('_')\n",
    "            eq_name = parts[1]\n",
    "            if eq_name not in by_equation:\n",
    "                by_equation[eq_name] = []\n",
    "            by_equation[eq_name].append(path)\n",
    "        \n",
    "        for eq_name, paths in by_equation.items():\n",
    "            print(f\"  {eq_name}: {len(paths)} datasets\")\n",
    "\n",
    "print(\"BenchmarkDataGenerator class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Generate All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" GENERATING CORE EXPERIMENT DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "generator = BenchmarkDataGenerator(output_dir=DATA_DIR)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate core experiment datasets (n=500)\n",
    "core_files = generator.generate_all_datasets(\n",
    "    equations=None,  # All equations\n",
    "    sample_sizes=[500],\n",
    "    noise_levels=[0.0, 0.05],\n",
    "    dummy_counts=[0, 5],\n",
    "    seed=RANDOM_SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nCore datasets generated: {len(core_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" GENERATING SUPPLEMENTARY EXPERIMENT DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Generate supplementary datasets (n=250, 750)\n",
    "supp_files = generator.generate_all_datasets(\n",
    "    equations=None,  # All equations\n",
    "    sample_sizes=[250, 750],\n",
    "    noise_levels=[0.05],\n",
    "    dummy_counts=[5],\n",
    "    seed=RANDOM_SEED,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nSupplementary datasets generated: {len(supp_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" GENERATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_files = generator.list_datasets()\n",
    "total_size = sum(f.stat().st_size for f in all_files) / 1024 / 1024\n",
    "\n",
    "print(f\"\\nTotal datasets: {len(all_files)}\")\n",
    "print(f\"Total size: {total_size:.2f} MB\")\n",
    "print(f\"Output directory: {generator.output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Validation and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" Y-VALUE RANGE VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for eq_name in EQUATION_REGISTRY.keys():\n",
    "    filename = generator.generate_filename(eq_name, 500, 0.0, 0)\n",
    "    filepath = generator.output_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        data = generator.load_dataset(filename)\n",
    "        y = data['y']\n",
    "        \n",
    "        y_nonzero = y[y != 0]\n",
    "        if len(y_nonzero) > 0:\n",
    "            y_abs = np.abs(y_nonzero)\n",
    "            y_min, y_max = y_abs.min(), y_abs.max()\n",
    "        else:\n",
    "            y_min, y_max = 0, 0\n",
    "        \n",
    "        # Check if in stable range\n",
    "        stable = (y_min >= Y_MIN_THRESHOLD) and (y_max <= Y_MAX_THRESHOLD)\n",
    "        status = \"[OK]\" if stable else \"[WARNING]\"\n",
    "        \n",
    "        print(f\"{eq_name} ({data['ai_feynman_id']}):\")\n",
    "        print(f\"  Equation: {data['equation_str']}\")\n",
    "        print(f\"  y range: [{y_min:.2e}, {y_max:.2e}]\")\n",
    "        print(f\"  Status: {status}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" DATASET STRUCTURE VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for eq_name in EQUATION_REGISTRY.keys():\n",
    "    filename = generator.generate_filename(eq_name, 500, 0.0, 5)\n",
    "    filepath = generator.output_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        data = generator.load_dataset(filename)\n",
    "        \n",
    "        print(f\"{eq_name} ({data['ai_feynman_id']}):\")\n",
    "        print(f\"  X.shape = {data['X'].shape}\")\n",
    "        print(f\"  X.dtype = {data['X'].dtype}\")\n",
    "        print(f\"  true_features = {list(data['true_features'])}\")\n",
    "        print(f\"  dummy_features = {list(data['dummy_features'])}\")\n",
    "        print(f\"  target_dimensions = {data['target_dimensions']}\")\n",
    "        print(f\"  has variable_dimensions = {'variable_dimensions' in data}\")\n",
    "        print(f\"  has physical_bounds = {'physical_bounds' in data}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, eq_name in enumerate(EQUATION_REGISTRY.keys()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    filename = generator.generate_filename(eq_name, 500, 0.0, 0)\n",
    "    filepath = generator.output_dir / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        data = generator.load_dataset(filename)\n",
    "        y = data['y']\n",
    "        \n",
    "        ax.hist(y, bins=50, edgecolor='black', alpha=0.7)\n",
    "        title = f\"{eq_name.upper()} ({data['ai_feynman_id']})\\n{data['equation_str']}\"\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.set_xlabel('Target Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        \n",
    "        stats_text = f\"Mean: {np.mean(y):.2e}\\nStd: {np.std(y):.2e}\"\n",
    "        ax.text(0.95, 0.95, stats_text, transform=ax.transAxes,\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                fontsize=8, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(generator.output_dir / 'target_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDistribution plot saved to: {generator.output_dir / 'target_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" EXAMPLE: Loading Dataset for Experiments\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Example: Load Coulomb dataset with noise and dummy features\n",
    "example_file = \"eq1_coulomb_n500_noise0.05_dummy5.npz\"\n",
    "data = generator.load_dataset(example_file)\n",
    "\n",
    "print(f\"Loaded: {example_file}\")\n",
    "print()\n",
    "print(\"Data structure:\")\n",
    "print(f\"  X.shape = {data['X'].shape}\")\n",
    "print(f\"  X.dtype = {data['X'].dtype}\")\n",
    "print(f\"  y.shape = {data['y'].shape}\")\n",
    "print(f\"  feature_names = {list(data['feature_names'])}\")\n",
    "print(f\"  true_features = {list(data['true_features'])}\")\n",
    "print(f\"  dummy_features = {list(data['dummy_features'])}\")\n",
    "print()\n",
    "print(\"Ground truth:\")\n",
    "print(f\"  equation = {data['equation_str']}\")\n",
    "print(f\"  type = {data['equation_type']}\")\n",
    "print(f\"  ai_feynman_id = {data['ai_feynman_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" EXAMPLE: Creating UserInputs for Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Reconstruct UserInputs from loaded dataset\n",
    "user_inputs = UserInputs(\n",
    "    variable_dimensions=data['variable_dimensions'],\n",
    "    target_dimensions=list(data['target_dimensions']),\n",
    "    physical_bounds=data['physical_bounds']\n",
    ")\n",
    "\n",
    "print(\"UserInputs created from dataset:\")\n",
    "print(f\"  Variables: {user_inputs.get_variable_names()}\")\n",
    "print(f\"  Target dims: {user_inputs.target_dimensions}\")\n",
    "print()\n",
    "print(\"Variable dimensions:\")\n",
    "for var, dims in user_inputs.variable_dimensions.items():\n",
    "    print(f\"  {var}: {dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" DataGen Module Complete\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Available classes:\")\n",
    "print(\"  - UserInputs\")\n",
    "print(\"  - BaseTestEquation\")\n",
    "print(\"  - CoulombEquation (AI Feynman I.12.2)\")\n",
    "print(\"  - LawOfCosinesEquation (AI Feynman I.29.16)\")\n",
    "print(\"  - BarometricEquation (AI Feynman I.40.1)\")\n",
    "print(\"  - DotProductEquation (AI Feynman I.11.19)\")\n",
    "print(\"  - BenchmarkDataGenerator\")\n",
    "print()\n",
    "print(\"Available functions:\")\n",
    "print(\"  - get_equation(name)\")\n",
    "print(\"  - get_core_experiment_configs()\")\n",
    "print(\"  - get_supplementary_experiment_configs()\")\n",
    "print()\n",
    "print(f\"Generated datasets: {len(generator.list_datasets())}\")\n",
    "print(f\"Output directory: {generator.output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# ==============================================================================\n",
    "# DOWNLOAD GENERATED DATA (Uncomment in Colab)\n",
    "# ==============================================================================\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "\n",
    "# Define path directly\n",
    "data_dir = Path('/content/Physics-Informed-Symbolic-Regression/benchmark/data')\n",
    "zip_path = '/content/benchmark_data_v4.1.zip'\n",
    "\n",
    "# Create zip of data directory\n",
    "shutil.make_archive('/content/benchmark_data_v4.1', 'zip', data_dir)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Number of files: {len(list(data_dir.glob('*.npz')))}\")\n",
    "print()\n",
    "print(\"Downloading benchmark_data_v4.1.zip...\")\n",
    "\n",
    "files.download(zip_path)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

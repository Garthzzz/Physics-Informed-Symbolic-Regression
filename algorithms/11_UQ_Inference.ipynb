{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11_UQ_Inference - Physics-SR Framework v4.1\n",
    "\n",
    "## Stage 3.3-3.4: Three-Layer Bootstrap UQ + Statistical Inference\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (Structure-Guided Feature Library Enhancement + Computational Optimization)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Comprehensive uncertainty quantification for discovered equations with three layers:\n",
    "\n",
    "1. **Structural UQ:** Which terms should be included? (Bootstrap inclusion probability)\n",
    "2. **Parametric UQ:** What are the coefficient values? (Bootstrap confidence intervals)\n",
    "3. **Predictive UQ:** How uncertain are predictions? (Prediction intervals)\n",
    "\n",
    "This is a **minor update** module for v4.1.\n",
    "\n",
    "### v4.1 Modifications\n",
    "\n",
    "| Feature | v3.0 | v4.1 |\n",
    "|---------|------|------|\n",
    "| Version | 3.0 | 4.1 |\n",
    "| Parallel bootstrap | Not supported | n_jobs parameter |\n",
    "| Report format | Basic | Enhanced v4.1 format |\n",
    "\n",
    "### Theoretical Foundation\n",
    "\n",
    "**Stability Selection (Meinshausen & Buhlmann 2010):**\n",
    "$$E[\\text{False Positives}] \\leq \\frac{q^2}{(2\\pi_{thr} - 1) \\cdot p}$$\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Meinshausen, N., & Buhlmann, P. (2010). Stability selection. *JRSS-B*, 72(4), 417-473.\n",
    "- Framework v4.0/v4.1 Section 5.3: Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "11_UQ_Inference.ipynb - Three-Layer Bootstrap UQ + Statistical Inference\n",
    "=========================================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v4.1\n",
    "\n",
    "This module provides:\n",
    "- BootstrapUQ: Three-layer uncertainty quantification\n",
    "- StatisticalInference: Hypothesis testing for coefficients\n",
    "- Structural, parametric, and predictive uncertainty\n",
    "- Robust estimators (median, MAD) for non-normal data\n",
    "\n",
    "v4.1 Key Changes from v3.0:\n",
    "- n_jobs parameter for parallel bootstrap\n",
    "- Updated version number to v4.1\n",
    "- Enhanced report format with v4.1 styling\n",
    "- Interface fully compatible with Stage 2 outputs\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for UQ\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import warnings\n",
    "\n",
    "print(\"11_UQ_Inference v4.1: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BOOTSTRAP UQ CLASS (v4.1 Minor Update)\n",
    "# ==============================================================================\n",
    "\n",
    "class BootstrapUQ:\n",
    "    \"\"\"\n",
    "    Three-Layer Bootstrap Uncertainty Quantification (v4.1 Minor Update).\n",
    "    \n",
    "    Layer 1: Structural UQ (inclusion probability)\n",
    "    Layer 2: Parametric UQ (coefficient CI)\n",
    "    Layer 3: Predictive UQ (prediction intervals)\n",
    "    \n",
    "    v4.1 Features:\n",
    "    - n_jobs parameter for parallel bootstrap execution\n",
    "    - Robust estimators (median, MAD)\n",
    "    - Confidence classification (HIGH/MEDIUM/LOW)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples (default: 200)\n",
    "    selection_method : str\n",
    "        Method for sparse selection: 'stlsq' or 'alasso'\n",
    "    confidence_level : float\n",
    "        Confidence level for intervals (default: 0.95)\n",
    "    n_jobs : int\n",
    "        Parallel jobs for bootstrap (v4.1, default: 2)\n",
    "    stlsq_threshold : float\n",
    "        STLSQ sparsity threshold (default: 0.1)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    run(feature_library, y, library_names, selection_kwargs) -> Dict\n",
    "        Run complete bootstrap UQ analysis\n",
    "    predictive_uq(X_new, residual_var) -> Tuple\n",
    "        Compute prediction intervals\n",
    "    compute_prediction_intervals(...) -> Tuple\n",
    "        Alias for predictive_uq\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Meinshausen & Buhlmann (2010). JRSSB, 72(4), 417-473.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> uq = BootstrapUQ(n_bootstrap=200, n_jobs=2)\n",
    "    >>> result = uq.run(Phi, y, library_names)\n",
    "    >>> print(f\"Inclusion probs: {result['inclusion_probabilities']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_bootstrap: int = DEFAULT_N_BOOTSTRAP,\n",
    "        selection_method: str = 'stlsq',\n",
    "        confidence_level: float = DEFAULT_CONFIDENCE_LEVEL,\n",
    "        n_jobs: int = 2,\n",
    "        stlsq_threshold: float = DEFAULT_STLSQ_THRESHOLD\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize BootstrapUQ.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_bootstrap : int\n",
    "            Number of bootstrap samples. Default: 200\n",
    "        selection_method : str\n",
    "            'stlsq' or 'alasso'. Default: 'stlsq'\n",
    "        confidence_level : float\n",
    "            Confidence level (e.g., 0.95 for 95% CI). Default: 0.95\n",
    "        n_jobs : int\n",
    "            Number of parallel jobs for bootstrap (v4.1). Default: 2\n",
    "        stlsq_threshold : float\n",
    "            STLSQ threshold for sparsity. Default: 0.1\n",
    "        \"\"\"\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "        self.selection_method = selection_method\n",
    "        self.confidence_level = confidence_level\n",
    "        self.n_jobs = n_jobs\n",
    "        self.stlsq_threshold = stlsq_threshold\n",
    "        \n",
    "        # Internal state\n",
    "        self._library_names = None\n",
    "        self._n_features = None\n",
    "        self._support_samples = None\n",
    "        self._coef_samples = None\n",
    "        self._inclusion_probs = None\n",
    "        self._estimates = None\n",
    "        self._ci_lower = None\n",
    "        self._ci_upper = None\n",
    "        self._se = None\n",
    "        self._residual_variance = None\n",
    "        self._uq_complete = False\n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        library_names: List[str] = None,\n",
    "        selection_kwargs: Dict = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run complete bootstrap UQ analysis.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_library : np.ndarray\n",
    "            Feature library matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        library_names : List[str], optional\n",
    "            Feature names\n",
    "        selection_kwargs : Dict, optional\n",
    "            Additional kwargs for selection method\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            - inclusion_probabilities: Array of P(selected) for each feature\n",
    "            - structural_confidence: Classification (HIGH/MEDIUM/LOW)\n",
    "            - coefficient_estimates: Median coefficients\n",
    "            - coefficient_CI: 95% confidence intervals\n",
    "            - coefficient_SE: Standard errors\n",
    "            - bootstrap_supports: All support matrices\n",
    "            - bootstrap_coefficients: All coefficient samples\n",
    "            - residual_variance: Estimated noise variance\n",
    "        \"\"\"\n",
    "        n_samples, n_features = feature_library.shape\n",
    "        self._n_features = n_features\n",
    "        \n",
    "        if library_names is None:\n",
    "            self._library_names = [f'f{i}' for i in range(n_features)]\n",
    "        else:\n",
    "            self._library_names = list(library_names)\n",
    "        \n",
    "        # Initialize storage\n",
    "        self._support_samples = np.zeros((self.n_bootstrap, n_features), dtype=bool)\n",
    "        self._coef_samples = np.zeros((self.n_bootstrap, n_features))\n",
    "        \n",
    "        # Run bootstrap - parallel or sequential\n",
    "        if self.n_jobs > 1:\n",
    "            self._run_parallel_bootstrap(feature_library, y, selection_kwargs)\n",
    "        else:\n",
    "            self._run_sequential_bootstrap(feature_library, y, selection_kwargs)\n",
    "        \n",
    "        # Layer 1: Structural UQ\n",
    "        self._inclusion_probs, structural_conf = self._structural_uq(\n",
    "            self._support_samples, self._library_names\n",
    "        )\n",
    "        \n",
    "        # Layer 2: Parametric UQ\n",
    "        self._estimates, ci_bounds, self._se = self._parametric_uq(\n",
    "            self._coef_samples, self._support_samples\n",
    "        )\n",
    "        self._ci_lower = ci_bounds[:, 0]\n",
    "        self._ci_upper = ci_bounds[:, 1]\n",
    "        \n",
    "        # Estimate residual variance\n",
    "        y_pred = feature_library @ self._estimates\n",
    "        self._residual_variance = np.var(y - y_pred)\n",
    "        \n",
    "        # Confidence classification\n",
    "        confidence_class = self.get_confidence_classification()\n",
    "        \n",
    "        self._uq_complete = True\n",
    "        \n",
    "        return {\n",
    "            'inclusion_probabilities': self._inclusion_probs,\n",
    "            'inclusion_probs': self._inclusion_probs,  # Alias\n",
    "            'structural_confidence': structural_conf,\n",
    "            'confidence_class': confidence_class,\n",
    "            'coefficient_estimates': self._estimates,\n",
    "            'estimates': self._estimates,  # Alias\n",
    "            'coefficient_CI': np.column_stack([self._ci_lower, self._ci_upper]),\n",
    "            'ci_lower': self._ci_lower,\n",
    "            'ci_upper': self._ci_upper,\n",
    "            'coefficient_SE': self._se,\n",
    "            'se': self._se,  # Alias\n",
    "            'bootstrap_supports': self._support_samples,\n",
    "            'support_samples': self._support_samples,  # Alias\n",
    "            'bootstrap_coefficients': self._coef_samples,\n",
    "            'coef_samples': self._coef_samples,  # Alias\n",
    "            'residual_variance': self._residual_variance,\n",
    "            'n_bootstrap': self.n_bootstrap,\n",
    "            'confidence_level': self.confidence_level,\n",
    "            'n_jobs': self.n_jobs  # v4.1\n",
    "        }\n",
    "    \n",
    "    def _run_sequential_bootstrap(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        selection_kwargs: Dict = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Run bootstrap sequentially.\n",
    "        \"\"\"\n",
    "        for b in range(self.n_bootstrap):\n",
    "            coefs, support = self._run_single_bootstrap(\n",
    "                feature_library, y, b, selection_kwargs\n",
    "            )\n",
    "            self._support_samples[b] = support\n",
    "            self._coef_samples[b] = coefs\n",
    "    \n",
    "    def _run_parallel_bootstrap(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        selection_kwargs: Dict = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Run bootstrap in parallel (v4.1).\n",
    "        \"\"\"\n",
    "        def bootstrap_task(seed):\n",
    "            return seed, self._run_single_bootstrap(\n",
    "                feature_library, y, seed, selection_kwargs\n",
    "            )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(bootstrap_task, b) for b in range(self.n_bootstrap)]\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    b, (coefs, support) = future.result()\n",
    "                    self._support_samples[b] = support\n",
    "                    self._coef_samples[b] = coefs\n",
    "                except Exception as e:\n",
    "                    warnings.warn(f\"Bootstrap iteration failed: {e}\")\n",
    "    \n",
    "    def _run_single_bootstrap(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        seed: int,\n",
    "        selection_kwargs: Dict = None\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run single bootstrap iteration.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature library\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        seed : int\n",
    "            Random seed for this iteration\n",
    "        selection_kwargs : Dict, optional\n",
    "            Additional selection parameters\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (coefficients, support)\n",
    "        \"\"\"\n",
    "        # Generate bootstrap sample\n",
    "        rng = np.random.RandomState(RANDOM_SEED + seed)\n",
    "        n = len(y)\n",
    "        indices = rng.choice(n, size=n, replace=True)\n",
    "        Phi_boot = Phi[indices]\n",
    "        y_boot = y[indices]\n",
    "        \n",
    "        # Run selection\n",
    "        n_features = Phi.shape[1]\n",
    "        \n",
    "        if self.selection_method == 'stlsq':\n",
    "            coefs = self._stlsq_simple(Phi_boot, y_boot)\n",
    "        else:  # alasso\n",
    "            coefs = self._alasso_simple(Phi_boot, y_boot)\n",
    "        \n",
    "        support = np.abs(coefs) > 1e-10\n",
    "        return coefs, support\n",
    "    \n",
    "    def _stlsq_simple(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simple STLSQ implementation for bootstrap.\n",
    "        \"\"\"\n",
    "        n_features = Phi.shape[1]\n",
    "        \n",
    "        # Initial OLS\n",
    "        try:\n",
    "            xi, _, _, _ = np.linalg.lstsq(Phi, y, rcond=None)\n",
    "        except np.linalg.LinAlgError:\n",
    "            return np.zeros(n_features)\n",
    "        \n",
    "        # Iterate\n",
    "        for _ in range(10):\n",
    "            support = np.abs(xi) > self.stlsq_threshold\n",
    "            if np.sum(support) == 0:\n",
    "                return np.zeros(n_features)\n",
    "            \n",
    "            xi_new = np.zeros(n_features)\n",
    "            try:\n",
    "                xi_new[support], _, _, _ = np.linalg.lstsq(\n",
    "                    Phi[:, support], y, rcond=None\n",
    "                )\n",
    "            except np.linalg.LinAlgError:\n",
    "                break\n",
    "            \n",
    "            if np.allclose(xi, xi_new):\n",
    "                break\n",
    "            xi = xi_new\n",
    "        \n",
    "        return xi\n",
    "    \n",
    "    def _alasso_simple(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simple Adaptive Lasso for bootstrap.\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import Ridge, LassoCV\n",
    "        \n",
    "        n_features = Phi.shape[1]\n",
    "        \n",
    "        # Initial estimate\n",
    "        ridge = Ridge(alpha=0.1, fit_intercept=False)\n",
    "        ridge.fit(Phi, y)\n",
    "        beta_init = ridge.coef_\n",
    "        \n",
    "        # Adaptive weights\n",
    "        eps = 1e-6\n",
    "        weights = 1.0 / (np.abs(beta_init) + eps)\n",
    "        \n",
    "        # Weighted Lasso\n",
    "        Phi_weighted = Phi / np.sqrt(weights)\n",
    "        lasso = LassoCV(cv=3, fit_intercept=False, max_iter=1000)\n",
    "        try:\n",
    "            lasso.fit(Phi_weighted, y)\n",
    "            beta = lasso.coef_ / np.sqrt(weights)\n",
    "        except Exception:\n",
    "            beta = np.zeros(n_features)\n",
    "        \n",
    "        return beta\n",
    "    \n",
    "    def _structural_uq(\n",
    "        self,\n",
    "        support_samples: np.ndarray,\n",
    "        library_names: List[str]\n",
    "    ) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"\n",
    "        Compute inclusion probabilities and classify confidence.\n",
    "        \n",
    "        Classification:\n",
    "        - HIGH: P > 0.9\n",
    "        - MEDIUM: 0.5 < P <= 0.9\n",
    "        - LOW: P <= 0.5\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, Dict]\n",
    "            (inclusion_probs, structural_confidence)\n",
    "        \"\"\"\n",
    "        inclusion_probs = np.mean(support_samples, axis=0)\n",
    "        \n",
    "        structural_conf = {}\n",
    "        for i, name in enumerate(library_names):\n",
    "            prob = inclusion_probs[i]\n",
    "            if prob > 0.9:\n",
    "                conf = 'HIGH'\n",
    "            elif prob > 0.5:\n",
    "                conf = 'MEDIUM'\n",
    "            else:\n",
    "                conf = 'LOW'\n",
    "            structural_conf[name] = {'prob': prob, 'confidence': conf}\n",
    "        \n",
    "        return inclusion_probs, structural_conf\n",
    "    \n",
    "    def _parametric_uq(\n",
    "        self,\n",
    "        coef_samples: np.ndarray,\n",
    "        support_samples: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute coefficient estimates and CIs.\n",
    "        \n",
    "        Uses robust estimators (median, MAD-based SE).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "            (estimates, ci_bounds, se)\n",
    "        \"\"\"\n",
    "        n_features = coef_samples.shape[1]\n",
    "        estimates = np.zeros(n_features)\n",
    "        se = np.zeros(n_features)\n",
    "        ci_bounds = np.zeros((n_features, 2))\n",
    "        \n",
    "        alpha = 1 - self.confidence_level\n",
    "        lower_percentile = 100 * alpha / 2\n",
    "        upper_percentile = 100 * (1 - alpha / 2)\n",
    "        \n",
    "        for j in range(n_features):\n",
    "            # Get non-zero samples\n",
    "            nonzero_mask = support_samples[:, j]\n",
    "            if np.sum(nonzero_mask) < 10:\n",
    "                continue\n",
    "            \n",
    "            samples_j = coef_samples[nonzero_mask, j]\n",
    "            \n",
    "            # Robust point estimate (median)\n",
    "            estimates[j] = np.median(samples_j)\n",
    "            \n",
    "            # Robust SE (MAD * 1.4826)\n",
    "            mad = np.median(np.abs(samples_j - estimates[j]))\n",
    "            se[j] = mad * 1.4826\n",
    "            \n",
    "            # Percentile CI\n",
    "            ci_bounds[j, 0] = np.percentile(samples_j, lower_percentile)\n",
    "            ci_bounds[j, 1] = np.percentile(samples_j, upper_percentile)\n",
    "        \n",
    "        return estimates, ci_bounds, se\n",
    "    \n",
    "    def predictive_uq(\n",
    "        self,\n",
    "        X_new: np.ndarray,\n",
    "        residual_var: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute prediction intervals.\n",
    "        \n",
    "        Total variance = model variance + residual variance\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_new : np.ndarray\n",
    "            New feature matrix\n",
    "        residual_var : float\n",
    "            Residual variance from training\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "            (predictions, pi_lower, pi_upper)\n",
    "        \"\"\"\n",
    "        if not self._uq_complete:\n",
    "            raise RuntimeError(\"Must run UQ first\")\n",
    "        \n",
    "        n_new = X_new.shape[0]\n",
    "        z = norm.ppf(1 - (1 - self.confidence_level) / 2)\n",
    "        \n",
    "        # Predictions from each bootstrap sample\n",
    "        pred_samples = np.zeros((self.n_bootstrap, n_new))\n",
    "        for b in range(self.n_bootstrap):\n",
    "            pred_samples[b] = X_new @ self._coef_samples[b]\n",
    "        \n",
    "        # Point prediction (median)\n",
    "        predictions = np.median(pred_samples, axis=0)\n",
    "        \n",
    "        # Model variance\n",
    "        model_var = np.var(pred_samples, axis=0)\n",
    "        \n",
    "        # Total variance\n",
    "        total_var = model_var + residual_var\n",
    "        total_se = np.sqrt(total_var)\n",
    "        \n",
    "        # Prediction interval\n",
    "        pi_lower = predictions - z * total_se\n",
    "        pi_upper = predictions + z * total_se\n",
    "        \n",
    "        return predictions, pi_lower, pi_upper\n",
    "    \n",
    "    def compute_prediction_intervals(\n",
    "        self,\n",
    "        coef_samples: np.ndarray,\n",
    "        support: np.ndarray,\n",
    "        X_new: np.ndarray,\n",
    "        residual_var: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute prediction intervals (v4.1 alias).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        coef_samples : np.ndarray\n",
    "            Bootstrap coefficient samples\n",
    "        support : np.ndarray\n",
    "            Support mask (not used, for interface compatibility)\n",
    "        X_new : np.ndarray\n",
    "            New feature matrix\n",
    "        residual_var : float\n",
    "            Residual variance\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (pi_lower, pi_upper)\n",
    "        \"\"\"\n",
    "        _, pi_lower, pi_upper = self.predictive_uq(X_new, residual_var)\n",
    "        return pi_lower, pi_upper\n",
    "    \n",
    "    def get_confidence_classification(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classify terms by inclusion probability.\n",
    "        \"\"\"\n",
    "        if self._inclusion_probs is None:\n",
    "            raise RuntimeError(\"Must run UQ first\")\n",
    "        \n",
    "        classification = {}\n",
    "        for name, prob in zip(self._library_names, self._inclusion_probs):\n",
    "            if prob > 0.9:\n",
    "                classification[name] = 'HIGH'\n",
    "            elif prob > 0.5:\n",
    "                classification[name] = 'MEDIUM'\n",
    "            else:\n",
    "                classification[name] = 'LOW'\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def print_uq_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed UQ report in v4.1 format.\n",
    "        \"\"\"\n",
    "        if not self._uq_complete:\n",
    "            print(\"UQ not yet performed. Call run() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(f\"=== Bootstrap UQ Results (B={self.n_bootstrap}) (v4.1) ===\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Bootstrap samples: {self.n_bootstrap}\")\n",
    "        print(f\"  Selection method: {self.selection_method}\")\n",
    "        print(f\"  Confidence level: {self.confidence_level:.0%}\")\n",
    "        print(f\"  Parallel jobs (n_jobs): {self.n_jobs}\")\n",
    "        print()\n",
    "        \n",
    "        # Layer 1\n",
    "        print(\"Layer 1: Structural UQ\")\n",
    "        print(f\"  {'Term':<25} {'P(include)':<12} {'Confidence'}\")\n",
    "        print(\"  \" + \"-\" * 50)\n",
    "        \n",
    "        conf_class = self.get_confidence_classification()\n",
    "        for name, prob in zip(self._library_names, self._inclusion_probs):\n",
    "            if prob > 0.1:\n",
    "                print(f\"  {name:<25} {prob:<12.2f} {conf_class[name]}\")\n",
    "        print()\n",
    "        \n",
    "        # Layer 2\n",
    "        print(\"Layer 2: Parametric UQ\")\n",
    "        print(f\"  {'Coefficient':<15} {'Estimate':<12} {'95% CI'}\")\n",
    "        print(\"  \" + \"-\" * 50)\n",
    "        \n",
    "        for i, name in enumerate(self._library_names):\n",
    "            if self._inclusion_probs[i] > 0.5:\n",
    "                ci_str = f\"[{self._ci_lower[i]:.4f}, {self._ci_upper[i]:.4f}]\"\n",
    "                print(f\"  {name:<15} {self._estimates[i]:<12.4f} {ci_str}\")\n",
    "        print()\n",
    "        \n",
    "        # Layer 3 info\n",
    "        print(\"Layer 3: Predictive UQ\")\n",
    "        print(f\"  Residual variance: {self._residual_variance:.6f}\")\n",
    "        print(f\"  Use predictive_uq(X_new, residual_var) for prediction intervals\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "print(\"BootstrapUQ class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STATISTICAL INFERENCE CLASS (v4.1 Minor Update)\n",
    "# ==============================================================================\n",
    "\n",
    "class StatisticalInference:\n",
    "    \"\"\"\n",
    "    Formal Statistical Inference (v4.1 Minor Update).\n",
    "    \n",
    "    Provides:\n",
    "    - Hypothesis testing for term significance\n",
    "    - P-values and effect sizes\n",
    "    - Comprehensive statistical report\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    alpha : float\n",
    "        Significance level (default: 0.05)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    test_coefficients(coef_samples, library_names) -> Dict\n",
    "        Test coefficient significance\n",
    "    generate_report(...) -> str\n",
    "        Generate comprehensive statistical report\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> inference = StatisticalInference(alpha=0.05)\n",
    "    >>> result = inference.test_coefficients(coef_samples, support_samples, names)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.05):\n",
    "        \"\"\"\n",
    "        Initialize StatisticalInference.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self._test_results = None\n",
    "    \n",
    "    def test_coefficients(\n",
    "        self,\n",
    "        coef_samples: np.ndarray,\n",
    "        support_samples: np.ndarray,\n",
    "        library_names: List[str]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test coefficient significance.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        coef_samples : np.ndarray\n",
    "            Bootstrap coefficient samples (n_bootstrap x n_features)\n",
    "        support_samples : np.ndarray\n",
    "            Bootstrap support indicators\n",
    "        library_names : List[str]\n",
    "            Feature names\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            - p_values: {term_name: p_value}\n",
    "            - significant: List of significant terms\n",
    "            - test_statistics: {term_name: t_stat}\n",
    "            - effect_sizes: {term_name: effect_size}\n",
    "        \"\"\"\n",
    "        n_features = coef_samples.shape[1]\n",
    "        self._test_results = {}\n",
    "        \n",
    "        p_values = {}\n",
    "        test_statistics = {}\n",
    "        effect_sizes = {}\n",
    "        significant = []\n",
    "        \n",
    "        for j in range(n_features):\n",
    "            name = library_names[j]\n",
    "            \n",
    "            # Get non-zero samples\n",
    "            nonzero_mask = support_samples[:, j]\n",
    "            n_nonzero = np.sum(nonzero_mask)\n",
    "            \n",
    "            if n_nonzero < 10:\n",
    "                self._test_results[name] = {\n",
    "                    'significant': False,\n",
    "                    'p_value': 1.0,\n",
    "                    'z_stat': 0.0,\n",
    "                    'estimate': 0.0,\n",
    "                    'se': np.inf,\n",
    "                    'effect_size': 0.0,\n",
    "                    'n_samples': int(n_nonzero)\n",
    "                }\n",
    "                p_values[name] = 1.0\n",
    "                test_statistics[name] = 0.0\n",
    "                effect_sizes[name] = 0.0\n",
    "                continue\n",
    "            \n",
    "            samples_j = coef_samples[nonzero_mask, j]\n",
    "            result = self._hypothesis_test(samples_j)\n",
    "            result['n_samples'] = int(n_nonzero)\n",
    "            self._test_results[name] = result\n",
    "            \n",
    "            p_values[name] = result['p_value']\n",
    "            test_statistics[name] = result['z_stat']\n",
    "            effect_sizes[name] = result['effect_size']\n",
    "            \n",
    "            if result['significant']:\n",
    "                significant.append(name)\n",
    "        \n",
    "        return {\n",
    "            'p_values': p_values,\n",
    "            'significant': significant,\n",
    "            'test_statistics': test_statistics,\n",
    "            'effect_sizes': effect_sizes,\n",
    "            'detailed_results': self._test_results\n",
    "        }\n",
    "    \n",
    "    def _hypothesis_test(\n",
    "        self,\n",
    "        samples: np.ndarray\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform hypothesis test for single coefficient.\n",
    "        \n",
    "        H0: coefficient = 0\n",
    "        Uses bootstrap distribution for inference.\n",
    "        \"\"\"\n",
    "        # Robust estimates\n",
    "        estimate = np.median(samples)\n",
    "        mad = np.median(np.abs(samples - estimate))\n",
    "        se = mad * 1.4826\n",
    "        \n",
    "        # Effect size (Cohen's d analog)\n",
    "        if se > 1e-10:\n",
    "            effect_size = abs(estimate) / se\n",
    "        else:\n",
    "            effect_size = np.inf if abs(estimate) > 1e-10 else 0.0\n",
    "        \n",
    "        if se < 1e-10:\n",
    "            z_stat = np.inf if abs(estimate) > 1e-10 else 0.0\n",
    "            p_value = 0.0 if abs(estimate) > 1e-10 else 1.0\n",
    "        else:\n",
    "            z_stat = estimate / se\n",
    "            p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        significant = p_value < self.alpha\n",
    "        \n",
    "        return {\n",
    "            'significant': significant,\n",
    "            'p_value': float(p_value),\n",
    "            'z_stat': float(z_stat),\n",
    "            'estimate': float(estimate),\n",
    "            'se': float(se),\n",
    "            'effect_size': float(effect_size),\n",
    "            'stars': self._format_significance_stars(p_value)\n",
    "        }\n",
    "    \n",
    "    def _format_significance_stars(\n",
    "        self,\n",
    "        p_value: float\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Format significance stars.\n",
    "        \"\"\"\n",
    "        if p_value < 0.001:\n",
    "            return '***'\n",
    "        elif p_value < 0.01:\n",
    "            return '**'\n",
    "        elif p_value < 0.05:\n",
    "            return '*'\n",
    "        elif p_value < 0.1:\n",
    "            return '.'\n",
    "        else:\n",
    "            return ''\n",
    "    \n",
    "    def generate_report(\n",
    "        self,\n",
    "        equation: str,\n",
    "        structural_uq: Dict,\n",
    "        parametric_uq: Dict,\n",
    "        predictive_uq: Dict,\n",
    "        physics_verification: Dict,\n",
    "        model_comparison: Dict,\n",
    "        library_analysis: Dict = None,\n",
    "        timing_profile: Dict = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate comprehensive statistical report (v4.1 format).\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"=\" * 70)\n",
    "        lines.append(\"PHYSICS-SR STATISTICAL REPORT (v4.1)\")\n",
    "        lines.append(\"=\" * 70)\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"1. DISCOVERED EQUATION\")\n",
    "        lines.append(\"-\" * 70)\n",
    "        lines.append(f\"   {equation}\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Additional sections would be added here...\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def print_inference_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print inference report in v4.1 format.\n",
    "        \"\"\"\n",
    "        if self._test_results is None:\n",
    "            print(\"Test not yet performed. Call test_coefficients() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"=== Statistical Inference Results (v4.1) ===\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Significance level: {self.alpha}\")\n",
    "        print()\n",
    "        print(f\"{'Feature':<25} {'Estimate':<10} {'SE':<10} {'z-stat':<10} {'p-value':<12} {'Sig'}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for name, result in self._test_results.items():\n",
    "            sig_str = result['stars'] if result['significant'] else ''\n",
    "            print(f\"{name:<25} {result['estimate']:<10.4f} {result['se']:<10.4f} \"\n",
    "                  f\"{result['z_stat']:<10.2f} {result['p_value']:<12.4f} {sig_str}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"Significance codes: *** p<0.001, ** p<0.01, * p<0.05, . p<0.1\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "print(\"StatisticalInference class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 11_UQ_Inference v4.1\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Structural UQ (Inclusion Probabilities)\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Structural UQ\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    x3 = np.random.randn(n_samples)  # Not in true model\n",
    "    \n",
    "    y = 3*x1 + 1.5*x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x1, x2, x3])\n",
    "    library_names = ['1', 'x1', 'x2', 'x3']\n",
    "    \n",
    "    print(f\"True: y = 3*x1 + 1.5*x2\")\n",
    "    print()\n",
    "    \n",
    "    uq = BootstrapUQ(n_bootstrap=50, n_jobs=2)\n",
    "    result = uq.run(Phi, y, library_names)\n",
    "    \n",
    "    print(f\"{'Feature':<10} {'P(include)':<12} {'Confidence'}\")\n",
    "    print(\"-\" * 35)\n",
    "    for name, prob in zip(library_names, result['inclusion_probs']):\n",
    "        conf = result['confidence_class'][name]\n",
    "        print(f\"{name:<10} {prob:<12.3f} {conf}\")\n",
    "    \n",
    "    # x1 and x2 should have high inclusion, x3 should be low\n",
    "    if (result['inclusion_probs'][1] > 0.8 and \n",
    "        result['inclusion_probs'][2] > 0.8 and\n",
    "        result['inclusion_probs'][3] < 0.5):\n",
    "        print(\"\\n[PASS] Structural UQ correctly identifies important terms\")\n",
    "    else:\n",
    "        print(\"\\n[INFO] Check bootstrap sample size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Parametric UQ (Coefficient CIs)\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: Parametric UQ - Coefficient CIs\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    true_coefs = [0, 3.0, 1.5]  # intercept=0, x1=3, x2=1.5\n",
    "    y = 3*x1 + 1.5*x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x1, x2])\n",
    "    library_names = ['1', 'x1', 'x2']\n",
    "    \n",
    "    uq = BootstrapUQ(n_bootstrap=100, n_jobs=2)\n",
    "    result = uq.run(Phi, y, library_names)\n",
    "    \n",
    "    print(f\"{'Feature':<10} {'True':<10} {'Estimate':<10} {'95% CI':<25} {'Covered'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, (name, true) in enumerate(zip(library_names, true_coefs)):\n",
    "        est = result['estimates'][i]\n",
    "        ci_l = result['ci_lower'][i]\n",
    "        ci_u = result['ci_upper'][i]\n",
    "        covered = ci_l <= true <= ci_u\n",
    "        print(f\"{name:<10} {true:<10.2f} {est:<10.4f} [{ci_l:.4f}, {ci_u:.4f}] {covered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: Parallel vs Sequential Bootstrap (v4.1)\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: Parallel vs Sequential Bootstrap (v4.1)\")\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    y = 2*x1 + 0.1*np.random.randn(n_samples)\n",
    "    Phi = np.column_stack([np.ones(n_samples), x1])\n",
    "    library_names = ['1', 'x1']\n",
    "    \n",
    "    # Sequential\n",
    "    start = time.time()\n",
    "    uq_seq = BootstrapUQ(n_bootstrap=50, n_jobs=1)\n",
    "    result_seq = uq_seq.run(Phi, y, library_names)\n",
    "    time_seq = time.time() - start\n",
    "    \n",
    "    # Parallel\n",
    "    start = time.time()\n",
    "    uq_par = BootstrapUQ(n_bootstrap=50, n_jobs=2)\n",
    "    result_par = uq_par.run(Phi, y, library_names)\n",
    "    time_par = time.time() - start\n",
    "    \n",
    "    print(f\"Sequential (n_jobs=1): {time_seq:.2f}s\")\n",
    "    print(f\"Parallel (n_jobs=2):   {time_par:.2f}s\")\n",
    "    print(f\"Speedup: {time_seq/time_par:.2f}x\")\n",
    "    print()\n",
    "    \n",
    "    # Results should be similar\n",
    "    diff = np.abs(result_seq['estimates'] - result_par['estimates']).max()\n",
    "    print(f\"Max estimate difference: {diff:.6f}\")\n",
    "    \n",
    "    if diff < 0.1:\n",
    "        print(\"[PASS] Parallel and sequential give similar results\")\n",
    "    else:\n",
    "        print(\"[INFO] Some variance expected due to different random seeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: Full UQ Report\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: Full UQ Report\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    z = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 0.5*x**2 + np.sin(z) + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([x**2, np.sin(z), np.ones(n_samples), x, z])\n",
    "    library_names = ['[PySR] x**2', '[PySR] sin(z)', '[Poly] 1', '[Poly] x', '[Poly] z']\n",
    "    \n",
    "    uq = BootstrapUQ(n_bootstrap=100, n_jobs=2)\n",
    "    result = uq.run(Phi, y, library_names)\n",
    "    \n",
    "    uq.print_uq_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Statistical Inference\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 5: Statistical Inference\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    x3 = np.random.randn(n_samples)  # Not in true model\n",
    "    \n",
    "    y = 5*x1 + 2*x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([x1, x2, x3])\n",
    "    library_names = ['x1', 'x2', 'x3']\n",
    "    \n",
    "    # Run UQ\n",
    "    uq = BootstrapUQ(n_bootstrap=100, n_jobs=2)\n",
    "    result = uq.run(Phi, y, library_names)\n",
    "    \n",
    "    # Statistical inference\n",
    "    inference = StatisticalInference(alpha=0.05)\n",
    "    test_results = inference.test_coefficients(\n",
    "        result['coef_samples'],\n",
    "        result['support_samples'],\n",
    "        library_names\n",
    "    )\n",
    "    \n",
    "    inference.print_inference_report()\n",
    "    \n",
    "    # x1, x2 should be significant, x3 should not\n",
    "    if ('x1' in test_results['significant'] and \n",
    "        'x2' in test_results['significant'] and \n",
    "        'x3' not in test_results['significant']):\n",
    "        print(\"\\n[PASS] Correct significance detection\")\n",
    "    else:\n",
    "        print(\"\\n[INFO] Check significance results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 11_UQ_Inference.ipynb v4.1 - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASSES:\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"1. BootstrapUQ (v4.1 Minor Update)\")\n",
    "print(\"   Purpose: Three-layer uncertainty quantification\")\n",
    "print(\"   \")\n",
    "print(\"   v4.1 Features:\")\n",
    "print(\"     - n_jobs parameter for parallel bootstrap\")\n",
    "print(\"     - Enhanced v4.1 report format\")\n",
    "print(\"   \")\n",
    "print(\"   Main Methods:\")\n",
    "print(\"     run(Phi, y, library_names, selection_kwargs) -> Dict\")\n",
    "print(\"     predictive_uq(X_new, residual_var) -> Tuple\")\n",
    "print(\"     compute_prediction_intervals(...) -> Tuple\")\n",
    "print(\"     get_confidence_classification() -> Dict\")\n",
    "print(\"     print_uq_report()\")\n",
    "print()\n",
    "print(\"2. StatisticalInference\")\n",
    "print(\"   Purpose: Hypothesis testing for coefficients\")\n",
    "print(\"   Main Methods:\")\n",
    "print(\"     test_coefficients(coef_samples, support_samples, names) -> Dict\")\n",
    "print(\"     generate_report(...) -> str\")\n",
    "print(\"     print_inference_report()\")\n",
    "print()\n",
    "print(\"Expected Output Format (v4.1):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "=== Bootstrap UQ Results (B=200) (v4.1) ===\n",
    "\n",
    "Layer 1: Structural UQ\n",
    "  Term                      P(include)   Confidence\n",
    "  x**2                      0.98         HIGH\n",
    "  sin(z)                    0.95         HIGH\n",
    "  Intercept                 0.15         LOW\n",
    "\n",
    "Layer 2: Parametric UQ\n",
    "  Coefficient      Estimate     95% CI\n",
    "  c1               0.498        [0.42, 0.58]\n",
    "  c2               0.998        [0.89, 1.10]\n",
    "\n",
    "Layer 3: Predictive UQ\n",
    "  PI Coverage: 94.5% (target: 95%)\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Run bootstrap UQ with parallel execution (v4.1)\n",
    "uq = BootstrapUQ(n_bootstrap=200, n_jobs=2)\n",
    "result = uq.run(Phi, y, library_names)\n",
    "\n",
    "# Check inclusion probabilities\n",
    "print(result['inclusion_probabilities'])\n",
    "\n",
    "# Get coefficient CIs\n",
    "print(f\"Estimates: {result['coefficient_estimates']}\")\n",
    "print(f\"95% CI: {result['coefficient_CI']}\")\n",
    "\n",
    "# Prediction intervals\n",
    "pred, pi_lower, pi_upper = uq.predictive_uq(X_new, result['residual_variance'])\n",
    "\n",
    "# Statistical inference\n",
    "inference = StatisticalInference()\n",
    "tests = inference.test_coefficients(\n",
    "    result['coef_samples'], result['support_samples'], library_names\n",
    ")\n",
    "inference.print_inference_report()\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 11_UQ_Inference.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

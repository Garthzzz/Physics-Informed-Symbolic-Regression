{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11_UQ_Inference - Physics-SR Framework v3.0\n",
    "\n",
    "## Stage 3.3-3.4: Three-Layer Bootstrap UQ + Statistical Inference\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Comprehensive uncertainty quantification for discovered equations with three layers:\n",
    "\n",
    "1. **Structural UQ:** Which terms should be included? (Bootstrap inclusion probability)\n",
    "2. **Parametric UQ:** What are the coefficient values? (Bootstrap confidence intervals)\n",
    "3. **Predictive UQ:** How uncertain are predictions? (Prediction intervals)\n",
    "\n",
    "### Theoretical Foundation\n",
    "\n",
    "**Stability Selection (Meinshausen & Buhlmann 2010):**\n",
    "$$E[\\text{False Positives}] \\leq \\frac{q^2}{(2\\pi_{thr} - 1) \\cdot p}$$\n",
    "\n",
    "where $q$ = average selected terms, $\\pi_{thr}$ = inclusion threshold, $p$ = total terms.\n",
    "\n",
    "### Robust Estimators\n",
    "\n",
    "- **Point estimate:** Median (not mean) for robustness to outliers\n",
    "- **Standard error:** MAD $\\times$ 1.4826 (consistent with SD for normal data)\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Meinshausen, N., & Buhlmann, P. (2010). Stability selection. *JRSS-B*, 72(4), 417-473."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "11_UQ_Inference.ipynb - Three-Layer Bootstrap UQ + Statistical Inference\n",
    "=========================================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v3.0\n",
    "\n",
    "This module provides:\n",
    "- BootstrapUQ: Three-layer uncertainty quantification\n",
    "- StatisticalInference: Hypothesis testing for coefficients\n",
    "- Structural, parametric, and predictive uncertainty\n",
    "- Robust estimators (median, MAD) for non-normal data\n",
    "\n",
    "Algorithm:\n",
    "    1. Bootstrap resampling (B samples)\n",
    "    2. Structural UQ: Inclusion probabilities\n",
    "    3. Parametric UQ: Coefficient confidence intervals\n",
    "    4. Predictive UQ: Prediction intervals\n",
    "    5. Statistical inference: Hypothesis tests\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for UQ\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "print(\"11_UQ_Inference: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BOOTSTRAP UQ CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class BootstrapUQ:\n",
    "    \"\"\"\n",
    "    Three-Layer Bootstrap Uncertainty Quantification.\n",
    "    \n",
    "    Provides comprehensive UQ for symbolic regression:\n",
    "    - Layer 1: Structural uncertainty (inclusion probabilities)\n",
    "    - Layer 2: Parametric uncertainty (coefficient CIs)\n",
    "    - Layer 3: Predictive uncertainty (prediction intervals)\n",
    "    \n",
    "    Uses robust estimators (median, MAD) for non-normal bootstrap distributions.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples (default: 200)\n",
    "    selection_method : str\n",
    "        'stlsq' or 'alasso' (default: 'stlsq')\n",
    "    confidence_level : float\n",
    "        Confidence level for CIs (default: 0.95)\n",
    "    stlsq_threshold : float\n",
    "        STLSQ sparsity threshold (default: 0.1)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> uq = BootstrapUQ(n_bootstrap=200)\n",
    "    >>> result = uq.run(Phi, y, feature_names)\n",
    "    >>> print(result['inclusion_probs'])\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_bootstrap: int = DEFAULT_N_BOOTSTRAP,\n",
    "        selection_method: str = 'stlsq',\n",
    "        confidence_level: float = DEFAULT_CONFIDENCE_LEVEL,\n",
    "        stlsq_threshold: float = DEFAULT_STLSQ_THRESHOLD\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize BootstrapUQ.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_bootstrap : int\n",
    "            Number of bootstrap samples. Default: 200\n",
    "        selection_method : str\n",
    "            'stlsq' or 'alasso'. Default: 'stlsq'\n",
    "        confidence_level : float\n",
    "            Confidence level (e.g., 0.95 for 95% CI). Default: 0.95\n",
    "        stlsq_threshold : float\n",
    "            STLSQ threshold for sparsity. Default: 0.1\n",
    "        \"\"\"\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "        self.selection_method = selection_method\n",
    "        self.confidence_level = confidence_level\n",
    "        self.stlsq_threshold = stlsq_threshold\n",
    "        \n",
    "        # Internal state\n",
    "        self._feature_names = None\n",
    "        self._n_features = None\n",
    "        self._support_samples = None\n",
    "        self._coef_samples = None\n",
    "        self._inclusion_probs = None\n",
    "        self._estimates = None\n",
    "        self._ci_lower = None\n",
    "        self._ci_upper = None\n",
    "        self._se = None\n",
    "        self._uq_complete = False\n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run full bootstrap UQ.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_library : np.ndarray\n",
    "            Feature matrix of shape (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        feature_names : List[str], optional\n",
    "            Feature names\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Dictionary containing:\n",
    "            - inclusion_probs: Inclusion probability for each term\n",
    "            - confidence_class: Classification (high/medium/low)\n",
    "            - estimates: Point estimates (median)\n",
    "            - ci_lower: Lower CI bounds\n",
    "            - ci_upper: Upper CI bounds\n",
    "            - se: Standard errors\n",
    "            - support_samples: Bootstrap support matrix\n",
    "            - coef_samples: Bootstrap coefficient matrix\n",
    "        \"\"\"\n",
    "        n_samples, n_features = feature_library.shape\n",
    "        self._n_features = n_features\n",
    "        \n",
    "        if feature_names is None:\n",
    "            self._feature_names = [f'f{i}' for i in range(n_features)]\n",
    "        else:\n",
    "            self._feature_names = list(feature_names)\n",
    "        \n",
    "        # Bootstrap sampling\n",
    "        self._support_samples = np.zeros((self.n_bootstrap, n_features), dtype=bool)\n",
    "        self._coef_samples = np.zeros((self.n_bootstrap, n_features))\n",
    "        \n",
    "        for b in range(self.n_bootstrap):\n",
    "            # Resample\n",
    "            Phi_boot, y_boot = self._bootstrap_sample(feature_library, y, b)\n",
    "            \n",
    "            # Run selection\n",
    "            coefs, support = self._run_selection(Phi_boot, y_boot)\n",
    "            \n",
    "            self._support_samples[b] = support\n",
    "            self._coef_samples[b] = coefs\n",
    "        \n",
    "        # Layer 1: Structural UQ\n",
    "        self._inclusion_probs = self._structural_uq(self._support_samples)\n",
    "        \n",
    "        # Layer 2: Parametric UQ\n",
    "        self._estimates, ci_bounds, self._se = self._parametric_uq(\n",
    "            self._coef_samples, self._support_samples\n",
    "        )\n",
    "        self._ci_lower = ci_bounds[:, 0]\n",
    "        self._ci_upper = ci_bounds[:, 1]\n",
    "        \n",
    "        # Confidence classification\n",
    "        confidence_class = self.get_confidence_classification()\n",
    "        \n",
    "        self._uq_complete = True\n",
    "        \n",
    "        return {\n",
    "            'inclusion_probs': self._inclusion_probs,\n",
    "            'confidence_class': confidence_class,\n",
    "            'estimates': self._estimates,\n",
    "            'ci_lower': self._ci_lower,\n",
    "            'ci_upper': self._ci_upper,\n",
    "            'se': self._se,\n",
    "            'support_samples': self._support_samples,\n",
    "            'coef_samples': self._coef_samples,\n",
    "            'n_bootstrap': self.n_bootstrap,\n",
    "            'confidence_level': self.confidence_level\n",
    "        }\n",
    "    \n",
    "    def _bootstrap_sample(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        seed: int\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate bootstrap sample.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        seed : int\n",
    "            Random seed\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (X_boot, y_boot)\n",
    "        \"\"\"\n",
    "        np.random.seed(RANDOM_SEED + seed)\n",
    "        n = len(y)\n",
    "        indices = np.random.choice(n, size=n, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    def _run_selection(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run sparse selection on bootstrap sample.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (coefficients, support)\n",
    "        \"\"\"\n",
    "        n_features = Phi.shape[1]\n",
    "        \n",
    "        if self.selection_method == 'stlsq':\n",
    "            coefs = self._stlsq_simple(Phi, y)\n",
    "        else:  # alasso\n",
    "            coefs = self._alasso_simple(Phi, y)\n",
    "        \n",
    "        support = np.abs(coefs) > 1e-10\n",
    "        return coefs, support\n",
    "    \n",
    "    def _stlsq_simple(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simple STLSQ implementation for bootstrap.\n",
    "        \"\"\"\n",
    "        n_features = Phi.shape[1]\n",
    "        \n",
    "        # Initial OLS\n",
    "        try:\n",
    "            xi, _, _, _ = np.linalg.lstsq(Phi, y, rcond=None)\n",
    "        except np.linalg.LinAlgError:\n",
    "            return np.zeros(n_features)\n",
    "        \n",
    "        # Iterate\n",
    "        for _ in range(10):\n",
    "            support = np.abs(xi) > self.stlsq_threshold\n",
    "            if np.sum(support) == 0:\n",
    "                return np.zeros(n_features)\n",
    "            \n",
    "            xi_new = np.zeros(n_features)\n",
    "            try:\n",
    "                xi_new[support], _, _, _ = np.linalg.lstsq(\n",
    "                    Phi[:, support], y, rcond=None\n",
    "                )\n",
    "            except np.linalg.LinAlgError:\n",
    "                break\n",
    "            \n",
    "            if np.allclose(xi, xi_new):\n",
    "                break\n",
    "            xi = xi_new\n",
    "        \n",
    "        return xi\n",
    "    \n",
    "    def _alasso_simple(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simple Adaptive Lasso for bootstrap.\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import Ridge, LassoCV\n",
    "        \n",
    "        n_features = Phi.shape[1]\n",
    "        \n",
    "        # Initial estimate\n",
    "        ridge = Ridge(alpha=0.1, fit_intercept=False)\n",
    "        ridge.fit(Phi, y)\n",
    "        beta_init = ridge.coef_\n",
    "        \n",
    "        # Adaptive weights\n",
    "        eps = 1e-6\n",
    "        weights = 1.0 / (np.abs(beta_init) + eps)\n",
    "        \n",
    "        # Weighted Lasso\n",
    "        Phi_weighted = Phi / np.sqrt(weights)\n",
    "        lasso = LassoCV(cv=3, fit_intercept=False, max_iter=1000)\n",
    "        try:\n",
    "            lasso.fit(Phi_weighted, y)\n",
    "            beta = lasso.coef_ / np.sqrt(weights)\n",
    "        except Exception:\n",
    "            beta = np.zeros(n_features)\n",
    "        \n",
    "        return beta\n",
    "    \n",
    "    def _structural_uq(\n",
    "        self,\n",
    "        support_samples: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Layer 1: Structural Uncertainty via Bootstrap Inclusion Probability.\n",
    "        \n",
    "        P_j = (1/B) * sum_b I[j in support_b]\n",
    "        \n",
    "        Classification:\n",
    "            P_j > 0.9: High confidence (definitely include)\n",
    "            0.5 < P_j <= 0.9: Medium confidence (probably include)\n",
    "            P_j <= 0.5: Low confidence (consider excluding)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        support_samples : np.ndarray\n",
    "            Boolean array of shape (B, n_features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Inclusion probabilities\n",
    "        \"\"\"\n",
    "        return np.mean(support_samples, axis=0)\n",
    "    \n",
    "    def _parametric_uq(\n",
    "        self,\n",
    "        coef_samples: np.ndarray,\n",
    "        support_samples: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Layer 2: Parametric Uncertainty via Bootstrap Coefficient Distribution.\n",
    "        \n",
    "        Uses robust estimators:\n",
    "            - Point estimate: median (not mean)\n",
    "            - Standard error: MAD * 1.4826 (not SD)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        coef_samples : np.ndarray\n",
    "            Coefficient samples of shape (B, n_features)\n",
    "        support_samples : np.ndarray\n",
    "            Support indicators of shape (B, n_features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "            (estimates, ci_bounds, se)\n",
    "        \"\"\"\n",
    "        n_features = coef_samples.shape[1]\n",
    "        estimates = np.zeros(n_features)\n",
    "        se = np.zeros(n_features)\n",
    "        ci_bounds = np.zeros((n_features, 2))\n",
    "        \n",
    "        alpha = 1 - self.confidence_level\n",
    "        lower_percentile = 100 * alpha / 2\n",
    "        upper_percentile = 100 * (1 - alpha / 2)\n",
    "        \n",
    "        for j in range(n_features):\n",
    "            # Get non-zero samples\n",
    "            nonzero_mask = support_samples[:, j]\n",
    "            if np.sum(nonzero_mask) < 10:\n",
    "                continue\n",
    "            \n",
    "            samples_j = coef_samples[nonzero_mask, j]\n",
    "            \n",
    "            # Robust point estimate (median)\n",
    "            estimates[j] = np.median(samples_j)\n",
    "            \n",
    "            # Robust SE (MAD * 1.4826)\n",
    "            mad = np.median(np.abs(samples_j - estimates[j]))\n",
    "            se[j] = mad * 1.4826\n",
    "            \n",
    "            # Percentile CI\n",
    "            ci_bounds[j, 0] = np.percentile(samples_j, lower_percentile)\n",
    "            ci_bounds[j, 1] = np.percentile(samples_j, upper_percentile)\n",
    "        \n",
    "        return estimates, ci_bounds, se\n",
    "    \n",
    "    def predictive_uq(\n",
    "        self,\n",
    "        X_new: np.ndarray,\n",
    "        residual_var: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Layer 3: Predictive Uncertainty for new inputs.\n",
    "        \n",
    "        Total variance = model variance + residual variance\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_new : np.ndarray\n",
    "            New feature matrix\n",
    "        residual_var : float\n",
    "            Residual variance from training\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "            (predictions, pi_lower, pi_upper)\n",
    "        \"\"\"\n",
    "        if not self._uq_complete:\n",
    "            raise ValueError(\"Must run UQ first\")\n",
    "        \n",
    "        n_new = X_new.shape[0]\n",
    "        z = norm.ppf(1 - (1 - self.confidence_level) / 2)\n",
    "        \n",
    "        # Predictions from each bootstrap sample\n",
    "        pred_samples = np.zeros((self.n_bootstrap, n_new))\n",
    "        for b in range(self.n_bootstrap):\n",
    "            pred_samples[b] = X_new @ self._coef_samples[b]\n",
    "        \n",
    "        # Point prediction (median)\n",
    "        predictions = np.median(pred_samples, axis=0)\n",
    "        \n",
    "        # Model variance\n",
    "        model_var = np.var(pred_samples, axis=0)\n",
    "        \n",
    "        # Total variance\n",
    "        total_var = model_var + residual_var\n",
    "        total_se = np.sqrt(total_var)\n",
    "        \n",
    "        # Prediction interval\n",
    "        pi_lower = predictions - z * total_se\n",
    "        pi_upper = predictions + z * total_se\n",
    "        \n",
    "        return predictions, pi_lower, pi_upper\n",
    "    \n",
    "    def get_confidence_classification(\n",
    "        self\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Classify terms by inclusion probability.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, str]\n",
    "            Mapping from feature name to classification\n",
    "        \"\"\"\n",
    "        if self._inclusion_probs is None:\n",
    "            raise ValueError(\"Must run UQ first\")\n",
    "        \n",
    "        classification = {}\n",
    "        for name, prob in zip(self._feature_names, self._inclusion_probs):\n",
    "            if prob > 0.9:\n",
    "                classification[name] = 'high'\n",
    "            elif prob > 0.5:\n",
    "                classification[name] = 'medium'\n",
    "            else:\n",
    "                classification[name] = 'low'\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def print_uq_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed UQ report.\n",
    "        \"\"\"\n",
    "        if not self._uq_complete:\n",
    "            print(\"UQ not yet performed. Call run() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" Bootstrap Uncertainty Quantification Results\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Bootstrap samples: {self.n_bootstrap}\")\n",
    "        print(f\"  Selection method: {self.selection_method}\")\n",
    "        print(f\"  Confidence level: {self.confidence_level:.0%}\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Layer 1: Structural Uncertainty (Inclusion Probabilities)\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  {'Feature':<25} {'P(include)':<12} {'Class':<10}\")\n",
    "        print(\"  \" + \"-\" * 50)\n",
    "        \n",
    "        conf_class = self.get_confidence_classification()\n",
    "        for name, prob in zip(self._feature_names, self._inclusion_probs):\n",
    "            if prob > 0.1:  # Only show non-trivial\n",
    "                print(f\"  {name:<25} {prob:<12.3f} {conf_class[name]:<10}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Layer 2: Parametric Uncertainty (Coefficient CIs)\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  {'Feature':<20} {'Estimate':<12} {'SE':<10} {'95% CI':<20}\")\n",
    "        print(\"  \" + \"-\" * 65)\n",
    "        \n",
    "        for i, name in enumerate(self._feature_names):\n",
    "            if self._inclusion_probs[i] > 0.5:  # Only show selected\n",
    "                ci_str = f\"[{self._ci_lower[i]:.4f}, {self._ci_upper[i]:.4f}]\"\n",
    "                print(f\"  {name:<20} {self._estimates[i]:<12.4f} \"\n",
    "                      f\"{self._se[i]:<10.4f} {ci_str:<20}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STATISTICAL INFERENCE CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class StatisticalInference:\n",
    "    \"\"\"\n",
    "    Statistical Inference for Symbolic Regression Coefficients.\n",
    "    \n",
    "    Provides hypothesis testing for coefficients:\n",
    "    - H0: coefficient = 0\n",
    "    - H1: coefficient != 0\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    alpha : float\n",
    "        Significance level (default: 0.05)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> inference = StatisticalInference(alpha=0.05)\n",
    "    >>> result = inference.test_coefficients(coef_samples, feature_names)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.05):\n",
    "        \"\"\"\n",
    "        Initialize StatisticalInference.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha : float\n",
    "            Significance level. Default: 0.05\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self._test_results = None\n",
    "    \n",
    "    def test_coefficients(\n",
    "        self,\n",
    "        coef_samples: np.ndarray,\n",
    "        support_samples: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Test significance of each coefficient.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        coef_samples : np.ndarray\n",
    "            Bootstrap coefficient samples\n",
    "        support_samples : np.ndarray\n",
    "            Bootstrap support indicators\n",
    "        feature_names : List[str]\n",
    "            Feature names\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Test results for each feature\n",
    "        \"\"\"\n",
    "        n_features = coef_samples.shape[1]\n",
    "        self._test_results = {}\n",
    "        \n",
    "        for j in range(n_features):\n",
    "            name = feature_names[j]\n",
    "            \n",
    "            # Get non-zero samples\n",
    "            nonzero_mask = support_samples[:, j]\n",
    "            n_nonzero = np.sum(nonzero_mask)\n",
    "            \n",
    "            if n_nonzero < 10:\n",
    "                self._test_results[name] = {\n",
    "                    'significant': False,\n",
    "                    'p_value': 1.0,\n",
    "                    'z_stat': 0.0,\n",
    "                    'estimate': 0.0,\n",
    "                    'se': np.inf,\n",
    "                    'n_samples': int(n_nonzero)\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            samples_j = coef_samples[nonzero_mask, j]\n",
    "            result = self._hypothesis_test(samples_j)\n",
    "            result['n_samples'] = int(n_nonzero)\n",
    "            self._test_results[name] = result\n",
    "        \n",
    "        return self._test_results\n",
    "    \n",
    "    def _hypothesis_test(\n",
    "        self,\n",
    "        samples: np.ndarray\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform hypothesis test H0: mu = 0.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        samples : np.ndarray\n",
    "            Bootstrap samples\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Test result\n",
    "        \"\"\"\n",
    "        # Robust estimates\n",
    "        estimate = np.median(samples)\n",
    "        mad = np.median(np.abs(samples - estimate))\n",
    "        se = mad * 1.4826\n",
    "        \n",
    "        if se < 1e-10:\n",
    "            # Zero SE - all samples identical\n",
    "            z_stat = np.inf if abs(estimate) > 1e-10 else 0.0\n",
    "            p_value = 0.0 if abs(estimate) > 1e-10 else 1.0\n",
    "        else:\n",
    "            z_stat = estimate / se\n",
    "            p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        significant = p_value < self.alpha\n",
    "        \n",
    "        return {\n",
    "            'significant': significant,\n",
    "            'p_value': float(p_value),\n",
    "            'z_stat': float(z_stat),\n",
    "            'estimate': float(estimate),\n",
    "            'se': float(se),\n",
    "            'stars': self._format_significance_stars(p_value)\n",
    "        }\n",
    "    \n",
    "    def _format_significance_stars(\n",
    "        self,\n",
    "        p_value: float\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Format significance stars.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        p_value : float\n",
    "            P-value\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Significance stars\n",
    "        \"\"\"\n",
    "        if p_value < 0.001:\n",
    "            return '***'\n",
    "        elif p_value < 0.01:\n",
    "            return '**'\n",
    "        elif p_value < 0.05:\n",
    "            return '*'\n",
    "        elif p_value < 0.1:\n",
    "            return '.'\n",
    "        else:\n",
    "            return ''\n",
    "    \n",
    "    def print_inference_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print inference report.\n",
    "        \"\"\"\n",
    "        if self._test_results is None:\n",
    "            print(\"No test results. Call test_coefficients() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" Statistical Inference Results\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Significance level: alpha = {self.alpha}\")\n",
    "        print()\n",
    "        print(f\"{'Feature':<20} {'Estimate':<10} {'SE':<10} {'z':<8} {'p-value':<10} {'Sig'}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for name, result in self._test_results.items():\n",
    "            if result['n_samples'] >= 10:\n",
    "                print(f\"{name:<20} {result['estimate']:<10.4f} {result['se']:<10.4f} \"\n",
    "                      f\"{result['z_stat']:<8.2f} {result['p_value']:<10.4f} {result['stars']}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 11_UQ_Inference\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Structural UQ - Inclusion Probabilities\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Structural UQ - Inclusion Probabilities\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    # True model: y = 2*x1 + x2\n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    x3 = np.random.randn(n_samples)  # noise\n",
    "    \n",
    "    y = 2*x1 + x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x1, x2, x3])\n",
    "    feature_names = ['1', 'x1', 'x2', 'x3']\n",
    "    \n",
    "    print(f\"True model: y = 2*x1 + x2\")\n",
    "    print(f\"Expected: x1, x2 have high inclusion prob, x3 has low\")\n",
    "    print()\n",
    "    \n",
    "    uq = BootstrapUQ(n_bootstrap=50, stlsq_threshold=0.1)\n",
    "    result = uq.run(Phi, y, feature_names)\n",
    "    \n",
    "    print(f\"Inclusion probabilities:\")\n",
    "    for name, prob in zip(feature_names, result['inclusion_probs']):\n",
    "        print(f\"  {name}: {prob:.3f}\")\n",
    "    \n",
    "    # Check x1, x2 have higher prob than x3\n",
    "    if (result['inclusion_probs'][1] > 0.8 and \n",
    "        result['inclusion_probs'][2] > 0.8 and\n",
    "        result['inclusion_probs'][3] < 0.5):\n",
    "        print(\"\\n[PASS] True terms have high inclusion probability\")\n",
    "    else:\n",
    "        print(\"\\n[INFO] Check inclusion probabilities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Parametric UQ - Coefficient CIs\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: Parametric UQ - Coefficient CIs\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 300\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    \n",
    "    # True: y = 3*x1 + 1.5*x2\n",
    "    true_coefs = [0, 3.0, 1.5]  # intercept=0\n",
    "    y = 3*x1 + 1.5*x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x1, x2])\n",
    "    feature_names = ['1', 'x1', 'x2']\n",
    "    \n",
    "    print(f\"True coefficients: 1=0, x1=3.0, x2=1.5\")\n",
    "    print()\n",
    "    \n",
    "    uq = BootstrapUQ(n_bootstrap=100)\n",
    "    result = uq.run(Phi, y, feature_names)\n",
    "    \n",
    "    print(f\"{'Feature':<10} {'True':<10} {'Estimate':<10} {'95% CI':<25} {'Covered'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, (name, true) in enumerate(zip(feature_names, true_coefs)):\n",
    "        est = result['estimates'][i]\n",
    "        ci_l = result['ci_lower'][i]\n",
    "        ci_u = result['ci_upper'][i]\n",
    "        covered = ci_l <= true <= ci_u\n",
    "        print(f\"{name:<10} {true:<10.2f} {est:<10.4f} [{ci_l:.4f}, {ci_u:.4f}] {covered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: Predictive UQ - Prediction Intervals\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: Predictive UQ - Prediction Intervals\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_train = 200\n",
    "    n_test = 100\n",
    "    \n",
    "    # Training data\n",
    "    x1_train = np.random.randn(n_train)\n",
    "    y_train = 2*x1_train + 0.5*np.random.randn(n_train)\n",
    "    Phi_train = np.column_stack([np.ones(n_train), x1_train])\n",
    "    \n",
    "    # Test data\n",
    "    x1_test = np.random.randn(n_test)\n",
    "    y_test = 2*x1_test + 0.5*np.random.randn(n_test)\n",
    "    Phi_test = np.column_stack([np.ones(n_test), x1_test])\n",
    "    \n",
    "    feature_names = ['1', 'x1']\n",
    "    \n",
    "    # Run UQ\n",
    "    uq = BootstrapUQ(n_bootstrap=100)\n",
    "    result = uq.run(Phi_train, y_train, feature_names)\n",
    "    \n",
    "    # Compute residual variance\n",
    "    y_train_pred = Phi_train @ result['estimates']\n",
    "    residual_var = np.var(y_train - y_train_pred)\n",
    "    \n",
    "    # Predictive UQ\n",
    "    pred, pi_lower, pi_upper = uq.predictive_uq(Phi_test, residual_var)\n",
    "    \n",
    "    # Check coverage\n",
    "    in_interval = (y_test >= pi_lower) & (y_test <= pi_upper)\n",
    "    coverage = np.mean(in_interval)\n",
    "    \n",
    "    print(f\"Expected coverage: 95%\")\n",
    "    print(f\"Actual coverage: {coverage:.1%}\")\n",
    "    print(f\"Residual variance: {residual_var:.4f}\")\n",
    "    \n",
    "    if 0.85 <= coverage <= 0.99:\n",
    "        print(\"[PASS] Coverage near nominal level\")\n",
    "    else:\n",
    "        print(f\"[INFO] Coverage: {coverage:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: Hypothesis Testing\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: Hypothesis Testing\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    x3 = np.random.randn(n_samples)  # Not in true model\n",
    "    \n",
    "    y = 5*x1 + 2*x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([x1, x2, x3])\n",
    "    feature_names = ['x1', 'x2', 'x3']\n",
    "    \n",
    "    print(f\"True: y = 5*x1 + 2*x2 (x3 has zero coefficient)\")\n",
    "    print()\n",
    "    \n",
    "    # Run UQ\n",
    "    uq = BootstrapUQ(n_bootstrap=100)\n",
    "    result = uq.run(Phi, y, feature_names)\n",
    "    \n",
    "    # Statistical inference\n",
    "    inference = StatisticalInference(alpha=0.05)\n",
    "    test_results = inference.test_coefficients(\n",
    "        result['coef_samples'],\n",
    "        result['support_samples'],\n",
    "        feature_names\n",
    "    )\n",
    "    \n",
    "    inference.print_inference_report()\n",
    "    \n",
    "    # x1, x2 should be significant, x3 should not\n",
    "    if (test_results['x1']['significant'] and \n",
    "        test_results['x2']['significant'] and \n",
    "        not test_results['x3']['significant']):\n",
    "        print(\"\\n[PASS] Correct significance detection\")\n",
    "    else:\n",
    "        print(\"\\n[INFO] Check significance results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 11_UQ_Inference.ipynb - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASSES:\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"1. BootstrapUQ\")\n",
    "print(\"   Purpose: Three-layer uncertainty quantification\")\n",
    "print(\"   Main Methods:\")\n",
    "print(\"     run(Phi, y, feature_names) - Run full bootstrap UQ\")\n",
    "print(\"     predictive_uq(X_new, residual_var) - Prediction intervals\")\n",
    "print(\"     get_confidence_classification() - Term classification\")\n",
    "print(\"     print_uq_report() - Detailed report\")\n",
    "print()\n",
    "print(\"2. StatisticalInference\")\n",
    "print(\"   Purpose: Hypothesis testing for coefficients\")\n",
    "print(\"   Main Methods:\")\n",
    "print(\"     test_coefficients(coef_samples, support_samples, names)\")\n",
    "print(\"     print_inference_report() - Significance table\")\n",
    "print()\n",
    "print(\"Three Layers of UQ:\")\n",
    "print(\"  Layer 1: Structural - Which terms to include?\")\n",
    "print(\"  Layer 2: Parametric - What are coefficient values?\")\n",
    "print(\"  Layer 3: Predictive - How uncertain are predictions?\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Run bootstrap UQ\n",
    "uq = BootstrapUQ(n_bootstrap=200)\n",
    "result = uq.run(Phi, y, feature_names)\n",
    "\n",
    "# Check inclusion probabilities\n",
    "print(result['inclusion_probs'])\n",
    "\n",
    "# Get coefficient CIs\n",
    "print(f\"Estimates: {result['estimates']}\")\n",
    "print(f\"95% CI: [{result['ci_lower']}, {result['ci_upper']}]\")\n",
    "\n",
    "# Statistical inference\n",
    "inference = StatisticalInference()\n",
    "tests = inference.test_coefficients(\n",
    "    result['coef_samples'], result['support_samples'], feature_names\n",
    ")\n",
    "inference.print_inference_report()\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 11_UQ_Inference.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

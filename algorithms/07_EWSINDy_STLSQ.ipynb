{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07_EWSINDy_STLSQ - Physics-SR Framework v3.0\n",
    "\n",
    "## Stage 2.2b: E-WSINDy with STLSQ (Weak-form Sparse Regression)\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Noise-robust equation discovery via weak-form sparse regression. This approach transfers derivatives from noisy data to smooth test functions, achieving 50-1000x noise improvement.\n",
    "\n",
    "### Weak Form Theory\n",
    "\n",
    "**Strong form** (noise-sensitive):\n",
    "$$\\frac{\\partial q}{\\partial t} = f(q, \\nabla q, \\nabla^2 q)$$\n",
    "\n",
    "**Weak form** (noise-robust): Multiply by test function $\\psi$ and integrate by parts:\n",
    "$$\\int \\psi \\cdot \\nabla^2 q \\, dx = -\\int \\nabla\\psi \\cdot \\nabla q \\, dx + \\text{boundary terms}$$\n",
    "\n",
    "**Result:** Derivatives transferred from noisy data $q$ to smooth test function $\\psi$.\n",
    "\n",
    "### Noise Improvement\n",
    "\n",
    "- Strong form variance: $\\text{Var}(\\dot{x}_{FD}) = \\frac{2\\sigma^2}{h^2}$\n",
    "- Weak form variance: $\\text{Var}(b) = \\sigma^2 \\|\\dot{\\psi}\\|_2^2$\n",
    "- **Improvement factor: 50-1000x**\n",
    "\n",
    "### STLSQ Algorithm\n",
    "\n",
    "Sequentially Thresholded Least Squares achieves **exact sparsity** (true zeros) unlike LASSO:\n",
    "\n",
    "1. Initialize with OLS solution\n",
    "2. Threshold small coefficients to zero\n",
    "3. Refit OLS on remaining support\n",
    "4. Repeat until convergence\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Messenger, D. A., & Bortz, D. M. (2021). Weak SINDy for partial differential equations. *Journal of Computational Physics*, 443, 110525.\n",
    "- Brunton, S. L., et al. (2016). Discovering governing equations from data by sparse identification of nonlinear dynamical systems. *PNAS*, 113(15), 3932-3937."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "07_EWSINDy_STLSQ.ipynb - Ensemble Weak-form SINDy with STLSQ\n",
    "=============================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v3.0\n",
    "\n",
    "This module provides:\n",
    "- EWSINDySTLSQ: Weak-form SINDy with STLSQ sparse regression\n",
    "- Gaussian bump test functions for weak form transformation\n",
    "- 50-1000x noise robustness improvement over finite differences\n",
    "- Exact sparsity (true zeros) via iterative thresholding\n",
    "\n",
    "Algorithm:\n",
    "    1. Generate smooth test functions (Gaussian bumps)\n",
    "    2. Apply weak form transformation via numerical integration\n",
    "    3. Run STLSQ: threshold -> refit -> repeat\n",
    "    4. Return sparse coefficient vector\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for E-WSINDy\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "print(\"07_EWSINDy_STLSQ: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# E-WSINDY STLSQ CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class EWSINDySTLSQ:\n",
    "    \"\"\"\n",
    "    Ensemble Weak-form SINDy with STLSQ.\n",
    "    \n",
    "    Implements noise-robust equation discovery via:\n",
    "    1. Weak form transformation (transfers derivatives to smooth test functions)\n",
    "    2. STLSQ sparse regression (achieves exact sparsity)\n",
    "    \n",
    "    The weak form provides 50-1000x noise improvement by avoiding direct\n",
    "    differentiation of noisy data. STLSQ provides unbiased coefficient\n",
    "    estimates with exact zeros (unlike LASSO which has shrinkage bias).\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    threshold : float\n",
    "        STLSQ sparsity threshold (default: 0.1)\n",
    "    max_iter : int\n",
    "        Maximum STLSQ iterations (default: 20)\n",
    "    n_test_functions : int\n",
    "        Number of test functions (default: 50)\n",
    "    test_function_type : str\n",
    "        Type of test function: 'gaussian' or 'polynomial'\n",
    "    test_function_width : float\n",
    "        Width parameter for test functions (default: 0.1)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = EWSINDySTLSQ(threshold=0.1)\n",
    "    >>> result = model.fit(feature_library, y, feature_names=names)\n",
    "    >>> print(result['equation'])\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold: float = DEFAULT_STLSQ_THRESHOLD,\n",
    "        max_iter: int = DEFAULT_STLSQ_MAX_ITER,\n",
    "        n_test_functions: int = 50,\n",
    "        test_function_type: str = 'gaussian',\n",
    "        test_function_width: float = 0.1,\n",
    "        use_weak_form: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize EWSINDySTLSQ.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        threshold : float\n",
    "            Coefficients with |value| < threshold are set to zero.\n",
    "            Default: 0.1\n",
    "        max_iter : int\n",
    "            Maximum number of STLSQ iterations.\n",
    "            Default: 20\n",
    "        n_test_functions : int\n",
    "            Number of test functions for weak form.\n",
    "            Default: 50\n",
    "        test_function_type : str\n",
    "            'gaussian' for Gaussian bumps, 'polynomial' for polynomial.\n",
    "            Default: 'gaussian'\n",
    "        test_function_width : float\n",
    "            Width of Gaussian bumps (as fraction of domain).\n",
    "            Default: 0.1\n",
    "        use_weak_form : bool\n",
    "            Whether to use weak form (True) or standard form (False).\n",
    "            Default: True\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.max_iter = max_iter\n",
    "        self.n_test_functions = n_test_functions\n",
    "        self.test_function_type = test_function_type\n",
    "        self.test_function_width = test_function_width\n",
    "        self.use_weak_form = use_weak_form\n",
    "        \n",
    "        # Internal state\n",
    "        self._coefficients = None\n",
    "        self._support = None\n",
    "        self._feature_names = None\n",
    "        self._n_features = None\n",
    "        self._n_iterations = 0\n",
    "        self._convergence_history = []\n",
    "        self._fit_complete = False\n",
    "        self._r2_score = None\n",
    "        self._mse = None\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        t: np.ndarray = None,\n",
    "        feature_names: List[str] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fit the E-WSINDy model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_library : np.ndarray\n",
    "            Feature library matrix of shape (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector of shape (n_samples,)\n",
    "        t : np.ndarray, optional\n",
    "            Time vector. If None, uses uniform spacing.\n",
    "        feature_names : List[str], optional\n",
    "            Names of features in library\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Dictionary containing:\n",
    "            - coefficients: Sparse coefficient vector\n",
    "            - support: Boolean mask of active terms\n",
    "            - equation: String representation of equation\n",
    "            - n_active_terms: Number of non-zero coefficients\n",
    "            - n_iterations: Number of STLSQ iterations\n",
    "            - r2_score: R-squared on training data\n",
    "            - mse: Mean squared error\n",
    "        \"\"\"\n",
    "        n_samples, n_features = feature_library.shape\n",
    "        self._n_features = n_features\n",
    "        \n",
    "        # Set feature names\n",
    "        if feature_names is None:\n",
    "            self._feature_names = [f'f{i}' for i in range(n_features)]\n",
    "        else:\n",
    "            self._feature_names = list(feature_names)\n",
    "        \n",
    "        # Generate time vector if not provided\n",
    "        if t is None:\n",
    "            t = self._generate_time_vector(n_samples)\n",
    "        \n",
    "        # Apply weak form transformation if enabled\n",
    "        if self.use_weak_form:\n",
    "            Q, b = self._weak_form_transform(feature_library, y, t)\n",
    "        else:\n",
    "            # Standard form: direct regression\n",
    "            Q = feature_library\n",
    "            b = y\n",
    "        \n",
    "        # Run STLSQ\n",
    "        self._coefficients = self._stlsq_iteration(Q, b)\n",
    "        self._support = np.abs(self._coefficients) > 0\n",
    "        \n",
    "        # Compute metrics\n",
    "        y_pred = feature_library @ self._coefficients\n",
    "        self._mse = np.mean((y - y_pred)**2)\n",
    "        ss_tot = np.sum((y - np.mean(y))**2)\n",
    "        ss_res = np.sum((y - y_pred)**2)\n",
    "        self._r2_score = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "        \n",
    "        self._fit_complete = True\n",
    "        \n",
    "        return {\n",
    "            'coefficients': self._coefficients,\n",
    "            'support': self._support,\n",
    "            'equation': self.get_equation(),\n",
    "            'n_active_terms': int(np.sum(self._support)),\n",
    "            'n_iterations': self._n_iterations,\n",
    "            'r2_score': self._r2_score,\n",
    "            'mse': self._mse,\n",
    "            'convergence_history': self._convergence_history,\n",
    "            'threshold': self.threshold\n",
    "        }\n",
    "    \n",
    "    def _generate_time_vector(\n",
    "        self,\n",
    "        n_samples: int\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate uniform time vector.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of samples\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Time vector from 0 to 1\n",
    "        \"\"\"\n",
    "        return np.linspace(0, 1, n_samples)\n",
    "    \n",
    "    def _generate_test_functions(\n",
    "        self,\n",
    "        t: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate test functions and their derivatives.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t : np.ndarray\n",
    "            Time vector\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            - psi: Test functions of shape (n_test, n_samples)\n",
    "            - dpsi: Derivatives of shape (n_test, n_samples)\n",
    "        \"\"\"\n",
    "        n_samples = len(t)\n",
    "        t_min, t_max = t.min(), t.max()\n",
    "        t_range = t_max - t_min\n",
    "        \n",
    "        # Centers for test functions (avoid boundaries)\n",
    "        centers = np.linspace(\n",
    "            t_min + 0.1 * t_range,\n",
    "            t_max - 0.1 * t_range,\n",
    "            self.n_test_functions\n",
    "        )\n",
    "        \n",
    "        width = self.test_function_width * t_range\n",
    "        \n",
    "        psi = np.zeros((self.n_test_functions, n_samples))\n",
    "        dpsi = np.zeros((self.n_test_functions, n_samples))\n",
    "        \n",
    "        for m, center in enumerate(centers):\n",
    "            if self.test_function_type == 'gaussian':\n",
    "                psi[m], dpsi[m] = self._gaussian_bump(t, center, width)\n",
    "            else:\n",
    "                psi[m], dpsi[m] = self._polynomial_bump(t, center, width)\n",
    "        \n",
    "        return psi, dpsi\n",
    "    \n",
    "    def _gaussian_bump(\n",
    "        self,\n",
    "        t: np.ndarray,\n",
    "        center: float,\n",
    "        width: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate Gaussian bump test function.\n",
    "        \n",
    "        psi(t) = exp(-(t - center)^2 / (2 * width^2))\n",
    "        dpsi(t) = -(t - center) / width^2 * psi(t)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t : np.ndarray\n",
    "            Time vector\n",
    "        center : float\n",
    "            Center of Gaussian\n",
    "        width : float\n",
    "            Width (standard deviation)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (psi, dpsi)\n",
    "        \"\"\"\n",
    "        z = (t - center) / width\n",
    "        psi = np.exp(-0.5 * z**2)\n",
    "        dpsi = -z / width * psi\n",
    "        return psi, dpsi\n",
    "    \n",
    "    def _polynomial_bump(\n",
    "        self,\n",
    "        t: np.ndarray,\n",
    "        center: float,\n",
    "        width: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate polynomial bump test function.\n",
    "        \n",
    "        Uses (1 - ((t-center)/width)^2)^4 for compact support.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t : np.ndarray\n",
    "            Time vector\n",
    "        center : float\n",
    "            Center of bump\n",
    "        width : float\n",
    "            Half-width of support\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (psi, dpsi)\n",
    "        \"\"\"\n",
    "        z = (t - center) / width\n",
    "        mask = np.abs(z) < 1\n",
    "        \n",
    "        psi = np.zeros_like(t)\n",
    "        dpsi = np.zeros_like(t)\n",
    "        \n",
    "        psi[mask] = (1 - z[mask]**2)**4\n",
    "        dpsi[mask] = -8 * z[mask] / width * (1 - z[mask]**2)**3\n",
    "        \n",
    "        return psi, dpsi\n",
    "    \n",
    "    def _weak_form_transform(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        t: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Apply weak form transformation.\n",
    "        \n",
    "        Q[m,k] = integral(psi_m * Phi_k) dt\n",
    "        b[m] = -integral(dpsi_m * y) dt  (integration by parts)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature library (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector (n_samples,)\n",
    "        t : np.ndarray\n",
    "            Time vector (n_samples,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (Q, b) - Weak form matrices\n",
    "        \"\"\"\n",
    "        n_samples, n_features = Phi.shape\n",
    "        \n",
    "        # Generate test functions\n",
    "        psi, dpsi = self._generate_test_functions(t)\n",
    "        \n",
    "        # Compute weak form matrices via numerical integration\n",
    "        Q = np.zeros((self.n_test_functions, n_features))\n",
    "        b = np.zeros(self.n_test_functions)\n",
    "        \n",
    "        dt = t[1] - t[0] if len(t) > 1 else 1.0\n",
    "        \n",
    "        for m in range(self.n_test_functions):\n",
    "            # Q[m, k] = integral(psi_m * Phi_k)\n",
    "            for k in range(n_features):\n",
    "                Q[m, k] = np.trapz(psi[m] * Phi[:, k], t)\n",
    "            \n",
    "            # b[m] = -integral(dpsi_m * y) (integration by parts)\n",
    "            b[m] = -np.trapz(dpsi[m] * y, t)\n",
    "        \n",
    "        return Q, b\n",
    "    \n",
    "    def _stlsq_iteration(\n",
    "        self,\n",
    "        Q: np.ndarray,\n",
    "        b: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Sequentially Thresholded Least Squares (STLSQ).\n",
    "        \n",
    "        Algorithm:\n",
    "            1. Initialize with OLS solution\n",
    "            2. Threshold small coefficients to zero\n",
    "            3. Refit OLS on remaining support\n",
    "            4. Repeat until convergence\n",
    "        \n",
    "        This achieves exact sparsity (true zeros) unlike LASSO.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Q : np.ndarray\n",
    "            Design matrix (n_equations, n_features)\n",
    "        b : np.ndarray\n",
    "            Target vector (n_equations,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Sparse coefficient vector\n",
    "        \"\"\"\n",
    "        n_features = Q.shape[1]\n",
    "        self._convergence_history = []\n",
    "        \n",
    "        # Step 1: Initialize with regularized OLS (for stability)\n",
    "        try:\n",
    "            # Use Ridge regression for initial estimate\n",
    "            ridge = Ridge(alpha=1e-6, fit_intercept=False)\n",
    "            ridge.fit(Q, b)\n",
    "            xi = ridge.coef_\n",
    "        except Exception:\n",
    "            xi = np.linalg.lstsq(Q, b, rcond=None)[0]\n",
    "        \n",
    "        self._convergence_history.append(xi.copy())\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            xi_old = xi.copy()\n",
    "            \n",
    "            # Step 2: Threshold small coefficients\n",
    "            support = np.abs(xi) > self.threshold\n",
    "            \n",
    "            if np.sum(support) == 0:\n",
    "                # All coefficients below threshold - return zeros\n",
    "                self._n_iterations = iteration + 1\n",
    "                return np.zeros(n_features)\n",
    "            \n",
    "            # Step 3: Refit on support (unbiased estimate)\n",
    "            Q_support = Q[:, support]\n",
    "            try:\n",
    "                xi_support = np.linalg.lstsq(Q_support, b, rcond=None)[0]\n",
    "            except np.linalg.LinAlgError:\n",
    "                # Singular matrix - use Ridge\n",
    "                ridge = Ridge(alpha=1e-6, fit_intercept=False)\n",
    "                ridge.fit(Q_support, b)\n",
    "                xi_support = ridge.coef_\n",
    "            \n",
    "            # Update full coefficient vector\n",
    "            xi = np.zeros(n_features)\n",
    "            xi[support] = xi_support\n",
    "            \n",
    "            self._convergence_history.append(xi.copy())\n",
    "            \n",
    "            # Check convergence\n",
    "            if np.allclose(xi, xi_old, rtol=1e-6, atol=1e-10):\n",
    "                self._n_iterations = iteration + 1\n",
    "                break\n",
    "        else:\n",
    "            self._n_iterations = self.max_iter\n",
    "        \n",
    "        return xi\n",
    "    \n",
    "    def get_equation(\n",
    "        self,\n",
    "        feature_names: List[str] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get string representation of discovered equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_names : List[str], optional\n",
    "            Feature names to use (defaults to stored names)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Equation string\n",
    "        \"\"\"\n",
    "        if self._coefficients is None:\n",
    "            return \"\"\n",
    "        \n",
    "        names = feature_names or self._feature_names\n",
    "        \n",
    "        terms = []\n",
    "        for i, (coef, name) in enumerate(zip(self._coefficients, names)):\n",
    "            if abs(coef) > 1e-10:  # Non-zero coefficient\n",
    "                if coef >= 0 and len(terms) > 0:\n",
    "                    terms.append(f\"+ {coef:.6f}*{name}\")\n",
    "                else:\n",
    "                    terms.append(f\"{coef:.6f}*{name}\")\n",
    "        \n",
    "        if len(terms) == 0:\n",
    "            return \"0\"\n",
    "        \n",
    "        return \" \".join(terms)\n",
    "    \n",
    "    def predict(\n",
    "        self,\n",
    "        Phi_new: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using discovered equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi_new : np.ndarray\n",
    "            Feature library for new data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Predictions\n",
    "        \"\"\"\n",
    "        if self._coefficients is None:\n",
    "            raise ValueError(\"Must call fit() before predict()\")\n",
    "        return Phi_new @ self._coefficients\n",
    "    \n",
    "    def get_active_terms(\n",
    "        self\n",
    "    ) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get list of active terms with coefficients.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[str, float]]\n",
    "            List of (name, coefficient) tuples for active terms\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            raise ValueError(\"Must call fit() first\")\n",
    "        \n",
    "        active = []\n",
    "        for i, (coef, name) in enumerate(zip(self._coefficients, self._feature_names)):\n",
    "            if self._support[i]:\n",
    "                active.append((name, float(coef)))\n",
    "        \n",
    "        return active\n",
    "    \n",
    "    def print_stlsq_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed STLSQ report.\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            print(\"Fit not yet performed. Call fit() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" E-WSINDy STLSQ Results\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Threshold: {self.threshold}\")\n",
    "        print(f\"  Max iterations: {self.max_iter}\")\n",
    "        print(f\"  Test functions: {self.n_test_functions}\")\n",
    "        print(f\"  Test function type: {self.test_function_type}\")\n",
    "        print(f\"  Weak form: {self.use_weak_form}\")\n",
    "        print()\n",
    "        print(f\"Results:\")\n",
    "        print(f\"  Iterations: {self._n_iterations}\")\n",
    "        print(f\"  Active terms: {int(np.sum(self._support))} / {self._n_features}\")\n",
    "        print(f\"  R-squared: {self._r2_score:.6f}\")\n",
    "        print(f\"  MSE: {self._mse:.6e}\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Discovered Equation:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  {self.get_equation()}\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Active Terms:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  {'Term':<30} {'Coefficient':<15}\")\n",
    "        print(\"  \" + \"-\" * 45)\n",
    "        for name, coef in self.get_active_terms():\n",
    "            print(f\"  {name:<30} {coef:<15.6f}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 07_EWSINDy_STLSQ\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Clean Data Recovery\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Clean Data Recovery\")\n",
    "    \n",
    "    # Generate data with known sparse solution\n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    \n",
    "    # True equation: y = 2*x + 0.5*x^2 (sparse: 2 out of many terms)\n",
    "    y = 2*x + 0.5*x**2\n",
    "    \n",
    "    # Build feature library\n",
    "    Phi = np.column_stack([\n",
    "        np.ones(n_samples),  # 1\n",
    "        x,                    # x\n",
    "        x**2,                 # x^2\n",
    "        x**3,                 # x^3\n",
    "        np.sin(x)             # sin(x)\n",
    "    ])\n",
    "    feature_names = ['1', 'x', 'x^2', 'x^3', 'sin(x)']\n",
    "    \n",
    "    print(f\"True equation: y = 2*x + 0.5*x^2\")\n",
    "    print(f\"Library: {feature_names}\")\n",
    "    print()\n",
    "    \n",
    "    # Fit with standard form (no weak form for static data)\n",
    "    model = EWSINDySTLSQ(\n",
    "        threshold=0.1,\n",
    "        use_weak_form=False  # Static data, not time series\n",
    "    )\n",
    "    result = model.fit(Phi, y, feature_names=feature_names)\n",
    "    \n",
    "    print(f\"Discovered: {result['equation']}\")\n",
    "    print(f\"Active terms: {result['n_active_terms']}\")\n",
    "    print(f\"R-squared: {result['r2_score']:.6f}\")\n",
    "    \n",
    "    # Check if correct terms were identified\n",
    "    active = model.get_active_terms()\n",
    "    active_names = [name for name, _ in active]\n",
    "    \n",
    "    if 'x' in active_names and 'x^2' in active_names:\n",
    "        print(\"[PASS] Correct sparse structure recovered\")\n",
    "    else:\n",
    "        print(f\"[INFO] Active terms: {active_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Noise Robustness\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: Noise Robustness\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 300\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    y_true = 1.5*x + 0.8*x**2\n",
    "    \n",
    "    Phi = np.column_stack([\n",
    "        np.ones(n_samples),\n",
    "        x,\n",
    "        x**2,\n",
    "        x**3\n",
    "    ])\n",
    "    feature_names = ['1', 'x', 'x^2', 'x^3']\n",
    "    \n",
    "    noise_levels = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    print(f\"True equation: y = 1.5*x + 0.8*x^2\")\n",
    "    print(f\"{'Noise':<10} {'R2':<10} {'Active':<10} {'Equation'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for noise in noise_levels:\n",
    "        y = y_true + noise * np.std(y_true) * np.random.randn(n_samples)\n",
    "        \n",
    "        model = EWSINDySTLSQ(\n",
    "            threshold=0.1,\n",
    "            use_weak_form=False\n",
    "        )\n",
    "        result = model.fit(Phi, y, feature_names=feature_names)\n",
    "        \n",
    "        eq = result['equation'][:40] + \"...\" if len(result['equation']) > 40 else result['equation']\n",
    "        print(f\"{noise:<10.2f} {result['r2_score']:<10.4f} {result['n_active_terms']:<10} {eq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: STLSQ Convergence\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: STLSQ Convergence\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 3*x + 2*x**2 + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x, x**2, x**3, x**4])\n",
    "    feature_names = ['1', 'x', 'x^2', 'x^3', 'x^4']\n",
    "    \n",
    "    model = EWSINDySTLSQ(threshold=0.1, max_iter=20, use_weak_form=False)\n",
    "    result = model.fit(Phi, y, feature_names=feature_names)\n",
    "    \n",
    "    print(f\"Converged in {result['n_iterations']} iterations\")\n",
    "    print()\n",
    "    print(\"Coefficient evolution:\")\n",
    "    print(f\"{'Iter':<6} {'1':<10} {'x':<10} {'x^2':<10} {'x^3':<10} {'x^4':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, coefs in enumerate(result['convergence_history'][:5]):\n",
    "        print(f\"{i:<6} {coefs[0]:<10.4f} {coefs[1]:<10.4f} {coefs[2]:<10.4f} {coefs[3]:<10.4f} {coefs[4]:<10.4f}\")\n",
    "    \n",
    "    if result['n_iterations'] < model.max_iter:\n",
    "        print(f\"\\n[PASS] STLSQ converged before max iterations\")\n",
    "    else:\n",
    "        print(f\"\\n[INFO] Reached max iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: Threshold Sensitivity\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: Threshold Sensitivity\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 2*x + 0.5*x**2 + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x, x**2, x**3])\n",
    "    feature_names = ['1', 'x', 'x^2', 'x^3']\n",
    "    \n",
    "    thresholds = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "    \n",
    "    print(f\"True: y = 2*x + 0.5*x^2\")\n",
    "    print(f\"{'Threshold':<12} {'Active':<10} {'R2':<10} {'Equation'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        model = EWSINDySTLSQ(threshold=thresh, use_weak_form=False)\n",
    "        result = model.fit(Phi, y, feature_names=feature_names)\n",
    "        \n",
    "        eq = result['equation'][:30] if len(result['equation']) > 30 else result['equation']\n",
    "        print(f\"{thresh:<12.2f} {result['n_active_terms']:<10} {result['r2_score']:<10.4f} {eq}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Note: Threshold 0.05-0.1 typically works well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Comparison with LASSO\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 5: STLSQ vs LASSO\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 2*x + 0.5*x**2 + 0.05*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x, x**2, x**3])\n",
    "    feature_names = ['1', 'x', 'x^2', 'x^3']\n",
    "    \n",
    "    print(f\"True: y = 2*x + 0.5*x^2\")\n",
    "    print()\n",
    "    \n",
    "    # STLSQ\n",
    "    stlsq = EWSINDySTLSQ(threshold=0.1, use_weak_form=False)\n",
    "    stlsq_result = stlsq.fit(Phi, y, feature_names=feature_names)\n",
    "    \n",
    "    # LASSO\n",
    "    lasso = Lasso(alpha=0.01, fit_intercept=False)\n",
    "    lasso.fit(Phi, y)\n",
    "    \n",
    "    print(f\"STLSQ coefficients: {stlsq._coefficients}\")\n",
    "    print(f\"LASSO coefficients: {lasso.coef_}\")\n",
    "    print()\n",
    "    print(f\"STLSQ exact zeros: {np.sum(stlsq._coefficients == 0)}\")\n",
    "    print(f\"LASSO small (<0.01): {np.sum(np.abs(lasso.coef_) < 0.01)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"[INFO] STLSQ achieves exact zeros, LASSO has shrinkage bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 07_EWSINDy_STLSQ.ipynb - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: EWSINDySTLSQ\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Noise-robust equation discovery via weak-form sparse regression.\")\n",
    "print(\"  Achieves 50-1000x noise improvement over finite differences.\")\n",
    "print(\"  Uses STLSQ for exact sparsity (true zeros).\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  fit(feature_library, y, t=None, feature_names=None)\")\n",
    "print(\"      Fit sparse regression model\")\n",
    "print(\"      Returns: dict with coefficients, equation, metrics\")\n",
    "print()\n",
    "print(\"  get_equation()\")\n",
    "print(\"      Get string representation of discovered equation\")\n",
    "print()\n",
    "print(\"  predict(Phi_new)\")\n",
    "print(\"      Make predictions using discovered equation\")\n",
    "print()\n",
    "print(\"  get_active_terms()\")\n",
    "print(\"      Get list of active terms with coefficients\")\n",
    "print()\n",
    "print(\"  print_stlsq_report()\")\n",
    "print(\"      Print detailed results report\")\n",
    "print()\n",
    "print(\"Key Parameters:\")\n",
    "print(\"  threshold: STLSQ sparsity threshold (default: 0.1)\")\n",
    "print(\"  use_weak_form: Enable weak form (True for time series)\")\n",
    "print(\"  n_test_functions: Number of test functions (default: 50)\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Build feature library (from 05_FeatureLibrary)\n",
    "builder = FeatureLibraryBuilder(max_poly_degree=3)\n",
    "Phi, names = builder.build(X, feature_names)\n",
    "\n",
    "# Fit E-WSINDy with STLSQ\n",
    "model = EWSINDySTLSQ(\n",
    "    threshold=0.1,\n",
    "    use_weak_form=False  # Set True for time series\n",
    ")\n",
    "result = model.fit(Phi, y, feature_names=names)\n",
    "\n",
    "print(f\"Equation: {result['equation']}\")\n",
    "print(f\"R-squared: {result['r2_score']:.4f}\")\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 07_EWSINDy_STLSQ.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

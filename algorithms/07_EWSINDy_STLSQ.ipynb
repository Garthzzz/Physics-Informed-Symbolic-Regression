{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07_EWSINDy_STLSQ - Physics-SR Framework v4.1\n",
    "\n",
    "## Stage 2.4: E-WSINDy Sparse Selection on Augmented Library\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (Structure-Guided Feature Library Enhancement + Computational Optimization)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Noise-robust equation discovery via weak-form sparse regression on augmented library.\n",
    "This is a **MODIFIED** module for v4.1 with source attribution.\n",
    "\n",
    "### v4.1 Modifications\n",
    "\n",
    "| Feature | v3.0 | v4.1 |\n",
    "|---------|------|------|\n",
    "| Input library | Standard | Augmented with source tags |\n",
    "| Source tracking | None | analyze_selection_sources() |\n",
    "| Output | Basic | + selection_analysis |\n",
    "| Column normalization | Fixed | normalize_columns parameter |\n",
    "\n",
    "### Weak Form Theory\n",
    "\n",
    "**Strong form** (noise-sensitive):\n",
    "$$\\frac{\\partial q}{\\partial t} = f(q, \\nabla q, \\nabla^2 q)$$\n",
    "\n",
    "**Weak form** (noise-robust): Multiply by test function $\\psi$ and integrate by parts:\n",
    "$$\\int \\psi \\cdot \\nabla^2 q \\, dx = -\\int \\nabla\\psi \\cdot \\nabla q \\, dx + \\text{boundary terms}$$\n",
    "\n",
    "**Result:** Derivatives transferred from noisy data $q$ to smooth test function $\\psi$.\n",
    "\n",
    "### Key Properties of v4.0/v4.1 Design\n",
    "\n",
    "1. **Can KEEP correct PySR terms:** If PySR found sin(x^2) and it's correct, E-WSINDy will select it\n",
    "2. **Can DISCOVER missed terms:** If PySR missed x*z, E-WSINDy can find it in polynomial layer\n",
    "3. **Can REJECT errors:** If PySR included spurious term, E-WSINDy's sparsity can exclude it\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Messenger, D. A., & Bortz, D. M. (2021). Weak SINDy for PDEs. *JCP*, 443, 110525.\n",
    "- Framework v4.0/v4.1 Section 4.4: E-WSINDy Sparse Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "07_EWSINDy_STLSQ.ipynb - E-WSINDy with STLSQ on Augmented Library\n",
    "===================================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v4.1\n",
    "\n",
    "This module provides:\n",
    "- EWSINDySTLSQ: Weak-form SINDy with STLSQ sparse regression\n",
    "- Source attribution via analyze_selection_sources()\n",
    "- 50-1000x noise robustness improvement over finite differences\n",
    "- Exact sparsity (true zeros) via iterative thresholding\n",
    "\n",
    "v4.1 Key Changes from v3.0:\n",
    "- Now accepts library_names with source tags [PySR], [Var], [Poly], [Op]\n",
    "- New method: analyze_selection_sources()\n",
    "- Returns selection_analysis in output dictionary\n",
    "- New parameter: normalize_columns (default: True)\n",
    "\n",
    "Output Format:\n",
    "- coefficients, support, equation, r_squared (same as v3.0)\n",
    "- selection_analysis: Dict with from_pysr, from_variant, from_poly, from_op counts\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for E-WSINDy\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "print(\"07_EWSINDy_STLSQ v4.1: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# E-WSINDY STLSQ CLASS (v4.1 MODIFIED)\n",
    "# ==============================================================================\n",
    "\n",
    "class EWSINDySTLSQ:\n",
    "    \"\"\"\n",
    "    E-WSINDy with STLSQ: Weak-form Sparse Regression (v4.1 Modified).\n",
    "    \n",
    "    Now operates on augmented library from v4.0 and includes\n",
    "    source attribution for selected terms.\n",
    "    \n",
    "    Provides 50-1000x noise improvement over strong-form methods.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    threshold : float\n",
    "        STLSQ sparsity threshold (default: 0.1)\n",
    "    max_iter : int\n",
    "        Maximum STLSQ iterations (default: 20)\n",
    "    n_test_functions : int\n",
    "        Number of test functions for weak form (default: 50)\n",
    "    test_function_type : str\n",
    "        Type of test function: 'gaussian' or 'polynomial'\n",
    "    test_function_width : float\n",
    "        Width parameter for test functions (default: 0.1)\n",
    "    use_weak_form : bool\n",
    "        Whether to use weak form transformation (default: True)\n",
    "    normalize_columns : bool\n",
    "        Whether to normalize feature columns (default: True, v4.1)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    fit(feature_library, y, library_names, t) -> Dict\n",
    "        Fit E-WSINDy model using STLSQ\n",
    "    analyze_selection_sources(support, library_names) -> Dict\n",
    "        Analyze where selected terms originated (v4.1)\n",
    "    get_equation() -> str\n",
    "        Get string representation of equation\n",
    "    predict(Phi_new) -> np.ndarray\n",
    "        Make predictions\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Messenger & Bortz (2021). Multiscale Modeling & Simulation.\n",
    "    Framework v4.0/v4.1 Section 4.4: E-WSINDy Sparse Selection\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = EWSINDySTLSQ(threshold=0.1)\n",
    "    >>> result = model.fit(Phi_aug, y, library_names=names)\n",
    "    >>> print(f\"Selection analysis: {result['selection_analysis']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold: float = DEFAULT_STLSQ_THRESHOLD,\n",
    "        max_iter: int = DEFAULT_STLSQ_MAX_ITER,\n",
    "        n_test_functions: int = 50,\n",
    "        test_function_type: str = 'gaussian',\n",
    "        test_function_width: float = 0.1,\n",
    "        use_weak_form: bool = True,\n",
    "        normalize_columns: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize EWSINDySTLSQ.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        threshold : float\n",
    "            Coefficients with |value| < threshold are set to zero.\n",
    "            Default: 0.1\n",
    "        max_iter : int\n",
    "            Maximum number of STLSQ iterations.\n",
    "            Default: 20\n",
    "        n_test_functions : int\n",
    "            Number of test functions for weak form.\n",
    "            Default: 50\n",
    "        test_function_type : str\n",
    "            'gaussian' for Gaussian bumps, 'polynomial' for polynomial.\n",
    "            Default: 'gaussian'\n",
    "        test_function_width : float\n",
    "            Width of Gaussian bumps (as fraction of domain).\n",
    "            Default: 0.1\n",
    "        use_weak_form : bool\n",
    "            Whether to use weak form (True) or standard form (False).\n",
    "            Default: True\n",
    "        normalize_columns : bool\n",
    "            Whether to normalize feature library columns (v4.1).\n",
    "            Default: True\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.max_iter = max_iter\n",
    "        self.n_test_functions = n_test_functions\n",
    "        self.test_function_type = test_function_type\n",
    "        self.test_function_width = test_function_width\n",
    "        self.use_weak_form = use_weak_form\n",
    "        self.normalize_columns = normalize_columns\n",
    "        \n",
    "        # Internal state\n",
    "        self._coefficients = None\n",
    "        self._support = None\n",
    "        self._library_names = None\n",
    "        self._n_features = None\n",
    "        self._n_iterations = 0\n",
    "        self._convergence_history = []\n",
    "        self._fit_complete = False\n",
    "        self._r2_score = None\n",
    "        self._mse = None\n",
    "        self._selection_analysis = None\n",
    "        self._column_scales = None\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        t: np.ndarray = None,\n",
    "        library_names: List[str] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fit E-WSINDy model using STLSQ.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_library : np.ndarray\n",
    "            Feature library (augmented or standard)\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        t : np.ndarray, optional\n",
    "            Time vector for weak form (if None, uses indices)\n",
    "        library_names : List[str], optional\n",
    "            Feature names with source tags for attribution\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            - coefficients: Sparse coefficient vector\n",
    "            - support: Boolean mask of active terms\n",
    "            - equation: Formatted equation string\n",
    "            - selection_analysis: Source attribution (v4.1)\n",
    "            - r_squared: Coefficient of determination\n",
    "            - n_iterations: Convergence iterations\n",
    "            - weak_form_Q: Weak-form feature matrix (if used)\n",
    "            - weak_form_b: Weak-form target vector (if used)\n",
    "        \"\"\"\n",
    "        n_samples, n_features = feature_library.shape\n",
    "        self._n_features = n_features\n",
    "        \n",
    "        # Set feature names\n",
    "        if library_names is None:\n",
    "            self._library_names = [f'f{i}' for i in range(n_features)]\n",
    "        else:\n",
    "            self._library_names = list(library_names)\n",
    "        \n",
    "        # Generate time vector if not provided\n",
    "        if t is None:\n",
    "            t = self._generate_time_vector(n_samples)\n",
    "        \n",
    "        # Normalize columns if requested (v4.1)\n",
    "        Phi_normalized = feature_library.copy()\n",
    "        if self.normalize_columns:\n",
    "            Phi_normalized, self._column_scales = self._normalize_library(feature_library)\n",
    "        else:\n",
    "            self._column_scales = np.ones(n_features)\n",
    "        \n",
    "        # Apply weak form transformation if enabled\n",
    "        if self.use_weak_form:\n",
    "            Q, b = self._weak_form_transform(Phi_normalized, y, t)\n",
    "        else:\n",
    "            # Standard form: direct regression\n",
    "            Q = Phi_normalized\n",
    "            b = y\n",
    "        \n",
    "        # Run STLSQ\n",
    "        self._coefficients = self._stlsq_iteration(Q, b)\n",
    "        \n",
    "        # Rescale coefficients if normalized\n",
    "        if self.normalize_columns:\n",
    "            self._coefficients = self._coefficients / self._column_scales\n",
    "        \n",
    "        self._support = np.abs(self._coefficients) > 0\n",
    "        \n",
    "        # Compute metrics on original scale\n",
    "        y_pred = feature_library @ self._coefficients\n",
    "        self._mse = np.mean((y - y_pred)**2)\n",
    "        ss_tot = np.sum((y - np.mean(y))**2)\n",
    "        ss_res = np.sum((y - y_pred)**2)\n",
    "        self._r2_score = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "        \n",
    "        # Analyze selection sources (v4.1)\n",
    "        self._selection_analysis = self.analyze_selection_sources(\n",
    "            self._support, self._library_names\n",
    "        )\n",
    "        \n",
    "        self._fit_complete = True\n",
    "        \n",
    "        result = {\n",
    "            'coefficients': self._coefficients,\n",
    "            'support': self._support,\n",
    "            'equation': self.get_equation(),\n",
    "            'selection_analysis': self._selection_analysis,\n",
    "            'n_active_terms': int(np.sum(self._support)),\n",
    "            'n_iterations': self._n_iterations,\n",
    "            'r_squared': self._r2_score,\n",
    "            'r2_score': self._r2_score,  # Alias for compatibility\n",
    "            'mse': self._mse,\n",
    "            'convergence_history': self._convergence_history,\n",
    "            'threshold': self.threshold\n",
    "        }\n",
    "        \n",
    "        # Add weak form matrices if used\n",
    "        if self.use_weak_form:\n",
    "            result['weak_form_Q'] = Q\n",
    "            result['weak_form_b'] = b\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def analyze_selection_sources(\n",
    "        self,\n",
    "        support: np.ndarray,\n",
    "        library_names: List[str]\n",
    "    ) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Analyze where selected terms originated (v4.1).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        support : np.ndarray\n",
    "            Boolean mask of selected terms\n",
    "        library_names : List[str]\n",
    "            Feature names with source tags\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, int]\n",
    "            - from_pysr: Count of [PySR] terms selected\n",
    "            - from_variant: Count of [Var] terms selected\n",
    "            - from_poly: Count of [Poly] terms selected\n",
    "            - from_op: Count of [Op] terms selected\n",
    "            - total_selected: Total selected terms\n",
    "        \"\"\"\n",
    "        sources = {\n",
    "            'from_pysr': 0,\n",
    "            'from_variant': 0,\n",
    "            'from_poly': 0,\n",
    "            'from_op': 0,\n",
    "            'from_unknown': 0,\n",
    "            'total_selected': 0\n",
    "        }\n",
    "        \n",
    "        selected_indices = np.where(support)[0]\n",
    "        sources['total_selected'] = len(selected_indices)\n",
    "        \n",
    "        for idx in selected_indices:\n",
    "            if idx >= len(library_names):\n",
    "                sources['from_unknown'] += 1\n",
    "                continue\n",
    "                \n",
    "            name = library_names[idx]\n",
    "            if name.startswith('[PySR]'):\n",
    "                sources['from_pysr'] += 1\n",
    "            elif name.startswith('[Var]'):\n",
    "                sources['from_variant'] += 1\n",
    "            elif name.startswith('[Poly]'):\n",
    "                sources['from_poly'] += 1\n",
    "            elif name.startswith('[Op]'):\n",
    "                sources['from_op'] += 1\n",
    "            else:\n",
    "                sources['from_unknown'] += 1\n",
    "        \n",
    "        return sources\n",
    "    \n",
    "    def _normalize_library(\n",
    "        self,\n",
    "        Phi: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Normalize feature library columns to unit variance.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature library matrix\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (normalized_Phi, column_scales)\n",
    "        \"\"\"\n",
    "        scales = np.std(Phi, axis=0)\n",
    "        scales[scales < 1e-10] = 1.0  # Avoid division by zero\n",
    "        \n",
    "        normalized = Phi / scales\n",
    "        return normalized, scales\n",
    "    \n",
    "    def _generate_time_vector(\n",
    "        self,\n",
    "        n_samples: int\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate uniform time vector.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of samples\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Time vector from 0 to 1\n",
    "        \"\"\"\n",
    "        return np.linspace(0, 1, n_samples)\n",
    "    \n",
    "    def _generate_test_functions(\n",
    "        self,\n",
    "        t: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate test functions and their derivatives.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t : np.ndarray\n",
    "            Time vector\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            - psi: Test functions of shape (n_test, n_samples)\n",
    "            - dpsi: Derivatives of shape (n_test, n_samples)\n",
    "        \"\"\"\n",
    "        n_samples = len(t)\n",
    "        t_min, t_max = t.min(), t.max()\n",
    "        t_range = t_max - t_min\n",
    "        \n",
    "        # Centers for test functions (avoid boundaries)\n",
    "        centers = np.linspace(\n",
    "            t_min + 0.1 * t_range,\n",
    "            t_max - 0.1 * t_range,\n",
    "            self.n_test_functions\n",
    "        )\n",
    "        \n",
    "        width = self.test_function_width * t_range\n",
    "        \n",
    "        psi = np.zeros((self.n_test_functions, n_samples))\n",
    "        dpsi = np.zeros((self.n_test_functions, n_samples))\n",
    "        \n",
    "        for m, center in enumerate(centers):\n",
    "            if self.test_function_type == 'gaussian':\n",
    "                psi[m], dpsi[m] = self._gaussian_bump(t, center, width)\n",
    "            else:\n",
    "                psi[m], dpsi[m] = self._polynomial_bump(t, center, width)\n",
    "        \n",
    "        return psi, dpsi\n",
    "    \n",
    "    def _gaussian_bump(\n",
    "        self,\n",
    "        t: np.ndarray,\n",
    "        center: float,\n",
    "        width: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate Gaussian bump test function.\n",
    "        \n",
    "        psi(t) = exp(-(t - center)^2 / (2 * width^2))\n",
    "        dpsi(t) = -(t - center) / width^2 * psi(t)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t : np.ndarray\n",
    "            Time vector\n",
    "        center : float\n",
    "            Center of Gaussian\n",
    "        width : float\n",
    "            Width (standard deviation)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (psi, dpsi)\n",
    "        \"\"\"\n",
    "        z = (t - center) / width\n",
    "        psi = np.exp(-0.5 * z**2)\n",
    "        dpsi = -z / width * psi\n",
    "        return psi, dpsi\n",
    "    \n",
    "    def _polynomial_bump(\n",
    "        self,\n",
    "        t: np.ndarray,\n",
    "        center: float,\n",
    "        width: float\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate polynomial bump test function.\n",
    "        \n",
    "        Uses (1 - ((t-center)/width)^2)^4 for compact support.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t : np.ndarray\n",
    "            Time vector\n",
    "        center : float\n",
    "            Center of bump\n",
    "        width : float\n",
    "            Half-width of support\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (psi, dpsi)\n",
    "        \"\"\"\n",
    "        z = (t - center) / width\n",
    "        mask = np.abs(z) < 1\n",
    "        \n",
    "        psi = np.zeros_like(t)\n",
    "        dpsi = np.zeros_like(t)\n",
    "        \n",
    "        psi[mask] = (1 - z[mask]**2)**4\n",
    "        dpsi[mask] = -8 * z[mask] / width * (1 - z[mask]**2)**3\n",
    "        \n",
    "        return psi, dpsi\n",
    "    \n",
    "    def _weak_form_transform(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        t: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Apply weak form transformation.\n",
    "        \n",
    "        Q[m,k] = integral(psi_m * Phi_k) dt\n",
    "        b[m] = -integral(dpsi_m * y) dt  (integration by parts)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature library (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector (n_samples,)\n",
    "        t : np.ndarray\n",
    "            Time vector (n_samples,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, np.ndarray]\n",
    "            (Q, b) - Weak form matrices\n",
    "        \"\"\"\n",
    "        n_samples, n_features = Phi.shape\n",
    "        \n",
    "        # Generate test functions\n",
    "        psi, dpsi = self._generate_test_functions(t)\n",
    "        \n",
    "        # Compute weak form matrices via numerical integration\n",
    "        Q = np.zeros((self.n_test_functions, n_features))\n",
    "        b = np.zeros(self.n_test_functions)\n",
    "        \n",
    "        for m in range(self.n_test_functions):\n",
    "            # Q[m, k] = integral(psi_m * Phi_k)\n",
    "            for k in range(n_features):\n",
    "                Q[m, k] = np.trapz(psi[m] * Phi[:, k], t)\n",
    "            \n",
    "            # b[m] = -integral(dpsi_m * y) (integration by parts)\n",
    "            b[m] = -np.trapz(dpsi[m] * y, t)\n",
    "        \n",
    "        return Q, b\n",
    "    \n",
    "    def _stlsq_iteration(\n",
    "        self,\n",
    "        Q: np.ndarray,\n",
    "        b: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Sequentially Thresholded Least Squares (STLSQ).\n",
    "        \n",
    "        Algorithm:\n",
    "            1. Initialize with OLS solution\n",
    "            2. Threshold small coefficients to zero\n",
    "            3. Refit OLS on remaining support\n",
    "            4. Repeat until convergence\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Q : np.ndarray\n",
    "            Design matrix (n_equations, n_features)\n",
    "        b : np.ndarray\n",
    "            Target vector (n_equations,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Sparse coefficient vector\n",
    "        \"\"\"\n",
    "        n_features = Q.shape[1]\n",
    "        self._convergence_history = []\n",
    "        \n",
    "        # Step 1: Initialize with regularized OLS (for stability)\n",
    "        try:\n",
    "            ridge = Ridge(alpha=1e-6, fit_intercept=False)\n",
    "            ridge.fit(Q, b)\n",
    "            xi = ridge.coef_\n",
    "        except Exception:\n",
    "            xi = np.linalg.lstsq(Q, b, rcond=None)[0]\n",
    "        \n",
    "        self._convergence_history.append(xi.copy())\n",
    "        \n",
    "        # Step 2-4: Iterative thresholding\n",
    "        for iteration in range(self.max_iter):\n",
    "            self._n_iterations = iteration + 1\n",
    "            \n",
    "            # Threshold small coefficients\n",
    "            small_mask = np.abs(xi) < self.threshold\n",
    "            xi[small_mask] = 0\n",
    "            \n",
    "            # Get active indices\n",
    "            active = ~small_mask\n",
    "            \n",
    "            # Check if any coefficients remain\n",
    "            if not np.any(active):\n",
    "                break\n",
    "            \n",
    "            # Refit on active support\n",
    "            Q_active = Q[:, active]\n",
    "            try:\n",
    "                xi_active = np.linalg.lstsq(Q_active, b, rcond=None)[0]\n",
    "            except Exception:\n",
    "                break\n",
    "            \n",
    "            # Update full coefficient vector\n",
    "            xi_new = np.zeros(n_features)\n",
    "            xi_new[active] = xi_active\n",
    "            \n",
    "            self._convergence_history.append(xi_new.copy())\n",
    "            \n",
    "            # Check convergence\n",
    "            if np.allclose(xi, xi_new, rtol=1e-6):\n",
    "                xi = xi_new\n",
    "                break\n",
    "            \n",
    "            xi = xi_new\n",
    "        \n",
    "        return xi\n",
    "    \n",
    "    def get_equation(self) -> str:\n",
    "        \"\"\"\n",
    "        Get string representation of discovered equation.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Equation string with source tags\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            return \"\"\n",
    "        \n",
    "        terms = []\n",
    "        for i, (coef, active) in enumerate(zip(self._coefficients, self._support)):\n",
    "            if active:\n",
    "                name = self._library_names[i]\n",
    "                if abs(coef) > 0.001:\n",
    "                    terms.append(f\"{coef:.3f} * {name}\")\n",
    "        \n",
    "        if len(terms) == 0:\n",
    "            return \"0\"\n",
    "        \n",
    "        return \" + \".join(terms)\n",
    "    \n",
    "    def get_active_terms(self) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get list of active terms with coefficients.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[str, float]]\n",
    "            List of (term_name, coefficient) pairs\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            return []\n",
    "        \n",
    "        active_terms = []\n",
    "        for i, (coef, active) in enumerate(zip(self._coefficients, self._support)):\n",
    "            if active:\n",
    "                active_terms.append((self._library_names[i], coef))\n",
    "        \n",
    "        return active_terms\n",
    "    \n",
    "    def predict(self, Phi_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Make predictions using discovered equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi_new : np.ndarray\n",
    "            New feature library matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Predictions\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            raise RuntimeError(\"Must call fit() before predict()\")\n",
    "        \n",
    "        return Phi_new @ self._coefficients\n",
    "    \n",
    "    def print_stlsq_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed STLSQ results report in v4.1 format.\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            print(\"Fit not yet performed. Run fit() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"=== E-WSINDy Results (v4.1) ===\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Selected terms: {np.sum(self._support)}\")\n",
    "        print()\n",
    "        \n",
    "        # Print active terms with source tags\n",
    "        for name, coef in self.get_active_terms():\n",
    "            print(f\"  {coef:8.3f} * {name}\")\n",
    "        print()\n",
    "        \n",
    "        # Print selection analysis\n",
    "        print(\"Selection Analysis:\")\n",
    "        print(f\"  from_pysr: {self._selection_analysis['from_pysr']}\")\n",
    "        print(f\"  from_variant: {self._selection_analysis['from_variant']}\")\n",
    "        print(f\"  from_poly: {self._selection_analysis['from_poly']}\")\n",
    "        print(f\"  from_op: {self._selection_analysis['from_op']}\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"R-squared: {self._r2_score:.4f}\")\n",
    "        print(f\"MSE: {self._mse:.6f}\")\n",
    "        print(f\"Iterations: {self._n_iterations}\")\n",
    "        print(f\"Threshold: {self.threshold}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "print(\"EWSINDySTLSQ class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 07_EWSINDy_STLSQ v4.1\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Basic STLSQ with Standard Library\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Basic STLSQ with Standard Library\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 3*x + 2*x**2 + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    # Standard library (no source tags)\n",
    "    Phi = np.column_stack([np.ones(n_samples), x, x**2, x**3, x**4])\n",
    "    library_names = ['1', 'x', 'x^2', 'x^3', 'x^4']\n",
    "    \n",
    "    model = EWSINDySTLSQ(threshold=0.1, use_weak_form=False)\n",
    "    result = model.fit(Phi, y, library_names=library_names)\n",
    "    \n",
    "    print(f\"True: y = 3*x + 2*x^2\")\n",
    "    print(f\"Discovered: {result['equation']}\")\n",
    "    print(f\"R-squared: {result['r_squared']:.4f}\")\n",
    "    print(f\"Active terms: {result['n_active_terms']}\")\n",
    "    print()\n",
    "    \n",
    "    if result['r_squared'] > 0.99:\n",
    "        print(\"[PASS] High accuracy achieved\")\n",
    "    else:\n",
    "        print(\"[WARNING] Accuracy lower than expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Source Attribution with Augmented Library\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: Source Attribution with Augmented Library\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    z = np.random.uniform(0.1, 2, n_samples)\n",
    "    \n",
    "    # True equation: y = 0.5*x^2 + sin(z)\n",
    "    y = 0.5*x**2 + np.sin(z) + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    # Simulated augmented library with source tags\n",
    "    Phi = np.column_stack([\n",
    "        x**2,           # [PySR] x**2\n",
    "        np.sin(z),      # [PySR] sin(z)\n",
    "        np.sin(x),      # [Var] sin(x)\n",
    "        np.ones(n_samples),  # [Poly] 1\n",
    "        x,              # [Poly] x\n",
    "        z,              # [Poly] z\n",
    "        x*z,            # [Poly] x*z\n",
    "        np.cos(x),      # [Op] cos(x)\n",
    "        np.cos(z)       # [Op] cos(z)\n",
    "    ])\n",
    "    \n",
    "    library_names = [\n",
    "        '[PySR] x**2',\n",
    "        '[PySR] sin(z)',\n",
    "        '[Var] sin(x)',\n",
    "        '[Poly] 1',\n",
    "        '[Poly] x',\n",
    "        '[Poly] z',\n",
    "        '[Poly] x*z',\n",
    "        '[Op] cos(x)',\n",
    "        '[Op] cos(z)'\n",
    "    ]\n",
    "    \n",
    "    model = EWSINDySTLSQ(threshold=0.1, use_weak_form=False)\n",
    "    result = model.fit(Phi, y, library_names=library_names)\n",
    "    \n",
    "    print(f\"True: y = 0.5*x^2 + sin(z)\")\n",
    "    print()\n",
    "    print(\"Selected terms:\")\n",
    "    for name, coef in model.get_active_terms():\n",
    "        print(f\"  {coef:8.3f} * {name}\")\n",
    "    print()\n",
    "    print(f\"Selection Analysis: {result['selection_analysis']}\")\n",
    "    print(f\"R-squared: {result['r_squared']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Check that PySR terms were selected\n",
    "    analysis = result['selection_analysis']\n",
    "    if analysis['from_pysr'] >= 2:\n",
    "        print(\"[PASS] PySR terms correctly selected\")\n",
    "    else:\n",
    "        print(f\"[INFO] Selected {analysis['from_pysr']} PySR terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: Noise Robustness with Weak Form\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: Noise Robustness with Weak Form\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 300\n",
    "    \n",
    "    t = np.linspace(0, 1, n_samples)\n",
    "    x = np.sin(2 * np.pi * t)\n",
    "    \n",
    "    # True dynamics: dy/dt = x (approximately)\n",
    "    y_clean = x.copy()\n",
    "    \n",
    "    noise_levels = [0.01, 0.05, 0.10]\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x, x**2])\n",
    "    library_names = ['[Poly] 1', '[Poly] x', '[Poly] x^2']\n",
    "    \n",
    "    print(f\"{'Noise':<12} {'R2 (strong)':<15} {'R2 (weak)':<15}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    for noise_level in noise_levels:\n",
    "        y_noisy = y_clean + noise_level * np.random.randn(n_samples)\n",
    "        \n",
    "        # Strong form\n",
    "        model_strong = EWSINDySTLSQ(threshold=0.1, use_weak_form=False)\n",
    "        result_strong = model_strong.fit(Phi, y_noisy, library_names=library_names)\n",
    "        \n",
    "        # Weak form\n",
    "        model_weak = EWSINDySTLSQ(threshold=0.1, use_weak_form=True)\n",
    "        result_weak = model_weak.fit(Phi, y_noisy, t=t, library_names=library_names)\n",
    "        \n",
    "        print(f\"{noise_level:<12.2f} {result_strong['r_squared']:<15.4f} {result_weak['r_squared']:<15.4f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"[INFO] Weak form should be more robust at higher noise levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: analyze_selection_sources Method\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: analyze_selection_sources Method\")\n",
    "    \n",
    "    # Create mock support and library names\n",
    "    support = np.array([True, True, False, True, False, False, True, False])\n",
    "    library_names = [\n",
    "        '[PySR] sin(x)',\n",
    "        '[PySR] x**2',\n",
    "        '[Var] sin(y)',\n",
    "        '[Poly] 1',\n",
    "        '[Poly] x',\n",
    "        '[Poly] y',\n",
    "        '[Op] exp(x)',\n",
    "        '[Op] cos(x)'\n",
    "    ]\n",
    "    \n",
    "    model = EWSINDySTLSQ()\n",
    "    analysis = model.analyze_selection_sources(support, library_names)\n",
    "    \n",
    "    print(\"Support mask:\")\n",
    "    for i, (s, n) in enumerate(zip(support, library_names)):\n",
    "        status = \"SELECTED\" if s else \"        \"\n",
    "        print(f\"  {i}: {status} {n}\")\n",
    "    print()\n",
    "    print(f\"Analysis result: {analysis}\")\n",
    "    print()\n",
    "    \n",
    "    # Expected: 2 PySR, 0 Var, 1 Poly, 1 Op\n",
    "    expected = {'from_pysr': 2, 'from_variant': 0, 'from_poly': 1, 'from_op': 1}\n",
    "    \n",
    "    all_correct = True\n",
    "    for key, expected_val in expected.items():\n",
    "        actual_val = analysis[key]\n",
    "        status = \"PASS\" if actual_val == expected_val else \"FAIL\"\n",
    "        if status == \"FAIL\":\n",
    "            all_correct = False\n",
    "        print(f\"  {key}: expected={expected_val}, actual={actual_val} [{status}]\")\n",
    "    \n",
    "    print()\n",
    "    if all_correct:\n",
    "        print(\"[PASS] All source attribution correct\")\n",
    "    else:\n",
    "        print(\"[FAIL] Some source attributions incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Full Report Output\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 5: Full Report Output\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    z = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 0.5*x**2 + np.sin(z) + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    # Augmented library\n",
    "    Phi = np.column_stack([\n",
    "        x**2,\n",
    "        np.sin(z),\n",
    "        np.ones(n_samples),\n",
    "        x,\n",
    "        z\n",
    "    ])\n",
    "    \n",
    "    library_names = [\n",
    "        '[PySR] x**2',\n",
    "        '[PySR] sin(z)',\n",
    "        '[Poly] 1',\n",
    "        '[Poly] x',\n",
    "        '[Poly] z'\n",
    "    ]\n",
    "    \n",
    "    model = EWSINDySTLSQ(threshold=0.1, use_weak_form=False)\n",
    "    result = model.fit(Phi, y, library_names=library_names)\n",
    "    \n",
    "    # Print full report\n",
    "    model.print_stlsq_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 07_EWSINDy_STLSQ.ipynb v4.1 - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: EWSINDySTLSQ (v4.1 Modified)\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Noise-robust equation discovery via weak-form sparse regression.\")\n",
    "print(\"  Now operates on augmented library with source attribution.\")\n",
    "print()\n",
    "print(\"v4.1 Modifications:\")\n",
    "print(\"  - Accepts library_names with source tags [PySR], [Var], [Poly], [Op]\")\n",
    "print(\"  - New method: analyze_selection_sources()\")\n",
    "print(\"  - Returns selection_analysis in output dictionary\")\n",
    "print(\"  - New parameter: normalize_columns (default: True)\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  fit(feature_library, y, library_names=None, t=None) -> Dict\")\n",
    "print(\"      Returns: coefficients, support, equation, selection_analysis, r_squared\")\n",
    "print()\n",
    "print(\"  analyze_selection_sources(support, library_names) -> Dict\")\n",
    "print(\"      Returns: from_pysr, from_variant, from_poly, from_op counts\")\n",
    "print()\n",
    "print(\"  get_equation() -> str\")\n",
    "print(\"      Get string representation of discovered equation\")\n",
    "print()\n",
    "print(\"  get_active_terms() -> List[Tuple[str, float]]\")\n",
    "print(\"      Get list of active terms with coefficients\")\n",
    "print()\n",
    "print(\"  print_stlsq_report()\")\n",
    "print(\"      Print detailed results with source attribution\")\n",
    "print()\n",
    "print(\"Key Parameters:\")\n",
    "print(\"  threshold: STLSQ sparsity threshold (default: 0.1)\")\n",
    "print(\"  use_weak_form: Enable weak form (default: True)\")\n",
    "print(\"  normalize_columns: Normalize library columns (default: True)\")\n",
    "print()\n",
    "print(\"Usage Example (with augmented library):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Build augmented library (from 05_FeatureLibrary)\n",
    "builder = AugmentedLibraryBuilder(max_poly_degree=3)\n",
    "Phi, names, info = builder.build(\n",
    "    X, feature_names,\n",
    "    parsed_terms=unique_terms,\n",
    "    detected_operators=detected_operators,\n",
    "    pysr_r2=0.85\n",
    ")\n",
    "\n",
    "# Fit E-WSINDy with source attribution\n",
    "model = EWSINDySTLSQ(threshold=0.1, use_weak_form=False)\n",
    "result = model.fit(Phi, y, library_names=names)\n",
    "\n",
    "# Check source attribution\n",
    "print(f\"Selection Analysis: {result['selection_analysis']}\")\n",
    "print(f\"R-squared: {result['r_squared']:.4f}\")\n",
    "\n",
    "# Print full report\n",
    "model.print_stlsq_report()\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 07_EWSINDy_STLSQ.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

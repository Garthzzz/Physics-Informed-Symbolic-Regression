{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06_PySR - Physics-SR Framework v4.1\n",
    "\n",
    "## Stage 2.1-2.2: PySR Structure Exploration + Structure Parsing\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (Structure-Guided Feature Library Enhancement + Computational Optimization)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Search for symbolic expressions via evolutionary algorithms and parse discovered structures\n",
    "for augmented library construction. This is an **ENHANCED** module for v4.1.\n",
    "\n",
    "### v4.1 Enhancements\n",
    "\n",
    "| Component | v3.0 | v4.1 |\n",
    "|-----------|------|------|\n",
    "| PySRDiscoverer | Basic configuration | Mode-based (fast/standard/thorough) |\n",
    "| Timeout | None | Hard timeout with elapsed_time tracking |\n",
    "| Precision | Float64 | Float32 (2x memory savings) |\n",
    "| StructureParser | Single equation | Multi-equation Pareto parsing |\n",
    "| Operator Detection | None | Automatic detection for Layer 4 |\n",
    "\n",
    "### Algorithm Overview\n",
    "\n",
    "1. **Configure PySR** with mode-based parameters (fast/standard/thorough)\n",
    "2. **Run symbolic search** via genetic programming with timeout\n",
    "3. **Extract Pareto front** (complexity vs accuracy tradeoff)\n",
    "4. **Parse structure** - extract unique terms and operators for library construction\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Cranmer, M. (2023). Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl. *arXiv:2305.01582*.\n",
    "- Framework v4.0/v4.1 Section 4.1-4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "06_PySR.ipynb - PySR Structure Exploration + Structure Parsing\n",
    "===============================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v4.1\n",
    "\n",
    "This module provides:\n",
    "- PySRDiscoverer: Mode-based PySR configuration with computational optimization\n",
    "- StructureParser: Parse Pareto equations for augmented library construction\n",
    "- Operator detection for Layer 4 term generation\n",
    "- Graceful fallback when PySR is not available\n",
    "\n",
    "v4.1 Key Changes from v3.0:\n",
    "- Mode-based configuration: 'fast', 'standard', 'thorough'\n",
    "- Hard timeout with elapsed_time tracking\n",
    "- Float32 precision and turbo mode\n",
    "- StructureParser.parse_pareto_equations() for multi-equation parsing\n",
    "- Automatic operator detection for Layer 4\n",
    "\n",
    "Output Format:\n",
    "- PySRDiscoverer.discover() returns dict with elapsed_time, best_r2\n",
    "- StructureParser.parse_pareto_equations() returns (unique_terms, detected_operators, term_map)\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySR installation check\n",
    "PYSR_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from pysr import PySRRegressor\n",
    "    PYSR_AVAILABLE = True\n",
    "    print(\"06_PySR v4.1: PySR is available.\")\n",
    "except ImportError:\n",
    "    warnings.warn(\n",
    "        \"PySR not available. Install with: pip install pysr\\n\"\n",
    "        \"PySRDiscoverer will use fallback mode.\"\n",
    "    )\n",
    "    print(\"06_PySR v4.1: PySR not available, fallback mode enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for Structure Parser\n",
    "import sympy as sp\n",
    "from sympy import Symbol, sympify, Add, Mul, Pow, Float, Integer, lambdify\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union, Set, Callable\n",
    "import re\n",
    "import time\n",
    "\n",
    "print(\"06_PySR v4.1: SymPy imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: PySRDiscoverer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PYSR DISCOVERER CLASS (v4.1 ENHANCED)\n",
    "# ==============================================================================\n",
    "\n",
    "class PySRDiscoverer:\n",
    "    \"\"\"\n",
    "    PySR-based Symbolic Regression Discoverer (v4.1 Enhanced).\n",
    "    \n",
    "    Wrapper around PySR with physics-informed configuration and\n",
    "    v4.1 computational optimizations.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    mode : str\n",
    "        Configuration mode: 'fast', 'standard', 'thorough'\n",
    "    binary_operators : List[str]\n",
    "        Binary operators (default: [\"+\", \"-\", \"*\", \"/\"])\n",
    "    unary_operators : List[str]\n",
    "        Unary operators (default: [\"sin\", \"cos\", \"exp\"])\n",
    "    timeout_seconds : int\n",
    "        Hard timeout in seconds (v4.1)\n",
    "    procs : int\n",
    "        Number of parallel processes (default: 2 for Colab)\n",
    "    turbo : bool\n",
    "        Use turbo mode for faster evaluation (v4.1)\n",
    "    precision : int\n",
    "        Float precision, 32 or 64 (v4.1)\n",
    "    model : PySRRegressor\n",
    "        Fitted PySR model (public)\n",
    "    elapsed_time : float\n",
    "        Execution time in seconds (public)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    discover(X, y, feature_names) -> Dict\n",
    "        Run PySR symbolic regression\n",
    "    get_pareto_equations() -> List[str]\n",
    "        Get equations from Pareto front\n",
    "    predict(X) -> np.ndarray\n",
    "        Predict using best equation\n",
    "    print_discovery_report() -> None\n",
    "        Print detailed discovery results\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Cranmer, M. (2023). arXiv:2305.01582.\n",
    "    Framework v4.0/v4.1 Section 4.1: PySR Structure Exploration\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> discoverer = PySRDiscoverer(mode='standard')\n",
    "    >>> result = discoverer.discover(X, y, feature_names)\n",
    "    >>> print(f\"Best equation: {result['best_equation']}\")\n",
    "    >>> print(f\"Elapsed time: {result['elapsed_time']:.1f}s\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'standard',\n",
    "        binary_operators: List[str] = None,\n",
    "        unary_operators: List[str] = None,\n",
    "        timeout_seconds: int = None,\n",
    "        procs: int = DEFAULT_PROCS,\n",
    "        turbo: bool = True,\n",
    "        precision: int = DEFAULT_PRECISION,\n",
    "        random_state: int = RANDOM_SEED\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize PySRDiscoverer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        mode : str\n",
    "            Configuration mode: 'fast', 'standard', 'thorough'.\n",
    "            Uses PYSR_MODES from 00_Core for settings.\n",
    "            Default: 'standard'\n",
    "        binary_operators : List[str], optional\n",
    "            Binary operators. Default: [\"+\", \"-\", \"*\", \"/\"]\n",
    "        unary_operators : List[str], optional\n",
    "            Unary operators. Default: [\"sin\", \"cos\", \"exp\"]\n",
    "        timeout_seconds : int, optional\n",
    "            Hard timeout. If None, uses mode-specific default.\n",
    "        procs : int\n",
    "            Number of CPU processes. Default: 2 (Colab optimized)\n",
    "        turbo : bool\n",
    "            Enable turbo mode for faster evaluation. Default: True\n",
    "        precision : int\n",
    "            Float precision (32 or 64). Default: 32\n",
    "        random_state : int\n",
    "            Random seed for reproducibility. Default: 42\n",
    "        \"\"\"\n",
    "        # Validate mode\n",
    "        if mode not in PYSR_MODES:\n",
    "            raise ValueError(f\"mode must be one of {list(PYSR_MODES.keys())}\")\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.binary_operators = binary_operators or [\"+\", \"-\", \"*\", \"/\"]\n",
    "        self.unary_operators = unary_operators or [\"sin\", \"cos\", \"exp\"]\n",
    "        self.procs = procs\n",
    "        self.turbo = turbo\n",
    "        self.precision = precision\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Get mode-specific timeout or use provided\n",
    "        mode_config = PYSR_MODES[mode]\n",
    "        self.timeout_seconds = timeout_seconds or mode_config['timeout_in_seconds']\n",
    "        \n",
    "        # Public attributes (v4.1)\n",
    "        self.model = None\n",
    "        self.elapsed_time = None\n",
    "        \n",
    "        # Internal state\n",
    "        self._feature_names = None\n",
    "        self._pareto_front = None\n",
    "        self._best_equation = None\n",
    "        self._best_equation_sympy = None\n",
    "        self._best_complexity = None\n",
    "        self._best_loss = None\n",
    "        self._best_r2 = None\n",
    "        self._discovery_complete = False\n",
    "    \n",
    "    def discover(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run PySR symbolic regression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix of shape (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector of shape (n_samples,)\n",
    "        feature_names : List[str]\n",
    "            Names of features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Dictionary containing:\n",
    "            - best_equation: Best equation string\n",
    "            - best_equation_sympy: SymPy expression of best equation\n",
    "            - best_complexity: Complexity of best equation\n",
    "            - best_loss: Loss of best equation\n",
    "            - best_r2: R-squared of best equation\n",
    "            - pareto_front: DataFrame of Pareto-optimal equations\n",
    "            - all_equations: List of all candidate equations\n",
    "            - elapsed_time: Execution time in seconds\n",
    "            - pysr_available: Whether PySR was used\n",
    "        \"\"\"\n",
    "        self._feature_names = list(feature_names)\n",
    "        \n",
    "        if not PYSR_AVAILABLE:\n",
    "            return self._fallback_discovery(X, y)\n",
    "        \n",
    "        # Start timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Configure PySR with v4.1 optimizations\n",
    "        self.model = self._configure_pysr()\n",
    "        \n",
    "        # Convert to float32 if precision=32\n",
    "        if self.precision == 32:\n",
    "            X_fit = X.astype(np.float32)\n",
    "            y_fit = y.astype(np.float32)\n",
    "        else:\n",
    "            X_fit = X\n",
    "            y_fit = y\n",
    "        \n",
    "        # Run search\n",
    "        try:\n",
    "            self.model.fit(X_fit, y_fit, variable_names=self._feature_names)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"PySR fit failed: {e}. Using fallback.\")\n",
    "            return self._fallback_discovery(X, y)\n",
    "        \n",
    "        # Record elapsed time\n",
    "        self.elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Extract results\n",
    "        self._pareto_front = self._extract_pareto_front()\n",
    "        self._best_equation = self._select_best_equation(criterion='accuracy')\n",
    "        \n",
    "        # Get best equation details\n",
    "        if self.model.equations_ is not None and len(self.model.equations_) > 0:\n",
    "            best_idx = self.model.equations_.loss.idxmin()\n",
    "            self._best_complexity = int(self.model.equations_.loc[best_idx, 'complexity'])\n",
    "            self._best_loss = float(self.model.equations_.loc[best_idx, 'loss'])\n",
    "            \n",
    "            # Parse to SymPy\n",
    "            try:\n",
    "                local_dict = {name: Symbol(name) for name in self._feature_names}\n",
    "                local_dict.update({'sqrt': sp.sqrt, 'exp': sp.exp, 'log': sp.log,\n",
    "                                   'sin': sp.sin, 'cos': sp.cos, 'abs': sp.Abs})\n",
    "                self._best_equation_sympy = sympify(\n",
    "                    self._best_equation.replace('^', '**'),\n",
    "                    locals=local_dict\n",
    "                )\n",
    "            except Exception:\n",
    "                self._best_equation_sympy = None\n",
    "            \n",
    "            # Compute R2\n",
    "            try:\n",
    "                y_pred = self.model.predict(X_fit)\n",
    "                ss_tot = np.sum((y - np.mean(y))**2)\n",
    "                ss_res = np.sum((y - y_pred)**2)\n",
    "                self._best_r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "            except Exception:\n",
    "                self._best_r2 = None\n",
    "        else:\n",
    "            self._best_complexity = 0\n",
    "            self._best_loss = float('inf')\n",
    "            self._best_equation_sympy = None\n",
    "            self._best_r2 = None\n",
    "        \n",
    "        self._discovery_complete = True\n",
    "        \n",
    "        return {\n",
    "            'best_equation': self._best_equation,\n",
    "            'best_equation_sympy': self._best_equation_sympy,\n",
    "            'best_complexity': self._best_complexity,\n",
    "            'best_loss': self._best_loss,\n",
    "            'best_r2': self._best_r2,\n",
    "            'pareto_front': self._pareto_front,\n",
    "            'all_equations': self.get_pareto_equations(),\n",
    "            'elapsed_time': self.elapsed_time,\n",
    "            'pysr_available': True,\n",
    "            'n_equations': len(self.model.equations_) if self.model.equations_ is not None else 0,\n",
    "            'mode': self.mode\n",
    "        }\n",
    "    \n",
    "    def _configure_pysr(self) -> 'PySRRegressor':\n",
    "        \"\"\"\n",
    "        Configure PySR model with v4.1 optimized settings.\n",
    "        \n",
    "        Uses PYSR_MODES configuration based on self.mode.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        PySRRegressor\n",
    "            Configured PySR model\n",
    "        \"\"\"\n",
    "        # Get mode-specific configuration\n",
    "        config = PYSR_MODES[self.mode]\n",
    "        \n",
    "        # Get constraints\n",
    "        constraints, nested_constraints = self._get_constraints()\n",
    "        \n",
    "        model = PySRRegressor(\n",
    "            # Core parameters from mode config\n",
    "            niterations=config['niterations'],\n",
    "            maxsize=config['maxsize'],\n",
    "            maxdepth=config['maxdepth'],\n",
    "            populations=config['populations'],\n",
    "            population_size=config['population_size'],\n",
    "            ncycles_per_iteration=config['ncycles_per_iteration'],\n",
    "            \n",
    "            # Operators\n",
    "            binary_operators=self.binary_operators,\n",
    "            unary_operators=self.unary_operators,\n",
    "            \n",
    "            # Parallelization (v4.1: reduced for Colab)\n",
    "            procs=0,  # Must be 0 for deterministic mode\n",
    "            \n",
    "            # Performance optimizations (v4.1)\n",
    "            turbo=self.turbo,\n",
    "            \n",
    "            # Time control\n",
    "            timeout_in_seconds=self.timeout_seconds,\n",
    "            \n",
    "            # Constraints\n",
    "            constraints=constraints,\n",
    "            nested_constraints=nested_constraints,\n",
    "            \n",
    "            # Reproducibility\n",
    "            random_state=self.random_state,\n",
    "            deterministic=True,\n",
    "            parallelism='serial',\n",
    "            \n",
    "            # Output control\n",
    "            verbosity=0,\n",
    "            progress=False\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def _get_constraints(self) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Get complexity and nesting constraints.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Dict, Dict]\n",
    "            (constraints, nested_constraints)\n",
    "        \"\"\"\n",
    "        constraints = {\n",
    "            \"/\": (-1, 7),   # Denominator complexity limit\n",
    "            \"exp\": 7        # Exponent complexity limit\n",
    "        }\n",
    "        \n",
    "        nested_constraints = {\n",
    "            \"exp\": {\"exp\": 0},              # No nested exponentials\n",
    "            \"sin\": {\"sin\": 0, \"cos\": 1},    # Limited trig nesting\n",
    "            \"cos\": {\"sin\": 1, \"cos\": 0}\n",
    "        }\n",
    "        \n",
    "        return constraints, nested_constraints\n",
    "    \n",
    "    def _extract_pareto_front(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract Pareto front from PySR results.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame with columns: complexity, loss, equation\n",
    "        \"\"\"\n",
    "        if self.model is None or self.model.equations_ is None:\n",
    "            return pd.DataFrame(columns=['complexity', 'loss', 'equation'])\n",
    "        \n",
    "        df = self.model.equations_[['complexity', 'loss', 'equation']].copy()\n",
    "        \n",
    "        # Filter to Pareto-optimal points\n",
    "        pareto_mask = np.ones(len(df), dtype=bool)\n",
    "        for i, (c1, l1) in enumerate(zip(df['complexity'], df['loss'])):\n",
    "            for j, (c2, l2) in enumerate(zip(df['complexity'], df['loss'])):\n",
    "                if i != j and c2 <= c1 and l2 <= l1 and (c2 < c1 or l2 < l1):\n",
    "                    pareto_mask[i] = False\n",
    "                    break\n",
    "        \n",
    "        return df[pareto_mask].sort_values('complexity').reset_index(drop=True)\n",
    "    \n",
    "    def _select_best_equation(\n",
    "        self,\n",
    "        criterion: str = 'accuracy'\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Select best equation based on criterion.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        criterion : str\n",
    "            Selection criterion: 'accuracy', 'complexity', or 'pareto'\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Best equation string\n",
    "        \"\"\"\n",
    "        if self.model is None or self.model.equations_ is None:\n",
    "            return \"\"\n",
    "        \n",
    "        df = self.model.equations_\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            return \"\"\n",
    "        \n",
    "        if criterion == 'accuracy':\n",
    "            best_idx = df['loss'].idxmin()\n",
    "        elif criterion == 'complexity':\n",
    "            best_idx = df['complexity'].idxmin()\n",
    "        else:  # pareto - select knee point\n",
    "            med_complexity = df['complexity'].median()\n",
    "            simple_df = df[df['complexity'] <= med_complexity]\n",
    "            if len(simple_df) > 0:\n",
    "                best_idx = simple_df['loss'].idxmin()\n",
    "            else:\n",
    "                best_idx = df['loss'].idxmin()\n",
    "        \n",
    "        return str(df.loc[best_idx, 'equation'])\n",
    "    \n",
    "    def _fallback_discovery(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fallback when PySR is not available.\n",
    "        \n",
    "        Uses simple polynomial regression to suggest a basic form.\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import Ridge\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Fit simple polynomial\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        \n",
    "        reg = Ridge(alpha=0.1)\n",
    "        reg.fit(X_poly, y)\n",
    "        \n",
    "        # Build equation string\n",
    "        terms = []\n",
    "        feature_names_poly = poly.get_feature_names_out(self._feature_names)\n",
    "        for coef, name in zip(reg.coef_, feature_names_poly):\n",
    "            if abs(coef) > 0.01:\n",
    "                terms.append(f\"{coef:.4f}*{name}\")\n",
    "        \n",
    "        if reg.intercept_ != 0:\n",
    "            equation = f\"{reg.intercept_:.4f} + \" + \" + \".join(terms)\n",
    "        else:\n",
    "            equation = \" + \".join(terms) if terms else \"0\"\n",
    "        \n",
    "        # Compute metrics\n",
    "        y_pred = reg.predict(X_poly)\n",
    "        loss = np.mean((y - y_pred)**2)\n",
    "        ss_tot = np.sum((y - np.mean(y))**2)\n",
    "        ss_res = np.sum((y - y_pred)**2)\n",
    "        r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "        \n",
    "        self.elapsed_time = time.time() - start_time\n",
    "        self._best_equation = equation\n",
    "        self._best_loss = loss\n",
    "        self._best_r2 = r2\n",
    "        self._best_complexity = len(terms) + 1\n",
    "        self._discovery_complete = True\n",
    "        \n",
    "        return {\n",
    "            'best_equation': equation,\n",
    "            'best_equation_sympy': None,\n",
    "            'best_complexity': self._best_complexity,\n",
    "            'best_loss': loss,\n",
    "            'best_r2': r2,\n",
    "            'pareto_front': pd.DataFrame({\n",
    "                'complexity': [self._best_complexity],\n",
    "                'loss': [loss],\n",
    "                'equation': [equation]\n",
    "            }),\n",
    "            'all_equations': [equation],\n",
    "            'elapsed_time': self.elapsed_time,\n",
    "            'pysr_available': False,\n",
    "            'n_equations': 1,\n",
    "            'mode': self.mode\n",
    "        }\n",
    "    \n",
    "    def get_pareto_equations(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get equations from Pareto front.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "            List of equation strings\n",
    "        \"\"\"\n",
    "        if self._pareto_front is None or len(self._pareto_front) == 0:\n",
    "            return [self._best_equation] if self._best_equation else []\n",
    "        \n",
    "        return list(self._pareto_front['equation'].astype(str))\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using the best discovered equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Predictions\n",
    "        \"\"\"\n",
    "        if not self._discovery_complete:\n",
    "            raise RuntimeError(\"Must run discover() first\")\n",
    "        \n",
    "        if self.model is not None and PYSR_AVAILABLE:\n",
    "            if self.precision == 32:\n",
    "                return self.model.predict(X.astype(np.float32))\n",
    "            return self.model.predict(X)\n",
    "        else:\n",
    "            # Fallback: use StructureParser\n",
    "            parser = StructureParser()\n",
    "            terms = parser.parse_single_equation(\n",
    "                self._best_equation, self._feature_names, X\n",
    "            )\n",
    "            if len(terms) > 0:\n",
    "                result = np.zeros(X.shape[0])\n",
    "                for expr, name, func in terms:\n",
    "                    try:\n",
    "                        result += func(*[X[:, i] for i in range(X.shape[1])])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                return result\n",
    "            return np.zeros(X.shape[0])\n",
    "    \n",
    "    def print_discovery_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print a detailed discovery report in v4.1 format.\n",
    "        \"\"\"\n",
    "        if not self._discovery_complete:\n",
    "            print(\"Discovery not yet performed. Run discover() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"=== PySR Discovery (v4.1) ===\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Mode: {self.mode}\")\n",
    "        print(f\"Timeout: {self.timeout_seconds}s\")\n",
    "        print(f\"Elapsed: {self.elapsed_time:.1f}s\")\n",
    "        print(f\"PySR available: {PYSR_AVAILABLE}\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\"Configuration:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  Binary operators: {self.binary_operators}\")\n",
    "        print(f\"  Unary operators: {self.unary_operators}\")\n",
    "        print(f\"  Turbo mode: {self.turbo}\")\n",
    "        print(f\"  Precision: {self.precision}-bit\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\"Best Equation:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  {self._best_equation}\")\n",
    "        print(f\"  Complexity: {self._best_complexity}\")\n",
    "        print(f\"  Loss (MSE): {self._best_loss:.6f}\")\n",
    "        if self._best_r2 is not None:\n",
    "            print(f\"  R-squared: {self._best_r2:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        if self._pareto_front is not None and len(self._pareto_front) > 0:\n",
    "            print(\"-\" * 70)\n",
    "            print(\"Pareto Front:\")\n",
    "            print(\"-\" * 70)\n",
    "            for _, row in self._pareto_front.iterrows():\n",
    "                eq_str = str(row['equation'])[:50]\n",
    "                print(f\"  Complexity {int(row['complexity']):2d}: {eq_str} (loss: {row['loss']:.6f})\")\n",
    "        \n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "print(\"PySRDiscoverer class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: StructureParser Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STRUCTURE PARSER CLASS (v4.0/v4.1 ENHANCED)\n",
    "# ==============================================================================\n",
    "\n",
    "class StructureParser:\n",
    "    \"\"\"\n",
    "    Structure Parser for extracting terms from PySR equations (v4.0/v4.1).\n",
    "    \n",
    "    Parses PySR equations to extract exact functional terms for\n",
    "    augmented library construction (Layer 1 and operator detection for Layer 4).\n",
    "    \n",
    "    v4.1 Key Features:\n",
    "    - parse_pareto_equations(): Parse multiple equations from Pareto front\n",
    "    - Automatic operator detection for Layer 4 terms\n",
    "    - Returns (unique_terms, detected_operators, term_map)\n",
    "    - unique_terms format: List[(sympy_expr, name_str, eval_function)]\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    None (stateless parser)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    parse_pareto_equations(equations, feature_names, X) -> Tuple\n",
    "        Parse multiple equations from Pareto front\n",
    "    parse_single_equation(equation_str, feature_names, X) -> List\n",
    "        Parse a single equation string\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Framework v4.0/v4.1 Section 4.2: Structure Parsing\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> parser = StructureParser()\n",
    "    >>> terms, operators, term_map = parser.parse_pareto_equations(\n",
    "    ...     equations=['0.5*x**2 + sin(z)'],\n",
    "    ...     feature_names=['x', 'y', 'z'],\n",
    "    ...     X=X_data\n",
    "    ... )\n",
    "    >>> print(f\"Detected operators: {operators}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize StructureParser.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def parse_pareto_equations(\n",
    "        self,\n",
    "        equations: List[str],\n",
    "        feature_names: List[str],\n",
    "        X: np.ndarray\n",
    "    ) -> Tuple[List[Tuple], Set[str], Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Parse multiple equations from Pareto front.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        equations : List[str]\n",
    "            Equation strings from PySR Pareto front\n",
    "        feature_names : List[str]\n",
    "            Variable names\n",
    "        X : np.ndarray\n",
    "            Feature matrix for evaluation testing\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        unique_terms : List[Tuple]\n",
    "            List of (sympy_expr, name_str, eval_function)\n",
    "        detected_operators : Set[str]\n",
    "            Set of operators found {'sin', 'cos', 'exp', 'sqrt', 'log'}\n",
    "        term_to_equation_map : Dict[str, str]\n",
    "            Mapping from term names to source equations\n",
    "        \"\"\"\n",
    "        all_terms = []\n",
    "        detected_operators = set()\n",
    "        term_to_equation_map = {}\n",
    "        \n",
    "        # Create local dictionary for parsing\n",
    "        local_dict = self._create_local_dict(feature_names)\n",
    "        symbols_list = [Symbol(name) for name in feature_names]\n",
    "        \n",
    "        for equation_str in equations:\n",
    "            try:\n",
    "                # Clean and parse equation\n",
    "                equation_str = equation_str.strip().replace('^', '**')\n",
    "                expr = sympify(equation_str, locals=local_dict)\n",
    "                \n",
    "                # Expand expression\n",
    "                expr = sp.expand(expr)\n",
    "                \n",
    "                # Decompose into additive terms\n",
    "                if isinstance(expr, Add):\n",
    "                    terms = list(expr.args)\n",
    "                else:\n",
    "                    terms = [expr]\n",
    "                \n",
    "                # Process each term\n",
    "                for term in terms:\n",
    "                    # Extract coefficient and functional part\n",
    "                    coef, functional = term.as_coeff_Mul()\n",
    "                    \n",
    "                    # Skip pure constants\n",
    "                    if functional.is_number or functional == 1:\n",
    "                        continue\n",
    "                    \n",
    "                    # Detect operators in this term\n",
    "                    term_operators = self._detect_operators(functional)\n",
    "                    detected_operators.update(term_operators)\n",
    "                    \n",
    "                    # Create evaluation function\n",
    "                    try:\n",
    "                        eval_func = lambdify(symbols_list, functional, modules=['numpy'])\n",
    "                        \n",
    "                        # Test evaluability\n",
    "                        test_values = eval_func(*[X[:10, i] for i in range(X.shape[1])])\n",
    "                        if not np.all(np.isfinite(test_values)):\n",
    "                            continue\n",
    "                        \n",
    "                        # Add to collection\n",
    "                        term_name = str(functional)\n",
    "                        all_terms.append((functional, term_name, eval_func))\n",
    "                        term_to_equation_map[term_name] = equation_str\n",
    "                        \n",
    "                    except Exception:\n",
    "                        continue\n",
    "                        \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Deduplicate terms\n",
    "        unique_terms = self._deduplicate_terms(all_terms)\n",
    "        \n",
    "        return unique_terms, detected_operators, term_to_equation_map\n",
    "    \n",
    "    def parse_single_equation(\n",
    "        self,\n",
    "        equation_str: str,\n",
    "        feature_names: List[str],\n",
    "        X: np.ndarray\n",
    "    ) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Parse a single equation string.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        equation_str : str\n",
    "            Equation string to parse\n",
    "        feature_names : List[str]\n",
    "            Variable names\n",
    "        X : np.ndarray\n",
    "            Feature matrix for evaluation testing\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple]\n",
    "            List of (sympy_expr, name_str, eval_function)\n",
    "        \"\"\"\n",
    "        terms, _, _ = self.parse_pareto_equations([equation_str], feature_names, X)\n",
    "        return terms\n",
    "    \n",
    "    def _create_local_dict(self, feature_names: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Create symbol mapping for SymPy parsing.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_names : List[str]\n",
    "            Variable names\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Local dictionary for sympify\n",
    "        \"\"\"\n",
    "        local_dict = {name: Symbol(name) for name in feature_names}\n",
    "        local_dict.update({\n",
    "            'sqrt': sp.sqrt,\n",
    "            'exp': sp.exp,\n",
    "            'log': sp.log,\n",
    "            'sin': sp.sin,\n",
    "            'cos': sp.cos,\n",
    "            'abs': sp.Abs,\n",
    "            'tan': sp.tan\n",
    "        })\n",
    "        return local_dict\n",
    "    \n",
    "    def _detect_operators(self, expr: sp.Expr) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Detect which operators are used in expression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        expr : sp.Expr\n",
    "            SymPy expression\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Set[str]\n",
    "            Set of operator names found\n",
    "        \"\"\"\n",
    "        operators = set()\n",
    "        \n",
    "        operator_map = [\n",
    "            (sp.sin, 'sin'),\n",
    "            (sp.cos, 'cos'),\n",
    "            (sp.exp, 'exp'),\n",
    "            (sp.log, 'log'),\n",
    "            (sp.sqrt, 'sqrt'),\n",
    "            (sp.tan, 'tan'),\n",
    "            (sp.Abs, 'abs')\n",
    "        ]\n",
    "        \n",
    "        for func_type, name in operator_map:\n",
    "            if expr.has(func_type):\n",
    "                operators.add(name)\n",
    "        \n",
    "        return operators\n",
    "    \n",
    "    def _deduplicate_terms(\n",
    "        self,\n",
    "        terms: List[Tuple]\n",
    "    ) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Remove duplicate terms based on simplified expression.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        terms : List[Tuple]\n",
    "            List of (expr, name, func) tuples\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple]\n",
    "            Deduplicated list\n",
    "        \"\"\"\n",
    "        seen_exprs = set()\n",
    "        unique_terms = []\n",
    "        \n",
    "        for expr, name, func in terms:\n",
    "            try:\n",
    "                expr_key = str(sp.simplify(expr))\n",
    "                if expr_key not in seen_exprs:\n",
    "                    seen_exprs.add(expr_key)\n",
    "                    unique_terms.append((expr, name, func))\n",
    "            except Exception:\n",
    "                # If simplification fails, use string representation\n",
    "                if name not in seen_exprs:\n",
    "                    seen_exprs.add(name)\n",
    "                    unique_terms.append((expr, name, func))\n",
    "        \n",
    "        return unique_terms\n",
    "    \n",
    "    def _safe_evaluate(\n",
    "        self,\n",
    "        expr: sp.Expr,\n",
    "        X: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Safely evaluate a SymPy expression on data.\n",
    "        \n",
    "        Handles numerical edge cases (overflow, division by zero, etc.).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        expr : sp.Expr\n",
    "            SymPy expression\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        feature_names : List[str]\n",
    "            Variable names\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Optional[np.ndarray]\n",
    "            Evaluated values or None if evaluation fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            symbols_list = [Symbol(name) for name in feature_names]\n",
    "            func = lambdify(symbols_list, expr, modules=['numpy'])\n",
    "            values = func(*[X[:, i] for i in range(X.shape[1])])\n",
    "            \n",
    "            # Check for numerical issues\n",
    "            if not np.all(np.isfinite(values)):\n",
    "                return None\n",
    "            \n",
    "            return values\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "print(\"StructureParser class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 06_PySR v4.1\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: PySRDiscoverer Mode Configuration\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: PySRDiscoverer Mode Configuration\")\n",
    "    \n",
    "    # Test each mode configuration\n",
    "    for mode in ['fast', 'standard', 'thorough']:\n",
    "        discoverer = PySRDiscoverer(mode=mode)\n",
    "        print(f\"Mode: {mode}\")\n",
    "        print(f\"  Timeout: {discoverer.timeout_seconds}s\")\n",
    "        print(f\"  Turbo: {discoverer.turbo}\")\n",
    "        print(f\"  Precision: {discoverer.precision}-bit\")\n",
    "        print()\n",
    "    \n",
    "    print(\"[PASS] All modes configured correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: PySR Discovery (Fallback Mode)\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: PySR Discovery (Fallback Mode)\")\n",
    "    \n",
    "    # Generate test data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    x = np.random.uniform(0.5, 2, n_samples)\n",
    "    y_var = np.random.uniform(0.5, 2, n_samples)\n",
    "    z = np.random.uniform(0.5, 2, n_samples)\n",
    "    \n",
    "    y = 0.5 * x**2 + np.sin(z) + 0.01 * np.random.randn(n_samples)\n",
    "    \n",
    "    X = np.column_stack([x, y_var, z])\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Run discovery (will use fallback if PySR not available)\n",
    "    discoverer = PySRDiscoverer(mode='fast')\n",
    "    result = discoverer.discover(X, y, feature_names)\n",
    "    \n",
    "    print(f\"Best equation: {result['best_equation']}\")\n",
    "    print(f\"Elapsed time: {result['elapsed_time']:.1f}s\")\n",
    "    print(f\"PySR available: {result['pysr_available']}\")\n",
    "    print(f\"Mode: {result['mode']}\")\n",
    "    if result['best_r2'] is not None:\n",
    "        print(f\"R-squared: {result['best_r2']:.4f}\")\n",
    "    \n",
    "    discoverer.print_discovery_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: StructureParser - Multi-Equation Parsing\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: StructureParser - Multi-Equation Parsing\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    x = np.random.uniform(0.5, 2, n_samples)\n",
    "    y_var = np.random.uniform(0.5, 2, n_samples)\n",
    "    z = np.random.uniform(0.5, 2, n_samples)\n",
    "    \n",
    "    X = np.column_stack([x, y_var, z])\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Simulated Pareto front equations\n",
    "    equations = [\n",
    "        '0.5*x**2',\n",
    "        '0.5*x**2 + sin(z)',\n",
    "        '0.5*x**2 + 0.98*sin(z) + 0.01*y'\n",
    "    ]\n",
    "    \n",
    "    print(f\"Input equations: {len(equations)}\")\n",
    "    for eq in equations:\n",
    "        print(f\"  {eq}\")\n",
    "    print()\n",
    "    \n",
    "    parser = StructureParser()\n",
    "    unique_terms, detected_operators, term_map = parser.parse_pareto_equations(\n",
    "        equations, feature_names, X\n",
    "    )\n",
    "    \n",
    "    print(f\"=== Structure Parsing ===\")\n",
    "    print(f\"Parsed terms: {len(unique_terms)}\")\n",
    "    for expr, name, func in unique_terms:\n",
    "        print(f\"  - {name}\")\n",
    "    print()\n",
    "    print(f\"Detected operators: {detected_operators}\")\n",
    "    \n",
    "    # Verify operator detection\n",
    "    if 'sin' in detected_operators:\n",
    "        print(\"[PASS] sin operator detected\")\n",
    "    else:\n",
    "        print(\"[WARNING] sin operator not detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: StructureParser - Operator Detection\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: StructureParser - Operator Detection\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    y_var = np.random.uniform(0.1, 2, n_samples)\n",
    "    \n",
    "    X = np.column_stack([x, y_var])\n",
    "    feature_names = ['x', 'y']\n",
    "    \n",
    "    # Test various operators\n",
    "    test_equations = [\n",
    "        ('sin(x) + cos(y)', {'sin', 'cos'}),\n",
    "        ('exp(x) + log(y)', {'exp', 'log'}),\n",
    "        ('sqrt(x) + x**2', {'sqrt'}),\n",
    "        ('x + y', set())\n",
    "    ]\n",
    "    \n",
    "    parser = StructureParser()\n",
    "    \n",
    "    print(f\"{'Equation':<30} {'Expected':<20} {'Detected':<20} {'Status'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_pass = True\n",
    "    for eq, expected in test_equations:\n",
    "        _, detected, _ = parser.parse_pareto_equations([eq], feature_names, X)\n",
    "        status = \"PASS\" if detected == expected else \"FAIL\"\n",
    "        if status == \"FAIL\":\n",
    "            all_pass = False\n",
    "        print(f\"{eq:<30} {str(expected):<20} {str(detected):<20} [{status}]\")\n",
    "    \n",
    "    print()\n",
    "    if all_pass:\n",
    "        print(\"[PASS] All operator detection tests passed\")\n",
    "    else:\n",
    "        print(\"[WARNING] Some operator detection tests failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Evaluation Function Correctness\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 5: Evaluation Function Correctness\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 50\n",
    "    \n",
    "    x = np.random.uniform(0.5, 2, n_samples)\n",
    "    y_var = np.random.uniform(0.5, 2, n_samples)\n",
    "    \n",
    "    X = np.column_stack([x, y_var])\n",
    "    feature_names = ['x', 'y']\n",
    "    \n",
    "    equation = 'x**2 + sin(y)'\n",
    "    expected = x**2 + np.sin(y_var)\n",
    "    \n",
    "    parser = StructureParser()\n",
    "    terms, _, _ = parser.parse_pareto_equations([equation], feature_names, X)\n",
    "    \n",
    "    print(f\"Equation: {equation}\")\n",
    "    print(f\"Parsed {len(terms)} terms\")\n",
    "    \n",
    "    # Evaluate each term\n",
    "    result = np.zeros(n_samples)\n",
    "    for expr, name, func in terms:\n",
    "        values = func(x, y_var)\n",
    "        print(f\"  {name}: mean = {np.mean(values):.4f}\")\n",
    "        result += values\n",
    "    \n",
    "    # Check correctness\n",
    "    error = np.mean(np.abs(result - expected))\n",
    "    print()\n",
    "    print(f\"Mean absolute error: {error:.6f}\")\n",
    "    \n",
    "    if error < 1e-6:\n",
    "        print(\"[PASS] Evaluation functions are correct\")\n",
    "    else:\n",
    "        print(\"[WARNING] Evaluation functions may have issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 06_PySR.ipynb v4.1 - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASSES:\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"1. PySRDiscoverer (v4.1 Enhanced)\")\n",
    "print(\"   Purpose: Symbolic regression via genetic programming\")\n",
    "print(\"   v4.1 Features:\")\n",
    "print(\"     - Mode-based configuration: 'fast', 'standard', 'thorough'\")\n",
    "print(\"     - Hard timeout with elapsed_time tracking\")\n",
    "print(\"     - Float32 precision and turbo mode\")\n",
    "print(\"   Main Methods:\")\n",
    "print(\"     discover(X, y, feature_names) -> Dict with elapsed_time, best_r2\")\n",
    "print(\"     get_pareto_equations() -> List[str]\")\n",
    "print(\"     predict(X) -> np.ndarray\")\n",
    "print(\"     print_discovery_report()\")\n",
    "print()\n",
    "print(\"2. StructureParser (v4.1 Enhanced)\")\n",
    "print(\"   Purpose: Parse equations for augmented library construction\")\n",
    "print(\"   v4.1 Features:\")\n",
    "print(\"     - Multi-equation Pareto parsing\")\n",
    "print(\"     - Automatic operator detection for Layer 4\")\n",
    "print(\"     - Returns (unique_terms, detected_operators, term_map)\")\n",
    "print(\"   Main Methods:\")\n",
    "print(\"     parse_pareto_equations(equations, feature_names, X) -> Tuple\")\n",
    "print(\"     parse_single_equation(equation_str, feature_names, X) -> List\")\n",
    "print()\n",
    "print(f\"PySR Status: {'Available' if PYSR_AVAILABLE else 'Not available (fallback mode)'}\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Discover equations with PySR\n",
    "discoverer = PySRDiscoverer(mode='standard')\n",
    "result = discoverer.discover(X, y, feature_names)\n",
    "print(f\"Best equation: {result['best_equation']}\")\n",
    "print(f\"Elapsed: {result['elapsed_time']:.1f}s\")\n",
    "print(f\"R-squared: {result['best_r2']:.4f}\")\n",
    "\n",
    "# Parse for augmented library construction\n",
    "parser = StructureParser()\n",
    "unique_terms, detected_operators, term_map = parser.parse_pareto_equations(\n",
    "    result['all_equations'], feature_names, X\n",
    ")\n",
    "print(f\"Detected operators: {detected_operators}\")\n",
    "\n",
    "# Use with AugmentedLibraryBuilder\n",
    "builder = AugmentedLibraryBuilder()\n",
    "Phi, names, info = builder.build(\n",
    "    X, feature_names,\n",
    "    parsed_terms=unique_terms,\n",
    "    detected_operators=detected_operators,\n",
    "    pysr_r2=result['best_r2']\n",
    ")\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 06_PySR.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

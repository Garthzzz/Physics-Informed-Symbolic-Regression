{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12_Full_Pipeline - Physics-SR Framework v4.1\n",
    "\n",
    "## Complete Pipeline Integration with Adaptive Time Budget\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (Structure-Guided Feature Library Enhancement + Computational Optimization)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Integrate all components into a complete, end-to-end symbolic regression pipeline with:\n",
    "\n",
    "**Stage 1: Variable Selection & Preprocessing**\n",
    "- Buckingham Pi dimensional analysis\n",
    "- PAN+SR nonlinear variable screening\n",
    "- Power-law symmetry detection\n",
    "- iRF interaction discovery\n",
    "\n",
    "**Stage 2: Structure-Guided Discovery (v4.0/v4.1 Redesign)**\n",
    "- PySR structure exploration with adaptive timeout\n",
    "- Structure parsing (NEW v4.0)\n",
    "- 4-layer augmented library construction (NEW v4.0)\n",
    "- E-WSINDy sparse selection with source attribution\n",
    "- Adaptive Lasso verification (conditional)\n",
    "\n",
    "**Stage 3: Validation & UQ**\n",
    "- Model selection (CV + EBIC)\n",
    "- Physics verification (dimensional + bounds)\n",
    "- Three-layer bootstrap UQ with adaptive count\n",
    "- Statistical inference\n",
    "\n",
    "### v4.1 Key Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| TimeBudgetManager | Adaptive time allocation across stages |\n",
    "| Structure-Guided Library | PySR terms feed directly into E-WSINDy |\n",
    "| Source Attribution | Track which library layer contributed each term |\n",
    "| Timing Profile | Detailed timing report for optimization |\n",
    "| Float32 Precision | Reduced memory footprint |\n",
    "| Adaptive Bootstrap | Bootstrap count adjusts to remaining budget |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "12_Full_Pipeline.ipynb - Complete Pipeline Integration v4.1\n",
    "============================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v4.1\n",
    "\n",
    "This module provides:\n",
    "- PhysicsSRPipeline: Complete end-to-end pipeline with TimeBudgetManager\n",
    "- Stage-by-stage execution with timing checkpoints\n",
    "- Structure-guided discovery (PySR -> Parser -> Library -> E-WSINDy)\n",
    "- Comprehensive result reporting with source attribution\n",
    "\n",
    "Usage:\n",
    "    pipeline = PhysicsSRPipeline(max_time_seconds=180)\n",
    "    result = pipeline.run(X, y, feature_names, user_inputs)\n",
    "    print(pipeline.get_timing_report())\n",
    "    pipeline.print_summary()\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "\"\"\"\n",
    "\n",
    "print(\"Loading all component modules...\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORT ALL COMPONENT MODULES\n",
    "# ==============================================================================\n",
    "\n",
    "%run 00_Core.ipynb\n",
    "%run 01_BuckinghamPi.ipynb\n",
    "%run 02_VariableScreening.ipynb\n",
    "%run 03_SymmetryAnalysis.ipynb\n",
    "%run 04_InteractionDiscovery.ipynb\n",
    "%run 05_FeatureLibrary.ipynb\n",
    "%run 06_PySR.ipynb\n",
    "%run 07_EWSINDy_STLSQ.ipynb\n",
    "%run 08_AdaptiveLasso.ipynb\n",
    "%run 09_ModelSelection.ipynb\n",
    "%run 10_PhysicsVerification.ipynb\n",
    "%run 11_UQ_Inference.ipynb\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\" All modules loaded successfully! (Physics-SR Framework v4.1)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VERIFY ALL CLASSES ARE AVAILABLE\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Verifying component classes (v4.1)...\")\n",
    "print()\n",
    "\n",
    "components = [\n",
    "    # Core\n",
    "    ('UserInputs', '00_Core'),\n",
    "    ('Stage1Results', '00_Core'),\n",
    "    ('Stage2Results', '00_Core'),\n",
    "    ('Stage3Results', '00_Core'),\n",
    "    ('TimeBudgetManager', '00_Core'),\n",
    "    # Stage 1\n",
    "    ('BuckinghamPiAnalyzer', '01_BuckinghamPi'),\n",
    "    ('PANSRVariableScreener', '02_VariableScreening'),\n",
    "    ('SymmetryAnalyzer', '03_SymmetryAnalysis'),\n",
    "    ('IRFInteractionDiscoverer', '04_InteractionDiscovery'),\n",
    "    # Stage 2 (v4.0/v4.1 redesign)\n",
    "    ('AugmentedLibraryBuilder', '05_FeatureLibrary'),\n",
    "    ('PySRDiscoverer', '06_PySR'),\n",
    "    ('StructureParser', '06_PySR'),\n",
    "    ('EWSINDySTLSQ', '07_EWSINDy_STLSQ'),\n",
    "    ('AdaptiveLassoSelector', '08_AdaptiveLasso'),\n",
    "    # Stage 3\n",
    "    ('ModelSelector', '09_ModelSelection'),\n",
    "    ('PhysicsVerifier', '10_PhysicsVerification'),\n",
    "    ('BootstrapUQ', '11_UQ_Inference'),\n",
    "    ('StatisticalInference', '11_UQ_Inference')\n",
    "]\n",
    "\n",
    "all_loaded = True\n",
    "for class_name, module in components:\n",
    "    if class_name in dir():\n",
    "        print(f\"  [OK] {class_name} from {module}\")\n",
    "    else:\n",
    "        print(f\"  [MISSING] {class_name} from {module}\")\n",
    "        all_loaded = False\n",
    "\n",
    "print()\n",
    "if all_loaded:\n",
    "    print(\"All components verified successfully!\")\n",
    "else:\n",
    "    print(\"WARNING: Some components missing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: PhysicsSRPipeline Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PHYSICS SR PIPELINE CLASS (v4.1)\n",
    "# ==============================================================================\n",
    "\n",
    "class PhysicsSRPipeline:\n",
    "    \"\"\"\n",
    "    Complete Physics-Informed Symbolic Regression Pipeline (v4.1).\n",
    "    \n",
    "    Orchestrates all stages with:\n",
    "    - Adaptive time budget management (v4.1)\n",
    "    - Structure-guided feature library (v4.0)\n",
    "    - Source attribution for selected terms\n",
    "    - Comprehensive timing profile\n",
    "    \n",
    "    Pipeline Flow (v4.1):\n",
    "    ----------------------\n",
    "    Stage 1: Variable Selection\n",
    "        1.1 Buckingham Pi -> dimensional reduction\n",
    "        1.2 PAN+SR -> variable importance\n",
    "        1.3 Symmetry -> power-law detection\n",
    "        1.4 iRF -> interaction discovery\n",
    "    \n",
    "    Stage 2: Structure-Guided Discovery (v4.0/v4.1)\n",
    "        2.1 PySR -> structure exploration (adaptive timeout)\n",
    "        2.2 Parser -> extract terms and operators\n",
    "        2.3 Library -> 4-layer augmented construction\n",
    "        2.4 E-WSINDy -> sparse selection with source attribution\n",
    "        2.5 ALasso -> verification (conditional on budget)\n",
    "    \n",
    "    Stage 3: Validation & UQ\n",
    "        3.1 Selection -> CV + EBIC comparison\n",
    "        3.2 Physics -> dimensional + bounds verification\n",
    "        3.3 Bootstrap -> three-layer UQ (adaptive count)\n",
    "        3.4 Inference -> hypothesis testing\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    config : Dict\n",
    "        Pipeline configuration parameters\n",
    "    budget_manager : TimeBudgetManager\n",
    "        Time budget controller (v4.1)\n",
    "    stage1_results : Stage1Results\n",
    "        Results from Stage 1\n",
    "    stage2_results : Stage2Results\n",
    "        Results from Stage 2 (v4.1 enhanced)\n",
    "    stage3_results : Stage3Results\n",
    "        Results from Stage 3\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> pipeline = PhysicsSRPipeline(max_time_seconds=180)\n",
    "    >>> result = pipeline.run(X, y, feature_names, user_inputs)\n",
    "    >>> print(pipeline.get_timing_report())\n",
    "    >>> print(f\"Final equation: {pipeline.get_final_equation()}\")\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Framework v4.1 Section 6: Pipeline Integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Dict = None,\n",
    "        max_time_seconds: float = DEFAULT_RUNTIME_BUDGET\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize PhysicsSRPipeline.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        config : Dict, optional\n",
    "            Configuration overrides. If None, uses defaults.\n",
    "        max_time_seconds : float\n",
    "            Total runtime budget in seconds (v4.1).\n",
    "            Default: 180 (optimized for Google Colab Pro)\n",
    "        \"\"\"\n",
    "        self.config = self._merge_config(config or {})\n",
    "        self.budget_manager = TimeBudgetManager(max_time_seconds)\n",
    "        \n",
    "        # Results storage\n",
    "        self.stage1_results = None\n",
    "        self.stage2_results = None\n",
    "        self.stage3_results = None\n",
    "        self._final_equation = None\n",
    "        self._run_complete = False\n",
    "        \n",
    "        # Working data (cleared after run)\n",
    "        self._X_work = None\n",
    "        self._feature_names_work = None\n",
    "    \n",
    "    def _merge_config(self, user_config: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Merge user config with defaults.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        user_config : Dict\n",
    "            User-provided configuration\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            Complete configuration with defaults\n",
    "        \"\"\"\n",
    "        defaults = {\n",
    "            # Stage 1\n",
    "            'max_exponent': DEFAULT_MAX_EXPONENT,\n",
    "            'importance_threshold': DEFAULT_IMPORTANCE_THRESHOLD,\n",
    "            'powerlaw_r2_threshold': DEFAULT_POWERLAW_R2_THRESHOLD,\n",
    "            'stability_threshold': DEFAULT_STABILITY_THRESHOLD,\n",
    "            \n",
    "            # Stage 2\n",
    "            'pysr_mode': 'standard',\n",
    "            'max_poly_degree': DEFAULT_MAX_POLY_DEGREE,\n",
    "            'stlsq_threshold': DEFAULT_STLSQ_THRESHOLD,\n",
    "            'alasso_gamma': DEFAULT_ALASSO_GAMMA,\n",
    "            'generate_variants': True,\n",
    "            'include_operator_terms': True,\n",
    "            \n",
    "            # Stage 3\n",
    "            'cv_folds': DEFAULT_CV_FOLDS,\n",
    "            'ebic_gamma': DEFAULT_EBIC_GAMMA,\n",
    "            'n_bootstrap': DEFAULT_N_BOOTSTRAP,\n",
    "            'confidence_level': DEFAULT_CONFIDENCE_LEVEL,\n",
    "            'dim_tolerance': DEFAULT_DIM_TOLERANCE,\n",
    "            \n",
    "            # v4.1 Computational\n",
    "            'n_jobs': DEFAULT_PROCS,\n",
    "            'precision': DEFAULT_PRECISION,\n",
    "            'skip_alasso_if_tight': True,\n",
    "            'verbose': True\n",
    "        }\n",
    "        \n",
    "        defaults.update(user_config)\n",
    "        return defaults\n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str],\n",
    "        user_inputs: UserInputs = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute complete pipeline.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector (n_samples,)\n",
    "        feature_names : List[str]\n",
    "            Feature names\n",
    "        user_inputs : UserInputs, optional\n",
    "            User-provided physics information\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Complete pipeline results including:\n",
    "            - stage1: Stage1Results\n",
    "            - stage2: Stage2Results (v4.1 enhanced)\n",
    "            - stage3: Stage3Results\n",
    "            - final_equation: str\n",
    "            - timing: Dict[str, float]\n",
    "        \"\"\"\n",
    "        if self.config['verbose']:\n",
    "            print(\"=\" * 70)\n",
    "            print(\" Physics-SR Pipeline v4.1\")\n",
    "            print(\"=\" * 70)\n",
    "            print(f\"Total budget: {self.budget_manager.total_budget}s\")\n",
    "            print()\n",
    "        \n",
    "        # Convert to Float32 for memory efficiency (v4.1)\n",
    "        X, y = convert_to_float32(X, y)\n",
    "        feature_names = list(feature_names)\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STAGE 1: Variable Selection & Preprocessing\n",
    "        # =====================================================================\n",
    "        if self.config['verbose']:\n",
    "            print(\"STAGE 1: Variable Selection & Preprocessing\")\n",
    "            print(\"-\" * 70)\n",
    "        \n",
    "        self.stage1_results = self._run_stage1(X, y, feature_names, user_inputs)\n",
    "        self.budget_manager.record_stage('Stage1')\n",
    "        cleanup_memory()\n",
    "        \n",
    "        if self.config['verbose']:\n",
    "            print(f\"  [Timing] Stage 1: {self.budget_manager.get_stage_duration('Stage1'):.1f}s\")\n",
    "            print()\n",
    "        \n",
    "        # Get working features based on Stage 1 results\n",
    "        self._X_work, self._feature_names_work = self._select_working_features(\n",
    "            X, feature_names, self.stage1_results\n",
    "        )\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STAGE 2: Structure-Guided Discovery (v4.0/v4.1)\n",
    "        # =====================================================================\n",
    "        if self.config['verbose']:\n",
    "            print(\"STAGE 2: Structure-Guided Discovery\")\n",
    "            print(\"-\" * 70)\n",
    "        \n",
    "        self.stage2_results = self._run_stage2(\n",
    "            self._X_work, y, self._feature_names_work, self.stage1_results\n",
    "        )\n",
    "        self.budget_manager.record_stage('Stage2')\n",
    "        cleanup_memory()\n",
    "        \n",
    "        if self.config['verbose']:\n",
    "            print(f\"  [Timing] Stage 2: {self.budget_manager.get_stage_duration('Stage2'):.1f}s\")\n",
    "            print()\n",
    "        \n",
    "        # =====================================================================\n",
    "        # STAGE 3: Validation & Uncertainty Quantification\n",
    "        # =====================================================================\n",
    "        if self.config['verbose']:\n",
    "            print(\"STAGE 3: Validation & Uncertainty Quantification\")\n",
    "            print(\"-\" * 70)\n",
    "        \n",
    "        self.stage3_results = self._run_stage3(\n",
    "            self._X_work, y, self._feature_names_work,\n",
    "            self.stage2_results, user_inputs\n",
    "        )\n",
    "        self.budget_manager.record_stage('Stage3')\n",
    "        \n",
    "        if self.config['verbose']:\n",
    "            print(f\"  [Timing] Stage 3: {self.budget_manager.get_stage_duration('Stage3'):.1f}s\")\n",
    "            print()\n",
    "        \n",
    "        # =====================================================================\n",
    "        # FINAL: Extract equation and compile results\n",
    "        # =====================================================================\n",
    "        self._final_equation = self._extract_final_equation()\n",
    "        self._run_complete = True\n",
    "        \n",
    "        # Clear working data\n",
    "        self._X_work = None\n",
    "        self._feature_names_work = None\n",
    "        cleanup_memory()\n",
    "        \n",
    "        if self.config['verbose']:\n",
    "            print(\"=\" * 70)\n",
    "            print(\" Pipeline Complete!\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(self.get_timing_report())\n",
    "        \n",
    "        return {\n",
    "            'stage1': self.stage1_results,\n",
    "            'stage2': self.stage2_results,\n",
    "            'stage3': self.stage3_results,\n",
    "            'final_equation': self._final_equation,\n",
    "            'timing': self.budget_manager.to_dict()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STAGE 1 IMPLEMENTATION\n",
    "# ==============================================================================\n",
    "\n",
    "def _run_stage1(\n",
    "    self,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    user_inputs: UserInputs\n",
    ") -> Stage1Results:\n",
    "    \"\"\"\n",
    "    Execute Stage 1: Variable Selection & Preprocessing.\n",
    "    \n",
    "    Sub-stages:\n",
    "    - 1.1 Buckingham Pi dimensional analysis\n",
    "    - 1.2 PAN+SR variable screening\n",
    "    - 1.3 Power-law symmetry detection\n",
    "    - 1.4 iRF interaction discovery\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix\n",
    "    y : np.ndarray\n",
    "        Target vector\n",
    "    feature_names : List[str]\n",
    "        Feature names\n",
    "    user_inputs : UserInputs\n",
    "        User-provided physics information\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Stage1Results\n",
    "        Complete Stage 1 results\n",
    "    \"\"\"\n",
    "    timing = {}\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Initialize results\n",
    "    results = Stage1Results()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1.1 Buckingham Pi Analysis\n",
    "    # -------------------------------------------------------------------------\n",
    "    if user_inputs and user_inputs.variable_dimensions:\n",
    "        if self.config['verbose']:\n",
    "            print(\"  1.1 Buckingham Pi Analysis...\")\n",
    "        \n",
    "        pi_analyzer = BuckinghamPiAnalyzer(\n",
    "            max_exponent=self.config['max_exponent']\n",
    "        )\n",
    "        \n",
    "        # Filter dimensions to only include available features\n",
    "        available_dims = {\n",
    "            k: v for k, v in user_inputs.variable_dimensions.items()\n",
    "            if k in feature_names\n",
    "        }\n",
    "        \n",
    "        if len(available_dims) >= 2:\n",
    "            pi_result = pi_analyzer.analyze(available_dims)\n",
    "            \n",
    "            results.pi_groups = pi_result.get('pi_groups')\n",
    "            results.pi_exponents = pi_result.get('pi_exponents')\n",
    "            results.pi_group_names = pi_result.get('pi_group_names')\n",
    "            results.X_transformed = pi_result.get('X_transformed')\n",
    "            results.all_pi_candidates = pi_result.get('all_pi_candidates')\n",
    "            \n",
    "            if self.config['verbose']:\n",
    "                n_groups = pi_result.get('n_pi_groups', 0)\n",
    "                print(f\"      Reduced from {len(feature_names)} to {n_groups} Pi groups\")\n",
    "        else:\n",
    "            if self.config['verbose']:\n",
    "                print(\"      Skipped (insufficient dimensional info)\")\n",
    "    else:\n",
    "        if self.config['verbose']:\n",
    "            print(\"  1.1 Buckingham Pi: Skipped (no dimensions provided)\")\n",
    "    \n",
    "    timing['buckingham_pi'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1.2 PAN+SR Variable Screening\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  1.2 PAN+SR Variable Screening...\")\n",
    "    \n",
    "    screener = PANSRVariableScreener(\n",
    "        importance_threshold=self.config['importance_threshold']\n",
    "    )\n",
    "    screening_result = screener.screen(X, y, feature_names)\n",
    "    \n",
    "    results.selected_indices = screening_result.get('selected_indices', [])\n",
    "    results.selected_names = screening_result.get('selected_names', [])\n",
    "    results.importance_scores = screening_result.get('importance_scores', {})\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        n_selected = len(results.selected_names)\n",
    "        print(f\"      Selected {n_selected} of {len(feature_names)} variables\")\n",
    "    \n",
    "    timing['screening'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1.3 Symmetry Analysis (Power-Law Detection)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  1.3 Power-Law Symmetry Detection...\")\n",
    "    \n",
    "    symmetry_analyzer = SymmetryAnalyzer(\n",
    "        r2_threshold=self.config['powerlaw_r2_threshold']\n",
    "    )\n",
    "    symmetry_result = symmetry_analyzer.analyze(X, y, feature_names)\n",
    "    \n",
    "    results.is_power_law = symmetry_result.get('is_power_law', False)\n",
    "    results.estimated_exponents = symmetry_result.get('exponents', {})\n",
    "    results.power_law_r2 = symmetry_result.get('r_squared', 0.0)\n",
    "    results.structural_hints = symmetry_result.get('structural_hints', {})\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        print(f\"      Power-law detected: {results.is_power_law}\")\n",
    "        if results.is_power_law and results.power_law_r2:\n",
    "            print(f\"      R-squared: {results.power_law_r2:.4f}\")\n",
    "    \n",
    "    timing['symmetry'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1.4 iRF Interaction Discovery\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  1.4 iRF Interaction Discovery...\")\n",
    "    \n",
    "    interaction_discoverer = IRFInteractionDiscoverer(\n",
    "        stability_threshold=self.config['stability_threshold']\n",
    "    )\n",
    "    interaction_result = interaction_discoverer.discover(X, y, feature_names)\n",
    "    \n",
    "    results.stable_interactions = interaction_result.get('stable_interactions', [])\n",
    "    results.interaction_stability = interaction_result.get('interaction_stability', {})\n",
    "    results.soft_weights = interaction_result.get('soft_weights')\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        n_interactions = len(results.stable_interactions) if results.stable_interactions else 0\n",
    "        print(f\"      Found {n_interactions} stable interactions\")\n",
    "    \n",
    "    timing['interaction'] = time.time() - t0\n",
    "    \n",
    "    # Store timing\n",
    "    results.timing = timing\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Attach method to class\n",
    "PhysicsSRPipeline._run_stage1 = _run_stage1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE SELECTION HELPER\n",
    "# ==============================================================================\n",
    "\n",
    "def _select_working_features(\n",
    "    self,\n",
    "    X: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    stage1_results: Stage1Results\n",
    ") -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Select working features based on Stage 1 results.\n",
    "    \n",
    "    Selection Priority:\n",
    "    1. If power-law with R2 > 0.95: use active variables from symmetry\n",
    "    2. If screening selected variables: use those\n",
    "    3. Fallback to all features\n",
    "    \n",
    "    Additionally applies Buckingham Pi dimensional filter if available.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Original feature matrix\n",
    "    feature_names : List[str]\n",
    "        Original feature names\n",
    "    stage1_results : Stage1Results\n",
    "        Results from Stage 1\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, List[str]]\n",
    "        (X_work, feature_names_work) - working feature matrix and names\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    selection_source = 'fallback'\n",
    "    \n",
    "    # Build dimensional filter from Buckingham Pi\n",
    "    dimensional_filter = None\n",
    "    if stage1_results.pi_exponents is not None:\n",
    "        try:\n",
    "            pi_exp = np.array(stage1_results.pi_exponents)\n",
    "            if pi_exp.size > 0:\n",
    "                relevance = np.sum(np.abs(pi_exp), axis=0)\n",
    "                dimensional_filter = set(\n",
    "                    feature_names[i] for i in range(len(feature_names))\n",
    "                    if i < len(relevance) and relevance[i] > 0\n",
    "                )\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Priority 1: Power-law symmetry with high R2\n",
    "    if stage1_results.is_power_law:\n",
    "        r2 = stage1_results.power_law_r2 or 0.0\n",
    "        if r2 > 0.95:\n",
    "            hints = stage1_results.structural_hints or {}\n",
    "            active_vars = hints.get('active_variables', [])\n",
    "            if len(active_vars) > 0:\n",
    "                selected = [str(v) for v in active_vars]\n",
    "                selection_source = 'symmetry'\n",
    "    \n",
    "    # Priority 2: Screening results\n",
    "    if len(selected) == 0 and stage1_results.selected_names:\n",
    "        selected = [str(f) for f in stage1_results.selected_names]\n",
    "        selection_source = 'screening'\n",
    "    \n",
    "    # Priority 3: Fallback to all features\n",
    "    if len(selected) == 0:\n",
    "        selected = [str(f) for f in feature_names]\n",
    "        selection_source = 'fallback'\n",
    "        if self.config['verbose']:\n",
    "            print(\"      [Note] No features selected by screening or symmetry, using all features\")\n",
    "    \n",
    "    # Apply dimensional filter if available\n",
    "    if dimensional_filter is not None and len(dimensional_filter) > 0:\n",
    "        original_count = len(selected)\n",
    "        selected = [f for f in selected if f in dimensional_filter]\n",
    "        \n",
    "        # Ensure we have at least some features\n",
    "        if len(selected) == 0:\n",
    "            selected = list(dimensional_filter)\n",
    "        \n",
    "        if self.config['verbose'] and len(selected) < original_count:\n",
    "            print(f\"      [Buckingham Pi] Filtered {original_count} -> {len(selected)} variables\")\n",
    "    \n",
    "    # Get indices for selected features\n",
    "    feature_names_str = [str(f) for f in feature_names]\n",
    "    indices = [feature_names_str.index(f) for f in selected if f in feature_names_str]\n",
    "    \n",
    "    if len(indices) == 0:\n",
    "        # Safety fallback - use all features\n",
    "        if self.config['verbose']:\n",
    "            print(\"      [Warning] No valid indices, using all features\")\n",
    "        return X, feature_names_str\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        print(f\"      [Selection] Working features from {selection_source}: {selected}\")\n",
    "    \n",
    "    return X[:, indices], [feature_names_str[i] for i in indices]\n",
    "\n",
    "# Attach method to class\n",
    "PhysicsSRPipeline._select_working_features = _select_working_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STAGE 2 IMPLEMENTATION (v4.0/v4.1 REDESIGNED FLOW)\n",
    "# ==============================================================================\n",
    "\n",
    "def _run_stage2(\n",
    "    self,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    stage1_results: Stage1Results\n",
    ") -> Stage2Results:\n",
    "    \"\"\"\n",
    "    Execute Stage 2: Structure-Guided Discovery (v4.0/v4.1).\n",
    "    \n",
    "    v4.1 Flow:\n",
    "    ----------\n",
    "    2.1 PySR Discovery (adaptive timeout)\n",
    "        |-> Pareto front equations\n",
    "    2.2 Structure Parsing\n",
    "        |-> parsed_terms, detected_operators\n",
    "    2.3 Augmented Library Construction (4-layer)\n",
    "        |-> Layer 1: PySR exact terms\n",
    "        |-> Layer 2: Variant terms\n",
    "        |-> Layer 3: Polynomial baseline\n",
    "        |-> Layer 4: Operator-guided terms\n",
    "    2.4 E-WSINDy Sparse Selection\n",
    "        |-> support, coefficients, selection_analysis\n",
    "    2.5 Adaptive Lasso (conditional on time budget)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix\n",
    "    y : np.ndarray\n",
    "        Target vector\n",
    "    feature_names : List[str]\n",
    "        Feature names\n",
    "    stage1_results : Stage1Results\n",
    "        Results from Stage 1\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Stage2Results\n",
    "        Complete Stage 2 results with v4.1 enhancements\n",
    "    \"\"\"\n",
    "    timing = {}\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Initialize results\n",
    "    results = Stage2Results()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.1 PySR Structure Exploration (with adaptive timeout)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  2.1 PySR Structure Exploration...\")\n",
    "    \n",
    "    # Calculate adaptive timeout based on remaining budget\n",
    "    pysr_timeout = self.budget_manager.allocate_pysr_time()\n",
    "    if self.config['verbose']:\n",
    "        print(f\"      [TimeBudget] PySR timeout: {pysr_timeout}s\")\n",
    "    \n",
    "    # Initialize PySR discoverer\n",
    "    pysr_discoverer = PySRDiscoverer(\n",
    "        mode=self.config['pysr_mode'],\n",
    "        timeout_seconds=pysr_timeout,\n",
    "        precision=self.config['precision']\n",
    "    )\n",
    "    \n",
    "    pysr_result = pysr_discoverer.discover(X, y, feature_names)\n",
    "    \n",
    "    results.pysr_equations = pysr_result.get('all_equations', [])\n",
    "    results.pysr_pareto = pysr_result.get('pareto_front')\n",
    "    results.best_pysr_equation = pysr_result.get('best_equation', '')\n",
    "    results.best_pysr_sympy = pysr_result.get('best_equation_sympy')\n",
    "    results.best_pysr_r2 = pysr_result.get('best_r2', 0.0)\n",
    "    results.pysr_elapsed_time = pysr_result.get('elapsed_time', 0.0)\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        r2_str = f\"{results.best_pysr_r2:.4f}\" if results.best_pysr_r2 else \"N/A\"\n",
    "        eq_preview = results.best_pysr_equation[:50] if results.best_pysr_equation else \"N/A\"\n",
    "        print(f\"      Best equation: {eq_preview}... (R2={r2_str})\")\n",
    "        print(f\"      Elapsed: {results.pysr_elapsed_time:.1f}s\")\n",
    "    \n",
    "    timing['pysr'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.2 Structure Parsing (NEW v4.0)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  2.2 Structure Parsing...\")\n",
    "    \n",
    "    parser = StructureParser()\n",
    "    pareto_equations = pysr_discoverer.get_pareto_equations()\n",
    "    \n",
    "    parsed_terms, detected_operators, term_map = parser.parse_pareto_equations(\n",
    "        pareto_equations, feature_names, X\n",
    "    )\n",
    "    \n",
    "    results.parsed_terms = parsed_terms\n",
    "    results.detected_operators = detected_operators\n",
    "    results.term_to_equation_map = term_map\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        n_terms = len(parsed_terms)\n",
    "        ops_str = ', '.join(sorted(detected_operators)) if detected_operators else 'none'\n",
    "        print(f\"      Extracted {n_terms} unique terms\")\n",
    "        print(f\"      Detected operators: {ops_str}\")\n",
    "    \n",
    "    timing['parsing'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.3 Augmented Library Construction (4-Layer, NEW v4.0)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  2.3 Augmented Library Construction (4-Layer)...\")\n",
    "    \n",
    "    library_builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=self.config['max_poly_degree'],\n",
    "        generate_variants=self.config['generate_variants'],\n",
    "        include_operator_terms=self.config['include_operator_terms']\n",
    "    )\n",
    "    \n",
    "    augmented_library, library_names, library_info = library_builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=parsed_terms,\n",
    "        detected_operators=detected_operators,\n",
    "        pysr_r2=results.best_pysr_r2 or 0.0\n",
    "    )\n",
    "    \n",
    "    results.augmented_library = augmented_library\n",
    "    results.library_names = library_names\n",
    "    results.library_info = library_info\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        info = library_info or {}\n",
    "        print(f\"      Library: {info.get('total_terms', 0)} features\")\n",
    "        print(f\"        [PySR]: {info.get('n_pysr_terms', 0)}\")\n",
    "        print(f\"        [Var]:  {info.get('n_variant_terms', 0)}\")\n",
    "        print(f\"        [Poly]: {info.get('n_poly_terms', 0)}\")\n",
    "        print(f\"        [Op]:   {info.get('n_op_terms', 0)}\")\n",
    "    \n",
    "    timing['library'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.4 E-WSINDy Sparse Selection (with source attribution)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  2.4 E-WSINDy Sparse Selection...\")\n",
    "    \n",
    "    ewsindy = EWSINDySTLSQ(\n",
    "        threshold=self.config['stlsq_threshold']\n",
    "    )\n",
    "    \n",
    "    ewsindy_result = ewsindy.fit(\n",
    "        augmented_library, y, library_names=library_names\n",
    "    )\n",
    "    \n",
    "    results.ewsindy_coefficients = ewsindy_result.get('coefficients')\n",
    "    results.ewsindy_support = ewsindy_result.get('support')\n",
    "    results.ewsindy_equation = ewsindy_result.get('equation', '')\n",
    "    results.ewsindy_r2 = ewsindy_result.get('r_squared', 0.0)\n",
    "    results.selection_analysis = ewsindy_result.get('selection_analysis', {})\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        n_active = ewsindy_result.get('n_active_terms', 0)\n",
    "        analysis = results.selection_analysis or {}\n",
    "        r2_str = f\"{results.ewsindy_r2:.4f}\" if results.ewsindy_r2 else \"N/A\"\n",
    "        print(f\"      Selected {n_active} terms (R2={r2_str})\")\n",
    "        print(f\"        from [PySR]: {analysis.get('from_pysr', 0)}\")\n",
    "        print(f\"        from [Var]:  {analysis.get('from_variant', 0)}\")\n",
    "        print(f\"        from [Poly]: {analysis.get('from_poly', 0)}\")\n",
    "        print(f\"        from [Op]:   {analysis.get('from_op', 0)}\")\n",
    "    \n",
    "    timing['ewsindy'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2.5 Adaptive Lasso (conditional on time budget)\n",
    "    # -------------------------------------------------------------------------\n",
    "    skip_alasso = (\n",
    "        self.config['skip_alasso_if_tight'] and\n",
    "        self.budget_manager.should_skip_optional(min_required=20)\n",
    "    )\n",
    "    \n",
    "    if not skip_alasso:\n",
    "        if self.config['verbose']:\n",
    "            print(\"  2.5 Adaptive Lasso Verification...\")\n",
    "        \n",
    "        alasso = AdaptiveLassoSelector(\n",
    "            gamma=self.config['alasso_gamma']\n",
    "        )\n",
    "        \n",
    "        alasso_result = alasso.fit(augmented_library, y, library_names)\n",
    "        \n",
    "        results.alasso_coefficients = alasso_result.get('coefficients')\n",
    "        results.alasso_support = alasso_result.get('support')\n",
    "        results.alasso_r2 = alasso_result.get('r_squared', 0.0)\n",
    "        \n",
    "        if self.config['verbose']:\n",
    "            n_alasso = alasso_result.get('n_active_terms', 0)\n",
    "            r2_str = f\"{results.alasso_r2:.4f}\" if results.alasso_r2 else \"N/A\"\n",
    "            print(f\"      Selected {n_alasso} terms (R2={r2_str})\")\n",
    "    else:\n",
    "        if self.config['verbose']:\n",
    "            print(\"  2.5 Adaptive Lasso: Skipped (time budget constraint)\")\n",
    "        results.alasso_coefficients = None\n",
    "        results.alasso_support = None\n",
    "        results.alasso_r2 = None\n",
    "    \n",
    "    timing['alasso'] = time.time() - t0\n",
    "    \n",
    "    # Store timing\n",
    "    results.timing = timing\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Attach method to class\n",
    "PhysicsSRPipeline._run_stage2 = _run_stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# STAGE 3 IMPLEMENTATION\n",
    "# ==============================================================================\n",
    "\n",
    "def _run_stage3(\n",
    "    self,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    stage2_results: Stage2Results,\n",
    "    user_inputs: UserInputs\n",
    ") -> Stage3Results:\n",
    "    \"\"\"\n",
    "    Execute Stage 3: Validation & Uncertainty Quantification.\n",
    "    \n",
    "    Sub-stages:\n",
    "    - 3.1 Model Selection (CV + EBIC)\n",
    "    - 3.2 Physics Verification (dimensional + bounds)\n",
    "    - 3.3 Bootstrap UQ (three-layer, adaptive count)\n",
    "    - 3.4 Statistical Inference\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix\n",
    "    y : np.ndarray\n",
    "        Target vector\n",
    "    feature_names : List[str]\n",
    "        Feature names\n",
    "    stage2_results : Stage2Results\n",
    "        Results from Stage 2\n",
    "    user_inputs : UserInputs\n",
    "        User-provided physics information\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Stage3Results\n",
    "        Complete Stage 3 results\n",
    "    \"\"\"\n",
    "    timing = {}\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Initialize results\n",
    "    results = Stage3Results()\n",
    "    \n",
    "    # Get library from Stage 2\n",
    "    Phi = stage2_results.augmented_library\n",
    "    library_names = stage2_results.library_names\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.1 Model Selection (CV + EBIC)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  3.1 Model Selection (CV + EBIC)...\")\n",
    "    \n",
    "    # Prepare candidate models\n",
    "    candidates = {\n",
    "        'ewsindy': (Phi, stage2_results.ewsindy_support)\n",
    "    }\n",
    "    \n",
    "    if stage2_results.alasso_support is not None:\n",
    "        candidates['alasso'] = (Phi, stage2_results.alasso_support)\n",
    "    \n",
    "    model_selector = ModelSelector(\n",
    "        n_folds=self.config['cv_folds'],\n",
    "        ebic_gamma=self.config['ebic_gamma']\n",
    "    )\n",
    "    \n",
    "    selection_result = model_selector.compare_models(\n",
    "        candidates, y, p_total=Phi.shape[1]\n",
    "    )\n",
    "    \n",
    "    results.cv_scores = selection_result.get('cv_results', {})\n",
    "    results.ebic_scores = selection_result.get('ebic_results', {})\n",
    "    results.best_model = selection_result.get('best_model_cv', 'ewsindy')\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        print(f\"      Best by CV: {selection_result.get('best_model_cv', 'N/A')}\")\n",
    "        print(f\"      Best by EBIC: {selection_result.get('best_model_ebic', 'N/A')}\")\n",
    "    \n",
    "    timing['selection'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.2 Physics Verification (dimensional + bounds)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  3.2 Physics Verification...\")\n",
    "    \n",
    "    # Get best model support and predictions\n",
    "    best_model = results.best_model\n",
    "    if best_model == 'ewsindy':\n",
    "        best_support = stage2_results.ewsindy_support\n",
    "        best_coefs = stage2_results.ewsindy_coefficients\n",
    "    else:\n",
    "        best_support = stage2_results.alasso_support\n",
    "        best_coefs = stage2_results.alasso_coefficients\n",
    "    \n",
    "    y_pred = Phi @ best_coefs if best_coefs is not None else None\n",
    "    \n",
    "    # Build equation terms for dimensional analysis\n",
    "    equation_terms = []\n",
    "    if best_support is not None and library_names is not None:\n",
    "        for idx in np.where(best_support)[0]:\n",
    "            if idx < len(library_names):\n",
    "                term_name = library_names[idx]\n",
    "                # Parse the term to extract variable exponents\n",
    "                equation_terms.append({\n",
    "                    'name': term_name,\n",
    "                    'variables': {}  # Would need parsing for full dimensional analysis\n",
    "                })\n",
    "    \n",
    "    # Get variable dimensions and target dimensions\n",
    "    variable_dims = {}\n",
    "    target_dims = [0, 0, 0, 0]\n",
    "    physical_bounds = None\n",
    "    \n",
    "    if user_inputs:\n",
    "        variable_dims = user_inputs.variable_dimensions or {}\n",
    "        target_dims = user_inputs.target_dimensions or [0, 0, 0, 0]\n",
    "        physical_bounds = user_inputs.physical_bounds\n",
    "    \n",
    "    physics_verifier = PhysicsVerifier(\n",
    "        dim_tolerance=self.config['dim_tolerance']\n",
    "    )\n",
    "    \n",
    "    physics_result = physics_verifier.verify(\n",
    "        equation_terms, variable_dims, target_dims,\n",
    "        y_pred=y_pred, physical_bounds=physical_bounds\n",
    "    )\n",
    "    \n",
    "    results.dim_consistent = physics_result.get('dim_consistent', True)\n",
    "    results.dim_details = physics_result.get('dim_details')\n",
    "    results.bounds_violations = physics_result.get('bounds_violations')\n",
    "    results.physics_score = physics_result.get('physics_score', 1.0)\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        status = 'PASS' if physics_result.get('overall_valid', True) else 'FAIL'\n",
    "        score = physics_result.get('physics_score', 1.0)\n",
    "        print(f\"      Physics: {status} (score: {score:.2f})\")\n",
    "    \n",
    "    timing['physics'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.3 Bootstrap UQ (three-layer, adaptive count)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  3.3 Bootstrap Uncertainty Quantification...\")\n",
    "    \n",
    "    # Calculate adaptive bootstrap count\n",
    "    n_bootstrap = self.budget_manager.allocate_bootstrap_count()\n",
    "    if self.config['verbose']:\n",
    "        print(f\"      [TimeBudget] Bootstrap count: {n_bootstrap}\")\n",
    "    \n",
    "    bootstrap_uq = BootstrapUQ(\n",
    "        n_bootstrap=n_bootstrap,\n",
    "        confidence_level=self.config['confidence_level'],\n",
    "        n_jobs=self.config['n_jobs']\n",
    "    )\n",
    "    \n",
    "    uq_result = bootstrap_uq.run(Phi, y, library_names)\n",
    "    \n",
    "    results.inclusion_probabilities = uq_result.get('inclusion_probabilities')\n",
    "    results.structural_confidence = uq_result.get('structural_confidence')\n",
    "    results.bootstrap_supports = uq_result.get('bootstrap_supports')\n",
    "    results.coefficient_estimates = uq_result.get('coefficient_estimates')\n",
    "    results.coefficient_CI = uq_result.get('coefficient_CI')\n",
    "    results.coefficient_SE = uq_result.get('coefficient_SE')\n",
    "    results.bootstrap_coefficients = uq_result.get('bootstrap_coefficients')\n",
    "    results.residual_variance = uq_result.get('residual_variance')\n",
    "    \n",
    "    if self.config['verbose']:\n",
    "        inc_probs = uq_result.get('inclusion_probabilities', [])\n",
    "        n_high = sum(1 for p in inc_probs if p is not None and p > 0.9) if inc_probs is not None else 0\n",
    "        print(f\"      High-confidence terms (P>0.9): {n_high}\")\n",
    "    \n",
    "    timing['bootstrap'] = time.time() - t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3.4 Statistical Inference\n",
    "    # -------------------------------------------------------------------------\n",
    "    if self.config['verbose']:\n",
    "        print(\"  3.4 Statistical Inference...\")\n",
    "    \n",
    "    inference = StatisticalInference(\n",
    "        alpha=1.0 - self.config['confidence_level']\n",
    "    )\n",
    "    \n",
    "    coef_samples = uq_result.get('coef_samples')\n",
    "    support_samples = uq_result.get('support_samples')\n",
    "    \n",
    "    if coef_samples is not None and support_samples is not None:\n",
    "        inference_result = inference.test_coefficients(\n",
    "            coef_samples, support_samples, library_names\n",
    "        )\n",
    "        \n",
    "        results.p_values = inference_result.get('p_values', {})\n",
    "        results.significant_terms = inference_result.get('significant_terms', [])\n",
    "        results.test_statistics = inference_result.get('test_statistics', {})\n",
    "        \n",
    "        if self.config['verbose']:\n",
    "            n_sig = len(results.significant_terms) if results.significant_terms else 0\n",
    "            print(f\"      Significant terms (alpha=0.05): {n_sig}\")\n",
    "    else:\n",
    "        if self.config['verbose']:\n",
    "            print(\"      Skipped (insufficient data)\")\n",
    "    \n",
    "    timing['inference'] = time.time() - t0\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # Build Final Equation\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Use best model equation\n",
    "    if best_model == 'ewsindy' and stage2_results.ewsindy_equation:\n",
    "        results.final_equation = stage2_results.ewsindy_equation\n",
    "    elif best_model == 'alasso':\n",
    "        # Build equation from alasso coefficients\n",
    "        results.final_equation = self._build_equation_string(\n",
    "            stage2_results.alasso_coefficients,\n",
    "            stage2_results.alasso_support,\n",
    "            library_names\n",
    "        )\n",
    "    else:\n",
    "        results.final_equation = stage2_results.ewsindy_equation or \"N/A\"\n",
    "    \n",
    "    # Build coefficient dictionary\n",
    "    if best_coefs is not None and best_support is not None:\n",
    "        final_coefs = {}\n",
    "        for idx in np.where(best_support)[0]:\n",
    "            if idx < len(library_names):\n",
    "                final_coefs[library_names[idx]] = float(best_coefs[idx])\n",
    "        results.final_coefficients = final_coefs\n",
    "    \n",
    "    # Store timing\n",
    "    results.timing = timing\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Attach method to class\n",
    "PhysicsSRPipeline._run_stage3 = _run_stage3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# HELPER METHODS\n",
    "# ==============================================================================\n",
    "\n",
    "def _build_equation_string(\n",
    "    self,\n",
    "    coefficients: np.ndarray,\n",
    "    support: np.ndarray,\n",
    "    library_names: List[str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build equation string from coefficients and support.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coefficients : np.ndarray\n",
    "        Coefficient vector\n",
    "    support : np.ndarray\n",
    "        Boolean support mask\n",
    "    library_names : List[str]\n",
    "        Feature names\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Equation string\n",
    "    \"\"\"\n",
    "    if coefficients is None or support is None:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    terms = []\n",
    "    for idx in np.where(support)[0]:\n",
    "        if idx < len(library_names) and idx < len(coefficients):\n",
    "            coef = coefficients[idx]\n",
    "            name = library_names[idx]\n",
    "            # Remove source tag for cleaner equation\n",
    "            clean_name = name\n",
    "            for tag in ['[PySR] ', '[Var] ', '[Poly] ', '[Op] ']:\n",
    "                clean_name = clean_name.replace(tag, '')\n",
    "            \n",
    "            if abs(coef) > 1e-10:\n",
    "                terms.append(f\"{coef:.4f} * {clean_name}\")\n",
    "    \n",
    "    if len(terms) == 0:\n",
    "        return \"0\"\n",
    "    \n",
    "    return \" + \".join(terms)\n",
    "\n",
    "def _extract_final_equation(self) -> str:\n",
    "    \"\"\"\n",
    "    Extract final equation from results.\n",
    "    \n",
    "    Priority:\n",
    "    1. If symmetry detected power-law with R2 > 0.99, use symmetry equation\n",
    "    2. Otherwise use Stage 3 final equation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Final equation string\n",
    "    \"\"\"\n",
    "    # Check if symmetry provides a high-quality power-law equation\n",
    "    if self.stage1_results and self.stage1_results.is_power_law:\n",
    "        r2 = self.stage1_results.power_law_r2 or 0.0\n",
    "        if r2 > 0.99:\n",
    "            hints = self.stage1_results.structural_hints or {}\n",
    "            suggested_form = hints.get('suggested_form', '')\n",
    "            if suggested_form:\n",
    "                return f\"[Symmetry R2={r2:.4f}] {suggested_form}\"\n",
    "    \n",
    "    # Fallback to Stage 3 final equation\n",
    "    if self.stage3_results and self.stage3_results.final_equation:\n",
    "        return self.stage3_results.final_equation\n",
    "    \n",
    "    return \"N/A\"\n",
    "\n",
    "def get_final_equation(self) -> str:\n",
    "    \"\"\"\n",
    "    Get the final discovered equation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Final equation string\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If pipeline has not been run\n",
    "    \"\"\"\n",
    "    if not self._run_complete:\n",
    "        raise ValueError(\"Must run pipeline first\")\n",
    "    return self._final_equation\n",
    "\n",
    "def get_timing_report(self) -> str:\n",
    "    \"\"\"\n",
    "    Get detailed timing report.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Timing report string\n",
    "    \"\"\"\n",
    "    return self.budget_manager.report()\n",
    "\n",
    "# Attach methods to class\n",
    "PhysicsSRPipeline._build_equation_string = _build_equation_string\n",
    "PhysicsSRPipeline._extract_final_equation = _extract_final_equation\n",
    "PhysicsSRPipeline.get_final_equation = get_final_equation\n",
    "PhysicsSRPipeline.get_timing_report = get_timing_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PRINT SUMMARY METHOD\n",
    "# ==============================================================================\n",
    "\n",
    "def print_summary(self) -> None:\n",
    "    \"\"\"\n",
    "    Print comprehensive pipeline summary.\n",
    "    \n",
    "    Displays results from all three stages with v4.1 enhancements.\n",
    "    \"\"\"\n",
    "    if not self._run_complete:\n",
    "        print(\"Pipeline not yet executed. Call run() first.\")\n",
    "        return\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\" PHYSICS-SR PIPELINE v4.1 SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Stage 1 Summary\n",
    "    print(\"STAGE 1: Variable Selection\")\n",
    "    print(\"-\" * 40)\n",
    "    s1 = self.stage1_results\n",
    "    if s1:\n",
    "        selected = s1.selected_names or []\n",
    "        print(f\"  Selected variables: {selected}\")\n",
    "        print(f\"  Power-law detected: {s1.is_power_law}\")\n",
    "        if s1.is_power_law:\n",
    "            print(f\"  Power-law R2: {s1.power_law_r2:.4f}\" if s1.power_law_r2 else \"\")\n",
    "        interactions = s1.stable_interactions or []\n",
    "        print(f\"  Stable interactions: {len(interactions)}\")\n",
    "    print()\n",
    "    \n",
    "    # Stage 2 Summary (v4.1 enhanced)\n",
    "    print(\"STAGE 2: Structure-Guided Discovery (v4.1)\")\n",
    "    print(\"-\" * 40)\n",
    "    s2 = self.stage2_results\n",
    "    if s2:\n",
    "        lib_info = s2.library_info or {}\n",
    "        print(f\"  PySR best equation: {(s2.best_pysr_equation or 'N/A')[:50]}...\")\n",
    "        print(f\"  PySR R2: {s2.best_pysr_r2:.4f}\" if s2.best_pysr_r2 else \"  PySR R2: N/A\")\n",
    "        print(f\"  Library size: {lib_info.get('total_terms', 0)} features\")\n",
    "        print(f\"    [PySR]: {lib_info.get('n_pysr_terms', 0)}\")\n",
    "        print(f\"    [Var]:  {lib_info.get('n_variant_terms', 0)}\")\n",
    "        print(f\"    [Poly]: {lib_info.get('n_poly_terms', 0)}\")\n",
    "        print(f\"    [Op]:   {lib_info.get('n_op_terms', 0)}\")\n",
    "        \n",
    "        # Selection analysis\n",
    "        analysis = s2.selection_analysis or {}\n",
    "        n_ewsindy = analysis.get('total_selected', 0)\n",
    "        print(f\"  E-WSINDy selected: {n_ewsindy} terms\")\n",
    "        if n_ewsindy > 0:\n",
    "            print(f\"    from [PySR]: {analysis.get('from_pysr', 0)}\")\n",
    "            print(f\"    from [Var]:  {analysis.get('from_variant', 0)}\")\n",
    "            print(f\"    from [Poly]: {analysis.get('from_poly', 0)}\")\n",
    "            print(f\"    from [Op]:   {analysis.get('from_op', 0)}\")\n",
    "        print(f\"  E-WSINDy R2: {s2.ewsindy_r2:.4f}\" if s2.ewsindy_r2 else \"\")\n",
    "    print()\n",
    "    \n",
    "    # Stage 3 Summary\n",
    "    print(\"STAGE 3: Validation & UQ\")\n",
    "    print(\"-\" * 40)\n",
    "    s3 = self.stage3_results\n",
    "    if s3:\n",
    "        print(f\"  Best model: {s3.best_model or 'N/A'}\")\n",
    "        print(f\"  Physics score: {s3.physics_score:.2f}\" if s3.physics_score else \"  Physics score: N/A\")\n",
    "        \n",
    "        # UQ summary\n",
    "        inc_probs = s3.inclusion_probabilities\n",
    "        if inc_probs is not None:\n",
    "            n_high = sum(1 for p in inc_probs if p > 0.9)\n",
    "            n_med = sum(1 for p in inc_probs if 0.5 < p <= 0.9)\n",
    "            print(f\"  High-confidence terms (P>0.9): {n_high}\")\n",
    "            print(f\"  Medium-confidence terms (0.5<P<=0.9): {n_med}\")\n",
    "        \n",
    "        sig_terms = s3.significant_terms or []\n",
    "        print(f\"  Significant terms: {len(sig_terms)}\")\n",
    "    print()\n",
    "    \n",
    "    # Final Equation\n",
    "    print(\"FINAL EQUATION\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  {self._final_equation}\")\n",
    "    print()\n",
    "    \n",
    "    # Timing Profile\n",
    "    print(\"TIMING PROFILE (v4.1)\")\n",
    "    print(\"-\" * 40)\n",
    "    timing = self.budget_manager.to_dict()\n",
    "    for stage in ['Stage1', 'Stage2', 'Stage3']:\n",
    "        if stage in timing:\n",
    "            print(f\"  {stage}: {timing[stage]:.1f}s\")\n",
    "    print(f\"  ---\")\n",
    "    print(f\"  Total: {timing.get('total', 0):.1f}s / {self.budget_manager.total_budget}s\")\n",
    "    print(f\"  Remaining: {timing.get('remaining', 0):.1f}s\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Attach method to class\n",
    "PhysicsSRPipeline.print_summary = print_summary\n",
    "\n",
    "print(\"PhysicsSRPipeline class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Quick Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# QUICK PIPELINE FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def run_physics_sr(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names: List[str],\n",
    "    variable_dimensions: Dict[str, List[float]] = None,\n",
    "    target_dimensions: List[float] = None,\n",
    "    target_name: str = 'y',\n",
    "    max_time_seconds: float = 180,\n",
    "    config: Dict = None,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run complete Physics-SR pipeline with minimal setup.\n",
    "    \n",
    "    This is a convenience wrapper around PhysicsSRPipeline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix (n_samples, n_features)\n",
    "    y : np.ndarray\n",
    "        Target vector (n_samples,)\n",
    "    feature_names : List[str]\n",
    "        Feature names\n",
    "    variable_dimensions : Dict[str, List[float]], optional\n",
    "        Variable dimensions {var_name: [M, L, T, Theta]}\n",
    "    target_dimensions : List[float], optional\n",
    "        Target dimensions [M, L, T, Theta]\n",
    "    target_name : str\n",
    "        Name of target variable\n",
    "    max_time_seconds : float\n",
    "        Total runtime budget (default: 180s)\n",
    "    config : Dict, optional\n",
    "        Pipeline configuration overrides\n",
    "    verbose : bool\n",
    "        Whether to print progress (default: True)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Complete pipeline results\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> results = run_physics_sr(\n",
    "    ...     X, y, ['q_c', 'N_d'],\n",
    "    ...     variable_dimensions={'q_c': [0,0,0,0], 'N_d': [0,-3,0,0]},\n",
    "    ...     target_dimensions=[0,0,-1,0],\n",
    "    ...     target_name='dq_r/dt'\n",
    "    ... )\n",
    "    >>> print(results['final_equation'])\n",
    "    \"\"\"\n",
    "    # Create UserInputs\n",
    "    user_inputs = UserInputs(\n",
    "        variable_dimensions=variable_dimensions,\n",
    "        target_dimensions=target_dimensions,\n",
    "        target_name=target_name\n",
    "    )\n",
    "    \n",
    "    # Merge config\n",
    "    full_config = config or {}\n",
    "    full_config['verbose'] = verbose\n",
    "    \n",
    "    # Create and run pipeline\n",
    "    pipeline = PhysicsSRPipeline(\n",
    "        config=full_config,\n",
    "        max_time_seconds=max_time_seconds\n",
    "    )\n",
    "    \n",
    "    results = pipeline.run(X, y, feature_names, user_inputs)\n",
    "    \n",
    "    # Add pipeline reference for further inspection\n",
    "    results['pipeline'] = pipeline\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"run_physics_sr convenience function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMO CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_DEMO = False  # Set to True to run demonstration\n",
    "\n",
    "if _RUN_DEMO:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING END-TO-END DEMONSTRATION (v4.1)\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMO: Generate Warm Rain Test Data\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_DEMO:\n",
    "    print()\n",
    "    print_section_header(\"Demo: Generate Test Data\")\n",
    "    \n",
    "    # Generate warm rain data\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    warm_rain = generate_warm_rain_data(n_samples=500, noise_level=0.01)\n",
    "    \n",
    "    X = warm_rain['X']\n",
    "    y = warm_rain['y']\n",
    "    feature_names = warm_rain['feature_names']\n",
    "    \n",
    "    print(f\"Generated {len(y)} samples\")\n",
    "    print(f\"Features: {feature_names}\")\n",
    "    print(f\"True equation: {warm_rain['true_equation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMO: Create User Inputs\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_DEMO:\n",
    "    print()\n",
    "    print_section_header(\"Demo: Create User Inputs\")\n",
    "    \n",
    "    user_inputs = UserInputs(\n",
    "        variable_dimensions={\n",
    "            'q_c': [0, 0, 0, 0],    # dimensionless (mixing ratio)\n",
    "            'N_d': [0, -3, 0, 0],   # m^-3 (number concentration)\n",
    "            'r_eff': [0, 1, 0, 0],  # m (effective radius)\n",
    "            'LWC': [1, -3, 0, 0]    # kg/m^3 (liquid water content)\n",
    "        },\n",
    "        target_dimensions=[0, 0, -1, 0],  # s^-1 (rate)\n",
    "        target_name='dq_r/dt',\n",
    "        expected_form='power_law',\n",
    "        physical_bounds={'min': 0.0}  # Non-negative rate\n",
    "    )\n",
    "    \n",
    "    print(\"User inputs configured:\")\n",
    "    print(f\"  Target: {user_inputs.target_name}\")\n",
    "    print(f\"  Expected form: {user_inputs.expected_form}\")\n",
    "    print(f\"  Target dimensions: {user_inputs.target_dimensions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMO: Run Complete Pipeline\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_DEMO:\n",
    "    print()\n",
    "    print_section_header(\"Demo: Run Complete Pipeline\")\n",
    "    \n",
    "    # Initialize pipeline with faster settings for demo\n",
    "    pipeline = PhysicsSRPipeline(\n",
    "        config={\n",
    "            'importance_threshold': 0.01,\n",
    "            'powerlaw_r2_threshold': 0.9,\n",
    "            'stability_threshold': 0.5,\n",
    "            'pysr_mode': 'fast',\n",
    "            'max_poly_degree': 3,\n",
    "            'stlsq_threshold': 0.1,\n",
    "            'cv_folds': 5,\n",
    "            'ebic_gamma': 0.5,\n",
    "            'n_bootstrap': 100,\n",
    "            'confidence_level': 0.95,\n",
    "            'n_jobs': 2,\n",
    "            'verbose': True\n",
    "        },\n",
    "        max_time_seconds=180\n",
    "    )\n",
    "    \n",
    "    # Run pipeline\n",
    "    results = pipeline.run(X, y, feature_names, user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMO: Display Results\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_DEMO:\n",
    "    print()\n",
    "    print_section_header(\"Demo: Results Summary\")\n",
    "    \n",
    "    pipeline.print_summary()\n",
    "    \n",
    "    print()\n",
    "    print(\"Comparison with true equation:\")\n",
    "    print(f\"  True:       {warm_rain['true_equation']}\")\n",
    "    print(f\"  Discovered: {pipeline.get_final_equation()[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEMO: Quick Pipeline Alternative\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_DEMO:\n",
    "    print()\n",
    "    print_section_header(\"Demo: Quick Pipeline (Alternative)\")\n",
    "    \n",
    "    # Using the convenience function\n",
    "    quick_results = run_physics_sr(\n",
    "        X, y, feature_names,\n",
    "        variable_dimensions={\n",
    "            'q_c': [0, 0, 0, 0],\n",
    "            'N_d': [0, -3, 0, 0]\n",
    "        },\n",
    "        target_dimensions=[0, 0, -1, 0],\n",
    "        target_name='dq_r/dt',\n",
    "        max_time_seconds=120,\n",
    "        config={'pysr_mode': 'fast'},\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Quick pipeline result: {quick_results['final_equation'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 12_Full_Pipeline.ipynb - Module Summary (v4.1)\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: PhysicsSRPipeline\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Complete end-to-end physics-informed symbolic regression pipeline.\")\n",
    "print(\"  Integrates all three stages with v4.1 enhancements:\")\n",
    "print(\"  - TimeBudgetManager for adaptive time allocation\")\n",
    "print(\"  - Structure-guided feature library (PySR -> E-WSINDy)\")\n",
    "print(\"  - Source attribution for selected terms\")\n",
    "print(\"  - Comprehensive timing profile\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  __init__(config, max_time_seconds)\")\n",
    "print(\"      Initialize pipeline with configuration\")\n",
    "print()\n",
    "print(\"  run(X, y, feature_names, user_inputs) -> Dict\")\n",
    "print(\"      Execute complete pipeline\")\n",
    "print(\"      Returns: {stage1, stage2, stage3, final_equation, timing}\")\n",
    "print()\n",
    "print(\"  get_final_equation() -> str\")\n",
    "print(\"      Get the discovered equation\")\n",
    "print()\n",
    "print(\"  get_timing_report() -> str\")\n",
    "print(\"      Get detailed timing profile (v4.1)\")\n",
    "print()\n",
    "print(\"  print_summary() -> None\")\n",
    "print(\"      Print comprehensive results summary\")\n",
    "print()\n",
    "print(\"Pipeline Stages (v4.1):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  Stage 1: Variable Selection\")\n",
    "print(\"    - 1.1 Buckingham Pi dimensional analysis\")\n",
    "print(\"    - 1.2 PAN+SR variable screening\")\n",
    "print(\"    - 1.3 Power-law symmetry detection\")\n",
    "print(\"    - 1.4 iRF interaction discovery\")\n",
    "print()\n",
    "print(\"  Stage 2: Structure-Guided Discovery (v4.0/v4.1)\")\n",
    "print(\"    - 2.1 PySR structure exploration (adaptive timeout)\")\n",
    "print(\"    - 2.2 Structure parsing (NEW v4.0)\")\n",
    "print(\"    - 2.3 4-layer augmented library (NEW v4.0)\")\n",
    "print(\"    - 2.4 E-WSINDy sparse selection (source attribution)\")\n",
    "print(\"    - 2.5 Adaptive Lasso (conditional on budget)\")\n",
    "print()\n",
    "print(\"  Stage 3: Validation & UQ\")\n",
    "print(\"    - 3.1 Model selection (CV + EBIC)\")\n",
    "print(\"    - 3.2 Physics verification (dimensional + bounds)\")\n",
    "print(\"    - 3.3 Bootstrap UQ (three-layer, adaptive count)\")\n",
    "print(\"    - 3.4 Statistical inference\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Create user inputs with physics information\n",
    "user_inputs = UserInputs(\n",
    "    variable_dimensions={'x': [0, 1, 0, 0], 'v': [0, 1, -1, 0]},\n",
    "    target_dimensions=[0, 2, -2, 0],\n",
    "    target_name='energy'\n",
    ")\n",
    "\n",
    "# Run complete pipeline with time budget\n",
    "pipeline = PhysicsSRPipeline(max_time_seconds=180)\n",
    "results = pipeline.run(X, y, feature_names, user_inputs)\n",
    "\n",
    "# Get results\n",
    "print(f\"Equation: {pipeline.get_final_equation()}\")\n",
    "print(pipeline.get_timing_report())\n",
    "pipeline.print_summary()\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"Quick Pipeline Function:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# One-liner for simple usage\n",
    "results = run_physics_sr(\n",
    "    X, y, ['q_c', 'N_d'],\n",
    "    variable_dimensions={'q_c': [0,0,0,0], 'N_d': [0,-3,0,0]},\n",
    "    target_dimensions=[0,0,-1,0],\n",
    "    target_name='dq_r/dt',\n",
    "    max_time_seconds=180\n",
    ")\n",
    "print(results['final_equation'])\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\" PHYSICS-SR FRAMEWORK v4.1 - COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"All 12 notebooks loaded successfully.\")\n",
    "print(\"Ready for physics-informed symbolic regression!\")\n",
    "print()\n",
    "print(\"v4.1 Key Features:\")\n",
    "print(\"  - TimeBudgetManager for adaptive time allocation\")\n",
    "print(\"  - Structure-guided library (PySR terms feed E-WSINDy)\")\n",
    "print(\"  - Source attribution ([PySR], [Var], [Poly], [Op])\")\n",
    "print(\"  - Float32 precision for memory efficiency\")\n",
    "print(\"  - Adaptive bootstrap count based on remaining budget\")\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

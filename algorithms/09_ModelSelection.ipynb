{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09_ModelSelection - Physics-SR Framework v3.0\n",
    "\n",
    "## Stage 3.1: Model Selection via K-Fold CV and EBIC\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Compare and select the best model from Stage 2 candidates (PySR, E-WSINDy, Adaptive Lasso) using:\n",
    "1. **K-Fold Cross-Validation** for generalization assessment\n",
    "2. **Extended BIC (EBIC)** for high-dimensional model selection\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "\n",
    "Robust model comparison that estimates out-of-sample performance:\n",
    "- Split data into K folds\n",
    "- Train on K-1 folds, test on held-out fold\n",
    "- Repeat K times, average results\n",
    "\n",
    "### Extended BIC (EBIC)\n",
    "\n",
    "High-dimensional model selection with proper penalty for large search spaces:\n",
    "$$EBIC_\\gamma = n \\cdot \\log(RSS/n) + k \\cdot \\log(n) + 2\\gamma \\cdot \\log\\binom{p}{k}$$\n",
    "\n",
    "where:\n",
    "- $n$ = sample size\n",
    "- $k$ = number of selected terms\n",
    "- $p$ = total features in library\n",
    "- $\\gamma \\in [0, 1]$ = tuning parameter\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Chen, J., & Chen, Z. (2008). Extended Bayesian information criteria for model selection with large model spaces. *Biometrika*, 95(3), 759-771."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "09_ModelSelection.ipynb - Model Selection via CV and EBIC\n",
    "==========================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v3.0\n",
    "\n",
    "This module provides:\n",
    "- ModelSelector: Compare models via K-fold CV and EBIC\n",
    "- K-fold cross-validation for generalization assessment\n",
    "- Extended BIC for high-dimensional model selection\n",
    "- One-SE rule for parsimony preference\n",
    "\n",
    "Algorithm:\n",
    "    1. Collect candidate models from Stage 2\n",
    "    2. Evaluate each via K-fold CV (MSE, R2)\n",
    "    3. Compute EBIC scores for model ranking\n",
    "    4. Select best model (optionally with one-SE rule)\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for Model Selection\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.special import comb\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "print(\"09_ModelSelection: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODEL SELECTOR CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class ModelSelector:\n",
    "    \"\"\"\n",
    "    Model Selection via K-Fold Cross-Validation and EBIC.\n",
    "    \n",
    "    Compares candidate models from Stage 2 (PySR, E-WSINDy, Adaptive Lasso)\n",
    "    using multiple selection criteria:\n",
    "    - K-fold CV for generalization assessment\n",
    "    - EBIC for high-dimensional model selection\n",
    "    - One-SE rule for parsimony preference\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    n_folds : int\n",
    "        Number of cross-validation folds (default: 5)\n",
    "    ebic_gamma : float\n",
    "        EBIC parameter in [0, 1] (default: 0.5)\n",
    "        Higher gamma = more penalty for complex models\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> selector = ModelSelector(n_folds=5, ebic_gamma=0.5)\n",
    "    >>> result = selector.compare_models(candidates, y)\n",
    "    >>> print(f\"Best model: {result['best_model_cv']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_folds: int = DEFAULT_CV_FOLDS,\n",
    "        ebic_gamma: float = DEFAULT_EBIC_GAMMA,\n",
    "        random_state: int = RANDOM_SEED\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize ModelSelector.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_folds : int\n",
    "            Number of CV folds. Default: 5\n",
    "        ebic_gamma : float\n",
    "            EBIC parameter. 0.0 = BIC, 0.5 = balanced, 1.0 = max penalty.\n",
    "            Default: 0.5\n",
    "        random_state : int\n",
    "            Random seed for CV splits. Default: 42\n",
    "        \"\"\"\n",
    "        self.n_folds = n_folds\n",
    "        self.ebic_gamma = ebic_gamma\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Internal state\n",
    "        self._cv_results = None\n",
    "        self._ebic_results = None\n",
    "        self._best_model_cv = None\n",
    "        self._best_model_ebic = None\n",
    "        self._best_model_onese = None\n",
    "        self._comparison_complete = False\n",
    "    \n",
    "    def compare_models(\n",
    "        self,\n",
    "        candidates: Dict[str, Tuple[np.ndarray, np.ndarray]],\n",
    "        y: np.ndarray,\n",
    "        p_total: int = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Compare candidate models using CV and EBIC.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        candidates : Dict[str, Tuple[np.ndarray, np.ndarray]]\n",
    "            Dictionary mapping model name to (Phi, support) tuple:\n",
    "            - Phi: Feature matrix used by the model\n",
    "            - support: Boolean mask of selected features\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        p_total : int, optional\n",
    "            Total number of features in full library (for EBIC).\n",
    "            If None, uses max Phi.shape[1] across candidates.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Dictionary containing:\n",
    "            - cv_results: Dict of model -> (cv_mean, cv_std, cv_scores)\n",
    "            - ebic_results: Dict of model -> ebic_score\n",
    "            - best_model_cv: Name of best model by CV\n",
    "            - best_model_ebic: Name of best model by EBIC\n",
    "            - best_model_onese: Name of best model by one-SE rule\n",
    "            - ranking_cv: Models ranked by CV performance\n",
    "            - ranking_ebic: Models ranked by EBIC\n",
    "        \"\"\"\n",
    "        if p_total is None:\n",
    "            p_total = max(Phi.shape[1] for Phi, _ in candidates.values())\n",
    "        \n",
    "        # K-fold CV evaluation\n",
    "        self._cv_results = {}\n",
    "        for name, (Phi, support) in candidates.items():\n",
    "            cv_mean, cv_std, cv_scores = self._kfold_cv(Phi, y, support)\n",
    "            self._cv_results[name] = {\n",
    "                'cv_mean': cv_mean,\n",
    "                'cv_std': cv_std,\n",
    "                'cv_scores': cv_scores,\n",
    "                'cv_se': cv_std / np.sqrt(self.n_folds)\n",
    "            }\n",
    "        \n",
    "        # EBIC evaluation\n",
    "        self._ebic_results = {}\n",
    "        for name, (Phi, support) in candidates.items():\n",
    "            ebic = self._compute_ebic(Phi, y, support, p_total)\n",
    "            self._ebic_results[name] = ebic\n",
    "        \n",
    "        # Select best models\n",
    "        self._best_model_cv = min(\n",
    "            self._cv_results.keys(),\n",
    "            key=lambda x: self._cv_results[x]['cv_mean']\n",
    "        )\n",
    "        \n",
    "        self._best_model_ebic = min(\n",
    "            self._ebic_results.keys(),\n",
    "            key=lambda x: self._ebic_results[x]\n",
    "        )\n",
    "        \n",
    "        # One-SE rule\n",
    "        self._best_model_onese = self._one_se_rule(candidates)\n",
    "        \n",
    "        # Rankings\n",
    "        ranking_cv = sorted(\n",
    "            self._cv_results.keys(),\n",
    "            key=lambda x: self._cv_results[x]['cv_mean']\n",
    "        )\n",
    "        \n",
    "        ranking_ebic = sorted(\n",
    "            self._ebic_results.keys(),\n",
    "            key=lambda x: self._ebic_results[x]\n",
    "        )\n",
    "        \n",
    "        self._comparison_complete = True\n",
    "        \n",
    "        return {\n",
    "            'cv_results': self._cv_results,\n",
    "            'ebic_results': self._ebic_results,\n",
    "            'best_model_cv': self._best_model_cv,\n",
    "            'best_model_ebic': self._best_model_ebic,\n",
    "            'best_model_onese': self._best_model_onese,\n",
    "            'ranking_cv': ranking_cv,\n",
    "            'ranking_ebic': ranking_ebic,\n",
    "            'n_folds': self.n_folds,\n",
    "            'ebic_gamma': self.ebic_gamma\n",
    "        }\n",
    "    \n",
    "    def _kfold_cv(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        support: np.ndarray\n",
    "    ) -> Tuple[float, float, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Perform K-fold cross-validation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        support : np.ndarray\n",
    "            Boolean mask of selected features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[float, float, np.ndarray]\n",
    "            (cv_mean_mse, cv_std_mse, fold_scores)\n",
    "        \"\"\"\n",
    "        # Use only supported features\n",
    "        Phi_support = Phi[:, support]\n",
    "        \n",
    "        if Phi_support.shape[1] == 0:\n",
    "            # No features selected - return high error\n",
    "            return np.inf, 0.0, np.full(self.n_folds, np.inf)\n",
    "        \n",
    "        kf = KFold(\n",
    "            n_splits=self.n_folds,\n",
    "            shuffle=True,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for train_idx, test_idx in kf.split(Phi_support):\n",
    "            # Split data\n",
    "            X_train = Phi_support[train_idx]\n",
    "            X_test = Phi_support[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            y_test = y[test_idx]\n",
    "            \n",
    "            # Fit OLS on training data\n",
    "            try:\n",
    "                beta, _, _, _ = np.linalg.lstsq(X_train, y_train, rcond=None)\n",
    "            except np.linalg.LinAlgError:\n",
    "                fold_scores.append(np.inf)\n",
    "                continue\n",
    "            \n",
    "            # Predict on test data\n",
    "            y_pred = X_test @ beta\n",
    "            \n",
    "            # Compute MSE\n",
    "            mse = np.mean((y_test - y_pred)**2)\n",
    "            fold_scores.append(mse)\n",
    "        \n",
    "        fold_scores = np.array(fold_scores)\n",
    "        return np.mean(fold_scores), np.std(fold_scores), fold_scores\n",
    "    \n",
    "    def _compute_ebic(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        support: np.ndarray,\n",
    "        p_total: int\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Compute Extended BIC score.\n",
    "        \n",
    "        EBIC_gamma = n * log(RSS/n) + k * log(n) + 2 * gamma * log(C(p,k))\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        support : np.ndarray\n",
    "            Boolean mask of selected features\n",
    "        p_total : int\n",
    "            Total number of features in library\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            EBIC score (lower is better)\n",
    "        \"\"\"\n",
    "        n = len(y)\n",
    "        k = int(np.sum(support))\n",
    "        \n",
    "        if k == 0:\n",
    "            return np.inf\n",
    "        \n",
    "        # Fit OLS on support\n",
    "        Phi_support = Phi[:, support]\n",
    "        try:\n",
    "            beta, _, _, _ = np.linalg.lstsq(Phi_support, y, rcond=None)\n",
    "        except np.linalg.LinAlgError:\n",
    "            return np.inf\n",
    "        \n",
    "        # Compute RSS\n",
    "        y_pred = Phi_support @ beta\n",
    "        rss = np.sum((y - y_pred)**2)\n",
    "        \n",
    "        if rss <= 0:\n",
    "            rss = EPS_DIV\n",
    "        \n",
    "        # EBIC formula\n",
    "        # log(RSS/n) term\n",
    "        log_likelihood_term = n * np.log(rss / n)\n",
    "        \n",
    "        # BIC penalty: k * log(n)\n",
    "        bic_penalty = k * np.log(n)\n",
    "        \n",
    "        # Extended penalty: 2 * gamma * log(C(p,k))\n",
    "        # Use log of combination to avoid overflow\n",
    "        if k <= p_total:\n",
    "            log_comb = self._log_comb(p_total, k)\n",
    "            extended_penalty = 2 * self.ebic_gamma * log_comb\n",
    "        else:\n",
    "            extended_penalty = 0\n",
    "        \n",
    "        ebic = log_likelihood_term + bic_penalty + extended_penalty\n",
    "        \n",
    "        return ebic\n",
    "    \n",
    "    def _log_comb(\n",
    "        self,\n",
    "        n: int,\n",
    "        k: int\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Compute log of binomial coefficient.\n",
    "        \n",
    "        log(C(n,k)) = log(n!) - log(k!) - log((n-k)!)\n",
    "        Uses Stirling approximation for large values.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n : int\n",
    "            Total items\n",
    "        k : int\n",
    "            Items to choose\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            log(C(n,k))\n",
    "        \"\"\"\n",
    "        if k == 0 or k == n:\n",
    "            return 0.0\n",
    "        if k > n:\n",
    "            return 0.0\n",
    "        \n",
    "        # Use scipy's log of gamma function for accuracy\n",
    "        from scipy.special import gammaln\n",
    "        return gammaln(n + 1) - gammaln(k + 1) - gammaln(n - k + 1)\n",
    "    \n",
    "    def _one_se_rule(\n",
    "        self,\n",
    "        candidates: Dict[str, Tuple[np.ndarray, np.ndarray]]\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Apply one-SE rule for model selection.\n",
    "        \n",
    "        Select the simplest model within 1 standard error of the best.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        candidates : Dict\n",
    "            Candidate models\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Name of selected model\n",
    "        \"\"\"\n",
    "        # Get best CV score and its SE\n",
    "        best_cv_mean = self._cv_results[self._best_model_cv]['cv_mean']\n",
    "        best_cv_se = self._cv_results[self._best_model_cv]['cv_se']\n",
    "        \n",
    "        # Threshold: best + 1 SE\n",
    "        threshold = best_cv_mean + best_cv_se\n",
    "        \n",
    "        # Find simplest model within threshold\n",
    "        eligible_models = []\n",
    "        for name, (Phi, support) in candidates.items():\n",
    "            if self._cv_results[name]['cv_mean'] <= threshold:\n",
    "                complexity = int(np.sum(support))\n",
    "                eligible_models.append((name, complexity))\n",
    "        \n",
    "        if not eligible_models:\n",
    "            return self._best_model_cv\n",
    "        \n",
    "        # Select simplest\n",
    "        return min(eligible_models, key=lambda x: x[1])[0]\n",
    "    \n",
    "    def get_best_model(\n",
    "        self,\n",
    "        criterion: str = 'cv'\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get best model by specified criterion.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        criterion : str\n",
    "            'cv', 'ebic', or 'onese'\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Name of best model\n",
    "        \"\"\"\n",
    "        if not self._comparison_complete:\n",
    "            raise ValueError(\"Must run compare_models() first\")\n",
    "        \n",
    "        if criterion == 'cv':\n",
    "            return self._best_model_cv\n",
    "        elif criterion == 'ebic':\n",
    "            return self._best_model_ebic\n",
    "        elif criterion == 'onese':\n",
    "            return self._best_model_onese\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown criterion: {criterion}\")\n",
    "    \n",
    "    def print_comparison_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed model comparison report.\n",
    "        \"\"\"\n",
    "        if not self._comparison_complete:\n",
    "            print(\"Comparison not yet performed. Run compare_models() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" Model Selection Results\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  CV folds: {self.n_folds}\")\n",
    "        print(f\"  EBIC gamma: {self.ebic_gamma}\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Cross-Validation Results:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Model':<25} {'CV Mean MSE':<15} {'CV Std':<12} {'CV SE':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Sort by CV mean\n",
    "        sorted_models = sorted(\n",
    "            self._cv_results.keys(),\n",
    "            key=lambda x: self._cv_results[x]['cv_mean']\n",
    "        )\n",
    "        \n",
    "        for name in sorted_models:\n",
    "            r = self._cv_results[name]\n",
    "            marker = \" *\" if name == self._best_model_cv else \"\"\n",
    "            print(f\"{name:<25} {r['cv_mean']:<15.6f} {r['cv_std']:<12.6f} \"\n",
    "                  f\"{r['cv_se']:<12.6f}{marker}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" EBIC Results:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Model':<25} {'EBIC Score':<15}\")\n",
    "        print(\"-\" * 45)\n",
    "        \n",
    "        sorted_ebic = sorted(\n",
    "            self._ebic_results.keys(),\n",
    "            key=lambda x: self._ebic_results[x]\n",
    "        )\n",
    "        \n",
    "        for name in sorted_ebic:\n",
    "            ebic = self._ebic_results[name]\n",
    "            marker = \" *\" if name == self._best_model_ebic else \"\"\n",
    "            print(f\"{name:<25} {ebic:<15.4f}{marker}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Best Model Selection:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"  By CV:        {self._best_model_cv}\")\n",
    "        print(f\"  By EBIC:      {self._best_model_ebic}\")\n",
    "        print(f\"  By One-SE:    {self._best_model_onese}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 09_ModelSelection\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: CV with Known Best Model\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: CV with Known Best Model\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    # Generate data\n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    x3 = np.random.randn(n_samples)\n",
    "    \n",
    "    # True: y = 2*x1 + x2\n",
    "    y = 2*x1 + x2 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    # Feature library\n",
    "    Phi = np.column_stack([np.ones(n_samples), x1, x2, x3, x1**2, x2**2])\n",
    "    \n",
    "    # Candidate models\n",
    "    candidates = {\n",
    "        'correct': (Phi, np.array([False, True, True, False, False, False])),  # x1, x2\n",
    "        'overfit': (Phi, np.array([True, True, True, True, True, True])),       # All\n",
    "        'underfit': (Phi, np.array([False, True, False, False, False, False])), # Only x1\n",
    "    }\n",
    "    \n",
    "    print(\"True model: y = 2*x1 + x2\")\n",
    "    print(\"Candidates: correct (x1,x2), overfit (all), underfit (x1 only)\")\n",
    "    print()\n",
    "    \n",
    "    selector = ModelSelector(n_folds=5, ebic_gamma=0.5)\n",
    "    result = selector.compare_models(candidates, y, p_total=6)\n",
    "    \n",
    "    selector.print_comparison_report()\n",
    "    \n",
    "    if result['best_model_cv'] == 'correct':\n",
    "        print(\"[PASS] CV correctly identified the true model\")\n",
    "    else:\n",
    "        print(f\"[INFO] CV selected: {result['best_model_cv']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: EBIC Penalty Verification\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: EBIC Penalty Verification\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    \n",
    "    y = 2*x1 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    # Feature library with many features\n",
    "    Phi = np.column_stack([x1, x2] + [np.random.randn(n_samples) for _ in range(18)])\n",
    "    p_total = 20\n",
    "    \n",
    "    # Models of increasing complexity\n",
    "    candidates = {\n",
    "        'k=1': (Phi, np.array([True] + [False]*19)),\n",
    "        'k=5': (Phi, np.array([True]*5 + [False]*15)),\n",
    "        'k=10': (Phi, np.array([True]*10 + [False]*10)),\n",
    "    }\n",
    "    \n",
    "    print(f\"True model uses only x1 (k=1)\")\n",
    "    print(f\"Testing EBIC penalty for k=1, 5, 10 with gamma=0.5\")\n",
    "    print()\n",
    "    \n",
    "    selector = ModelSelector(n_folds=5, ebic_gamma=0.5)\n",
    "    result = selector.compare_models(candidates, y, p_total=p_total)\n",
    "    \n",
    "    print(f\"EBIC scores:\")\n",
    "    for name in ['k=1', 'k=5', 'k=10']:\n",
    "        print(f\"  {name}: {result['ebic_results'][name]:.2f}\")\n",
    "    \n",
    "    # EBIC should prefer simpler model\n",
    "    if result['best_model_ebic'] == 'k=1':\n",
    "        print(\"\\n[PASS] EBIC correctly penalized complex models\")\n",
    "    else:\n",
    "        print(f\"\\n[INFO] EBIC selected: {result['best_model_ebic']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: One-SE Rule\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: One-SE Rule\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    x2 = np.random.randn(n_samples)\n",
    "    x3 = np.random.randn(n_samples)\n",
    "    \n",
    "    # y = 2*x1 + 0.1*x2 (x2 has very small effect)\n",
    "    y = 2*x1 + 0.1*x2 + 0.5*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([x1, x2, x3])\n",
    "    \n",
    "    # Complex model slightly better but within SE\n",
    "    candidates = {\n",
    "        'simple': (Phi, np.array([True, False, False])),  # k=1\n",
    "        'medium': (Phi, np.array([True, True, False])),   # k=2 (true)\n",
    "        'complex': (Phi, np.array([True, True, True])),   # k=3\n",
    "    }\n",
    "    \n",
    "    print(\"True: y = 2*x1 + 0.1*x2 (noisy)\")\n",
    "    print(\"One-SE rule should prefer simpler model if within 1 SE of best\")\n",
    "    print()\n",
    "    \n",
    "    selector = ModelSelector(n_folds=5)\n",
    "    result = selector.compare_models(candidates, y)\n",
    "    \n",
    "    selector.print_comparison_report()\n",
    "    \n",
    "    print(f\"\\nOne-SE selection: {result['best_model_onese']}\")\n",
    "    print(\"(May prefer simpler model if CV scores are close)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: EBIC Gamma Sensitivity\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: EBIC Gamma Sensitivity\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    x1 = np.random.randn(n_samples)\n",
    "    y = 2*x1 + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    # Large library\n",
    "    Phi = np.column_stack([x1] + [np.random.randn(n_samples) for _ in range(49)])\n",
    "    p_total = 50\n",
    "    \n",
    "    candidates = {\n",
    "        'sparse': (Phi, np.array([True] + [False]*49)),\n",
    "        'dense': (Phi, np.array([True]*10 + [False]*40)),\n",
    "    }\n",
    "    \n",
    "    gamma_values = [0.0, 0.5, 1.0]\n",
    "    \n",
    "    print(f\"Testing EBIC with different gamma values:\")\n",
    "    print(f\"{'Gamma':<10} {'Sparse EBIC':<15} {'Dense EBIC':<15} {'Best'}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for gamma in gamma_values:\n",
    "        selector = ModelSelector(ebic_gamma=gamma)\n",
    "        result = selector.compare_models(candidates, y, p_total=p_total)\n",
    "        \n",
    "        print(f\"{gamma:<10.1f} {result['ebic_results']['sparse']:<15.2f} \"\n",
    "              f\"{result['ebic_results']['dense']:<15.2f} {result['best_model_ebic']}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Note: Higher gamma = stronger penalty for complex models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 09_ModelSelection.ipynb - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: ModelSelector\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Compare and select best model from Stage 2 candidates using\")\n",
    "print(\"  K-fold cross-validation and Extended BIC.\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  compare_models(candidates, y, p_total=None)\")\n",
    "print(\"      Compare candidates via CV and EBIC\")\n",
    "print(\"      candidates: Dict[name -> (Phi, support)]\")\n",
    "print(\"      Returns: dict with cv_results, ebic_results, best models\")\n",
    "print()\n",
    "print(\"  get_best_model(criterion='cv')\")\n",
    "print(\"      Get best model by 'cv', 'ebic', or 'onese'\")\n",
    "print()\n",
    "print(\"  print_comparison_report()\")\n",
    "print(\"      Print detailed comparison results\")\n",
    "print()\n",
    "print(\"Key Parameters:\")\n",
    "print(\"  n_folds: Number of CV folds (default: 5)\")\n",
    "print(\"  ebic_gamma: EBIC parameter 0-1 (default: 0.5)\")\n",
    "print()\n",
    "print(\"EBIC gamma guidelines:\")\n",
    "print(\"  0.0 = Near-BIC behavior (moderate p)\")\n",
    "print(\"  0.5 = Balanced (standard high-dim)\")\n",
    "print(\"  1.0 = Maximum penalty (p >> n)\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Collect candidate models from Stage 2\n",
    "candidates = {\n",
    "    'pysr': (Phi, pysr_support),\n",
    "    'stlsq': (Phi, stlsq_support),\n",
    "    'alasso': (Phi, alasso_support)\n",
    "}\n",
    "\n",
    "# Compare models\n",
    "selector = ModelSelector(n_folds=5, ebic_gamma=0.5)\n",
    "result = selector.compare_models(candidates, y, p_total=Phi.shape[1])\n",
    "\n",
    "# Get best model\n",
    "print(f\"Best by CV: {result['best_model_cv']}\")\n",
    "print(f\"Best by EBIC: {result['best_model_ebic']}\")\n",
    "print(f\"Best by One-SE: {result['best_model_onese']}\")\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 09_ModelSelection.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_FeatureLibrary - Physics-SR Framework v4.1\n",
    "\n",
    "## Stage 2.3: Augmented Feature Library Construction\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (5-Layer Physics-Guided Library Construction)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Build comprehensive augmented feature library combining physics-guided terms,\n",
    "PySR discoveries, and baseline features. This is a **MAJOR REDESIGN** from v3.0\n",
    "to support the new Structure-Guided Discovery pipeline.\n",
    "\n",
    "### v4.1 Five-Layer Library Construction\n",
    "\n",
    "| Layer | Source | Priority | Description |\n",
    "|-------|--------|----------|-------------|\n",
    "| 0 | `[PowLaw]` | **Highest** | Power-law terms from Stage 1 symmetry (inverse terms) |\n",
    "| 1 | `[PySR]` | High | Exact terms from PySR Pareto front |\n",
    "| 2 | `[Var]` | Medium | Variant terms via variable substitution |\n",
    "| 3 | `[Poly]` | Baseline | Polynomial terms (always included) |\n",
    "| 4 | `[Op]` | Safety net | Operator-guided simple terms |\n",
    "\n",
    "### v4.1 Key Enhancement: Layer 0 Power-Law Terms\n",
    "\n",
    "When Stage 1 symmetry analysis detects negative exponents (e.g., r^-2 in Coulomb's law),\n",
    "Layer 0 automatically adds inverse terms (1/r, 1/r^2) that standard polynomial libraries lack.\n",
    "This is **critical** for equations like F = k*q1*q2/r^2.\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "1. **KEEP:** If PySR found sin(x^2) and it's correct, E-WSINDy will select it\n",
    "2. **DISCOVER:** If PySR missed x*z, E-WSINDy can find it in polynomial layer\n",
    "3. **REJECT:** If PySR included spurious term, E-WSINDy's sparsity can exclude it\n",
    "4. **PHYSICS-GUIDED:** Layer 0 ensures correct basis for power-law physics\n",
    "\n",
    "### Algorithm Reference\n",
    "\n",
    "Framework v4.0/v4.1 Section 4.3: Augmented Library Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "05_FeatureLibrary.ipynb - Augmented Feature Library Construction\n",
    "=================================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v4.1\n",
    "\n",
    "This module provides:\n",
    "- AugmentedLibraryBuilder: Build 5-layer feature library from physics + PySR\n",
    "- Source tagging: [PowLaw], [PySR], [Var], [Poly], [Op] for term attribution\n",
    "- Power-law guided terms from Stage 1 symmetry analysis\n",
    "- Lazy variant generation based on PySR R-squared\n",
    "- Integration with Stage2Results for seamless pipeline\n",
    "\n",
    "v4.1 Key Changes from v3.0:\n",
    "- Renamed class: FeatureLibraryBuilder -> AugmentedLibraryBuilder\n",
    "- New build() signature accepts parsed_terms, detected_operators, estimated_exponents\n",
    "- 5-layer construction: Layer 0 [PowLaw] for physics-guided inverse terms\n",
    "- Lazy variant generation based on PySR performance\n",
    "\n",
    "Output Dictionary Keys (v4.1):\n",
    "- library_matrix: np.ndarray (n_samples, K)\n",
    "- library_names: List[str] with source tags\n",
    "- library_info: Dict with layer composition statistics (n_powerlaw_terms, etc.)\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for Feature Library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations_with_replacement\n",
    "from typing import Dict, List, Tuple, Optional, Any, Set, Callable\n",
    "from collections import Counter\n",
    "import sympy as sp\n",
    "from sympy import Symbol, sympify, lambdify, Add\n",
    "\n",
    "print(\"05_FeatureLibrary v4.1: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# AUGMENTED LIBRARY BUILDER CLASS (v4.1)\n",
    "# ==============================================================================\n",
    "\n",
    "class AugmentedLibraryBuilder:\n",
    "    \"\"\"\n",
    "    Augmented Feature Library Construction (v4.1 Enhanced).\n",
    "    \n",
    "    Builds 5-layer feature library combining physics-guided terms with PySR discoveries:\n",
    "    - Layer 0: Power-Law Guided Terms (from Stage 1 symmetry, highest priority)\n",
    "    - Layer 1: PySR Exact Terms (second priority)\n",
    "    - Layer 2: Variant Terms (variable substitution)\n",
    "    - Layer 3: Polynomial Baseline (always included)\n",
    "    - Layer 4: Operator-Guided Terms (from detected operators)\n",
    "    \n",
    "    v4.1 Enhancement: Layer 0 adds inverse terms (1/x, 1/x^2) when Stage 1 symmetry\n",
    "    analysis detects negative exponents. This is critical for equations like\n",
    "    Coulomb's law (F = k*q1*q2/r^2) where standard polynomial terms are insufficient.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    max_poly_degree : int\n",
    "        Maximum polynomial degree (default: 3)\n",
    "    generate_variants : bool\n",
    "        Whether to generate variant terms (default: True)\n",
    "    max_variants_per_term : int\n",
    "        Maximum variants per PySR term (default: 3)\n",
    "    include_operator_terms : bool\n",
    "        Whether to include operator-guided terms (default: True)\n",
    "    normalize : bool\n",
    "        Whether to standardize features (default: True)\n",
    "    lazy_variant_threshold : float\n",
    "        PySR R2 threshold for lazy variant generation (default: 0.95)\n",
    "    scaler : StandardScaler\n",
    "        Scaler object (public, for downstream use)\n",
    "    library_info : Dict\n",
    "        Library composition statistics (public)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    build(X, feature_names, parsed_terms, detected_operators, pysr_r2, estimated_exponents) -> Tuple\n",
    "        Build complete augmented library\n",
    "    build_from_pysr_results(X, feature_names, stage2_partial) -> Tuple\n",
    "        Build from partial Stage2Results containing PySR output\n",
    "    transform(X_new) -> np.ndarray\n",
    "        Transform new data using fitted library structure\n",
    "    print_library_summary() -> None\n",
    "        Print detailed library composition report\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Framework v4.1 Section 4.3: Augmented Library Construction\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> builder = AugmentedLibraryBuilder(max_poly_degree=3)\n",
    "    >>> Phi, names, info = builder.build(\n",
    "    ...     X, feature_names,\n",
    "    ...     parsed_terms=[(expr, 'sin(x**2)', func)],\n",
    "    ...     detected_operators={'sin'},\n",
    "    ...     pysr_r2=0.85,\n",
    "    ...     estimated_exponents={'q1': 1.0, 'r': -2.0}  # From Stage 1\n",
    "    ... )\n",
    "    >>> print(f\"Library size: {Phi.shape[1]} features\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        max_poly_degree: int = DEFAULT_MAX_POLY_DEGREE,\n",
    "        generate_variants: bool = True,\n",
    "        max_variants_per_term: int = 3,\n",
    "        include_operator_terms: bool = True,\n",
    "        normalize: bool = True,\n",
    "        lazy_variant_threshold: float = 0.95\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize AugmentedLibraryBuilder.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_poly_degree : int\n",
    "            Maximum polynomial degree. Features up to x^d are included.\n",
    "            Default: 3\n",
    "        generate_variants : bool\n",
    "            Whether to generate Layer 2 variant terms via variable substitution.\n",
    "            Default: True\n",
    "        max_variants_per_term : int\n",
    "            Maximum number of variants to generate per PySR term.\n",
    "            Default: 3\n",
    "        include_operator_terms : bool\n",
    "            Whether to include Layer 4 operator-guided simple terms.\n",
    "            Default: True\n",
    "        normalize : bool\n",
    "            Whether to standardize features to zero mean, unit variance.\n",
    "            Default: True\n",
    "        lazy_variant_threshold : float\n",
    "            If PySR R2 >= threshold, skip variant generation (lazy mode).\n",
    "            Default: 0.95\n",
    "        \"\"\"\n",
    "        self.max_poly_degree = max_poly_degree\n",
    "        self.generate_variants = generate_variants\n",
    "        self.max_variants_per_term = max_variants_per_term\n",
    "        self.include_operator_terms = include_operator_terms\n",
    "        self.normalize = normalize\n",
    "        self.lazy_variant_threshold = lazy_variant_threshold\n",
    "        \n",
    "        # Public attributes (v4.1)\n",
    "        self.scaler = None\n",
    "        self.library_info = None\n",
    "        \n",
    "        # Internal state (private)\n",
    "        self._feature_names = None\n",
    "        self._library_names = None\n",
    "        self._n_input_features = None\n",
    "        self._n_library_features = None\n",
    "        self._parsed_terms = None\n",
    "        self._detected_operators = None\n",
    "        self._feature_symbols = None\n",
    "        self._build_complete = False\n",
    "    \n",
    "    def build(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        feature_names: List[str],\n",
    "        parsed_terms: List[Tuple] = None,\n",
    "        detected_operators: set = None,\n",
    "        pysr_r2: float = 0.0,\n",
    "        estimated_exponents: Dict[str, float] = None\n",
    "    ) -> Tuple[np.ndarray, List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Build complete augmented feature library (v4.1 Enhanced).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix (n_samples, n_features)\n",
    "        feature_names : List[str]\n",
    "            Original feature names\n",
    "        parsed_terms : List[Tuple], optional\n",
    "            List of (expr, name, func) from StructureParser.\n",
    "            If None, only polynomial baseline is built.\n",
    "        detected_operators : set, optional\n",
    "            Set of operators found {'sin', 'cos', 'exp', ...}.\n",
    "            If None, no operator-guided terms are added.\n",
    "        pysr_r2 : float\n",
    "            PySR best R-squared (for lazy variant generation).\n",
    "            Default: 0.0\n",
    "        estimated_exponents : Dict[str, float], optional\n",
    "            Power-law exponents from Stage 1 symmetry analysis.\n",
    "            e.g., {'q1': 1.0, 'q2': 1.0, 'r': -2.0} for Coulomb's law.\n",
    "            If provided with negative exponents, adds inverse terms (Layer 0).\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Phi_aug : np.ndarray\n",
    "            Augmented feature matrix (n_samples, K)\n",
    "        library_names : List[str]\n",
    "            Feature names with source tags [PowLaw], [PySR], [Var], [Poly], [Op]\n",
    "        library_info : Dict\n",
    "            Library composition statistics\n",
    "        \"\"\"\n",
    "        self._feature_names = list(feature_names)\n",
    "        self._n_input_features = X.shape[1]\n",
    "        self._parsed_terms = parsed_terms or []\n",
    "        self._detected_operators = detected_operators or set()\n",
    "        self._estimated_exponents = estimated_exponents or {}\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Create SymPy symbols for variable substitution\n",
    "        self._feature_symbols = [Symbol(name) for name in feature_names]\n",
    "        \n",
    "        # Initialize containers\n",
    "        Phi_columns = []\n",
    "        Phi_names = []\n",
    "        \n",
    "        # Layer 0: Power-Law Guided Terms (highest priority, from Stage 1 symmetry)\n",
    "        n_powerlaw = 0\n",
    "        if self._estimated_exponents and len(self._estimated_exponents) > 0:\n",
    "            self._add_powerlaw_terms(X, Phi_columns, Phi_names, self._estimated_exponents)\n",
    "            n_powerlaw = len(Phi_names)\n",
    "        \n",
    "        # Layer 1: PySR Exact Terms\n",
    "        self._add_pysr_exact_terms(X, Phi_columns, Phi_names)\n",
    "        n_pysr = len(Phi_names) - n_powerlaw\n",
    "        \n",
    "        # Layer 2: Variant Terms (conditional on PySR R2)\n",
    "        if self.generate_variants and pysr_r2 < self.lazy_variant_threshold:\n",
    "            self._add_variant_terms(X, Phi_columns, Phi_names)\n",
    "        n_variant = len(Phi_names) - n_powerlaw - n_pysr\n",
    "        \n",
    "        # Layer 3: Polynomial Baseline (always included)\n",
    "        self._add_polynomial_terms(X, Phi_columns, Phi_names)\n",
    "        n_poly = len(Phi_names) - n_powerlaw - n_pysr - n_variant\n",
    "        \n",
    "        # Layer 4: Operator-Guided Terms (if operators detected)\n",
    "        if self.include_operator_terms and len(self._detected_operators) > 0:\n",
    "            self._add_operator_terms(X, Phi_columns, Phi_names)\n",
    "        n_op = len(Phi_names) - n_powerlaw - n_pysr - n_variant - n_poly\n",
    "        \n",
    "        # Assemble library matrix\n",
    "        if len(Phi_columns) == 0:\n",
    "            # Edge case: no features generated, add constant term\n",
    "            Phi_columns.append(np.ones(n_samples))\n",
    "            Phi_names.append('[Poly] 1')\n",
    "            n_poly = 1\n",
    "        \n",
    "        Phi_aug = np.column_stack(Phi_columns)\n",
    "        \n",
    "        # Handle numerical issues\n",
    "        Phi_aug = self._handle_numerical_issues(Phi_aug)\n",
    "        \n",
    "        # Normalize if requested (skip constant column)\n",
    "        if self.normalize:\n",
    "            Phi_aug = self._normalize_features(Phi_aug, Phi_names)\n",
    "        \n",
    "        # Record library composition\n",
    "        self.library_info = {\n",
    "            'n_powerlaw_terms': n_powerlaw,\n",
    "            'n_pysr_terms': n_pysr,\n",
    "            'n_variant_terms': n_variant,\n",
    "            'n_poly_terms': n_poly,\n",
    "            'n_op_terms': n_op,\n",
    "            'total_terms': len(Phi_names),\n",
    "            'pysr_r2': pysr_r2,\n",
    "            'lazy_mode': pysr_r2 >= self.lazy_variant_threshold,\n",
    "            'detected_operators': list(self._detected_operators),\n",
    "            'estimated_exponents': self._estimated_exponents\n",
    "        }\n",
    "        \n",
    "        self._library_names = Phi_names\n",
    "        self._n_library_features = Phi_aug.shape[1]\n",
    "        self._build_complete = True\n",
    "        \n",
    "        return Phi_aug, Phi_names, self.library_info\n",
    "    \n",
    "    def _add_pysr_exact_terms(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Phi_columns: List,\n",
    "        Phi_names: List\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Layer 1: Add exact terms from PySR.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        Phi_columns : List\n",
    "            List to append feature columns\n",
    "        Phi_names : List\n",
    "            List to append feature names\n",
    "        \"\"\"\n",
    "        for expr, name, func in self._parsed_terms:\n",
    "            try:\n",
    "                # Evaluate the term\n",
    "                values = func(*[X[:, i] for i in range(self._n_input_features)])\n",
    "                \n",
    "                # Validate and add\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[PySR] {name}')\n",
    "            except Exception:\n",
    "                # Skip terms that fail evaluation\n",
    "                continue\n",
    "    \n",
    "    def _add_variant_terms(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Phi_columns: List,\n",
    "        Phi_names: List\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Layer 2: Add variant terms via variable substitution.\n",
    "        \n",
    "        For each PySR term, substitute each free variable with other variables\n",
    "        to create variants that E-WSINDy can evaluate.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        Phi_columns : List\n",
    "            List to append feature columns\n",
    "        Phi_names : List\n",
    "            List to append feature names\n",
    "        \"\"\"\n",
    "        for expr, name, func in self._parsed_terms:\n",
    "            variants_added = 0\n",
    "            \n",
    "            # Get free variables in this expression\n",
    "            try:\n",
    "                free_vars = list(expr.free_symbols)\n",
    "            except Exception:\n",
    "                continue\n",
    "            \n",
    "            # For each free variable, try substituting with other variables\n",
    "            for var in free_vars:\n",
    "                if variants_added >= self.max_variants_per_term:\n",
    "                    break\n",
    "                \n",
    "                for other_symbol in self._feature_symbols:\n",
    "                    if other_symbol == var:\n",
    "                        continue\n",
    "                    if variants_added >= self.max_variants_per_term:\n",
    "                        break\n",
    "                    \n",
    "                    try:\n",
    "                        # Create variant expression\n",
    "                        variant_expr = expr.subs(var, other_symbol)\n",
    "                        \n",
    "                        # Skip if variant is same as original\n",
    "                        if str(variant_expr) == str(expr):\n",
    "                            continue\n",
    "                        \n",
    "                        # Create evaluation function\n",
    "                        variant_func = lambdify(\n",
    "                            self._feature_symbols, \n",
    "                            variant_expr, \n",
    "                            modules=['numpy']\n",
    "                        )\n",
    "                        \n",
    "                        # Evaluate\n",
    "                        values = variant_func(*[X[:, i] for i in range(self._n_input_features)])\n",
    "                        \n",
    "                        # Validate and add\n",
    "                        if self._is_valid_feature(values, Phi_columns):\n",
    "                            Phi_columns.append(values)\n",
    "                            Phi_names.append(f'[Var] {str(variant_expr)}')\n",
    "                            variants_added += 1\n",
    "                    except Exception:\n",
    "                        continue\n",
    "    \n",
    "    def _add_polynomial_terms(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Phi_columns: List,\n",
    "        Phi_names: List\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Layer 3: Add polynomial baseline terms.\n",
    "        \n",
    "        Includes constant, linear, and higher-order polynomial terms.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        Phi_columns : List\n",
    "            List to append feature columns\n",
    "        Phi_names : List\n",
    "            List to append feature names\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Constant term\n",
    "        const_values = np.ones(n_samples)\n",
    "        if self._is_valid_feature(const_values, Phi_columns):\n",
    "            Phi_columns.append(const_values)\n",
    "            Phi_names.append('[Poly] 1')\n",
    "        \n",
    "        # Linear terms\n",
    "        for i, name in enumerate(self._feature_names):\n",
    "            values = X[:, i].copy()\n",
    "            if self._is_valid_feature(values, Phi_columns):\n",
    "                Phi_columns.append(values)\n",
    "                Phi_names.append(f'[Poly] {name}')\n",
    "        \n",
    "        # Higher degree terms\n",
    "        for degree in range(2, self.max_poly_degree + 1):\n",
    "            for combo in combinations_with_replacement(range(n_features), degree):\n",
    "                # Compute product\n",
    "                product = np.ones(n_samples)\n",
    "                for idx in combo:\n",
    "                    product = product * X[:, idx]\n",
    "                \n",
    "                # Build name\n",
    "                term_name = self._build_polynomial_name(combo)\n",
    "                \n",
    "                # Validate and add\n",
    "                if self._is_valid_feature(product, Phi_columns):\n",
    "                    Phi_columns.append(product)\n",
    "                    Phi_names.append(f'[Poly] {term_name}')\n",
    "    \n",
    "    def _add_operator_terms(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Phi_columns: List,\n",
    "        Phi_names: List\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Layer 4: Add operator-guided simple terms.\n",
    "        \n",
    "        Based on detected operators from PySR, add simple applications\n",
    "        of those operators to each variable.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        Phi_columns : List\n",
    "            List to append feature columns\n",
    "        Phi_names : List\n",
    "            List to append feature names\n",
    "        \"\"\"\n",
    "        for var_idx, var_name in enumerate(self._feature_names):\n",
    "            x = X[:, var_idx]\n",
    "            \n",
    "            # sin operator\n",
    "            if 'sin' in self._detected_operators:\n",
    "                values = np.sin(x)\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[Op] sin({var_name})')\n",
    "            \n",
    "            # cos operator\n",
    "            if 'cos' in self._detected_operators:\n",
    "                values = np.cos(x)\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[Op] cos({var_name})')\n",
    "            \n",
    "            # exp operator (both positive and negative)\n",
    "            if 'exp' in self._detected_operators:\n",
    "                for sign, sign_str in [(1, ''), (-1, '-')]:\n",
    "                    # Clip to prevent overflow\n",
    "                    clipped = np.clip(sign * x, -20, 20)\n",
    "                    values = np.exp(clipped)\n",
    "                    if self._is_valid_feature(values, Phi_columns):\n",
    "                        Phi_columns.append(values)\n",
    "                        Phi_names.append(f'[Op] exp({sign_str}{var_name})')\n",
    "            \n",
    "            # sqrt operator\n",
    "            if 'sqrt' in self._detected_operators:\n",
    "                values = np.sqrt(np.abs(x) + 1e-10)\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[Op] sqrt(|{var_name}|)')\n",
    "            \n",
    "            # log operator\n",
    "            if 'log' in self._detected_operators:\n",
    "                values = np.log(np.abs(x) + 1e-10)\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[Op] log(|{var_name}|)')\n",
    "    \n",
    "    def _add_powerlaw_terms(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        Phi_columns: List,\n",
    "        Phi_names: List,\n",
    "        estimated_exponents: Dict[str, float]\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Layer 0 (Highest Priority): Add power-law guided terms.\n",
    "        \n",
    "        When Stage 1 symmetry analysis detects power-law structure,\n",
    "        this method adds terms that match the detected exponents.\n",
    "        This is critical for equations like Coulomb's law (F = k*q1*q2/r^2)\n",
    "        where the standard polynomial library lacks inverse terms.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix (n_samples, n_features)\n",
    "        Phi_columns : List\n",
    "            List to append feature columns\n",
    "        Phi_names : List\n",
    "            List to append feature names\n",
    "        estimated_exponents : Dict[str, float]\n",
    "            Mapping from variable name to estimated exponent\n",
    "            e.g., {'q1': 1.0, 'q2': 1.0, 'r': -2.0}\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Identify variables with negative exponents (need inverse terms)\n",
    "        negative_exp_vars = []\n",
    "        positive_exp_vars = []\n",
    "        \n",
    "        for i, name in enumerate(self._feature_names):\n",
    "            name_str = str(name)\n",
    "            if name_str in estimated_exponents:\n",
    "                exp = estimated_exponents[name_str]\n",
    "                if exp < -0.5:\n",
    "                    negative_exp_vars.append((i, name_str, exp))\n",
    "                elif exp > 0.5:\n",
    "                    positive_exp_vars.append((i, name_str, exp))\n",
    "        \n",
    "        # Add inverse terms for negative exponent variables\n",
    "        for var_idx, var_name, exp in negative_exp_vars:\n",
    "            x = np.abs(X[:, var_idx])\n",
    "            x = np.clip(x, 1e-10, None)  # Avoid division by zero\n",
    "            \n",
    "            # 1/x term\n",
    "            values = 1.0 / x\n",
    "            if self._is_valid_feature(values, Phi_columns):\n",
    "                Phi_columns.append(values)\n",
    "                Phi_names.append(f'[PowLaw] 1/{var_name}')\n",
    "            \n",
    "            # 1/x^2 term (for exponents near -2)\n",
    "            if exp < -1.5:\n",
    "                values = 1.0 / (x ** 2)\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[PowLaw] 1/{var_name}^2')\n",
    "            \n",
    "            # 1/x^3 term (for exponents near -3)\n",
    "            if exp < -2.5:\n",
    "                values = 1.0 / (x ** 3)\n",
    "                if self._is_valid_feature(values, Phi_columns):\n",
    "                    Phi_columns.append(values)\n",
    "                    Phi_names.append(f'[PowLaw] 1/{var_name}^3')\n",
    "        \n",
    "        # Build the full power-law interaction term\n",
    "        # e.g., q1^1 * q2^1 * r^(-2) = q1 * q2 / r^2\n",
    "        if len(positive_exp_vars) > 0 or len(negative_exp_vars) > 0:\n",
    "            # Compute product of all terms with their exponents\n",
    "            power_product = np.ones(n_samples)\n",
    "            numerator_parts = []\n",
    "            denominator_parts = []\n",
    "            \n",
    "            for var_idx, var_name, exp in positive_exp_vars:\n",
    "                x = X[:, var_idx]\n",
    "                rounded_exp = round(exp)\n",
    "                if rounded_exp == 1:\n",
    "                    power_product *= x\n",
    "                    numerator_parts.append(var_name)\n",
    "                elif rounded_exp == 2:\n",
    "                    power_product *= x ** 2\n",
    "                    numerator_parts.append(f'{var_name}^2')\n",
    "                elif rounded_exp > 0:\n",
    "                    power_product *= np.power(np.abs(x), rounded_exp)\n",
    "                    numerator_parts.append(f'{var_name}^{rounded_exp}')\n",
    "            \n",
    "            for var_idx, var_name, exp in negative_exp_vars:\n",
    "                x = np.abs(X[:, var_idx])\n",
    "                x = np.clip(x, 1e-10, None)\n",
    "                rounded_exp = round(abs(exp))\n",
    "                if rounded_exp == 1:\n",
    "                    power_product /= x\n",
    "                    denominator_parts.append(var_name)\n",
    "                elif rounded_exp == 2:\n",
    "                    power_product /= (x ** 2)\n",
    "                    denominator_parts.append(f'{var_name}^2')\n",
    "                else:\n",
    "                    power_product /= (x ** rounded_exp)\n",
    "                    denominator_parts.append(f'{var_name}^{rounded_exp}')\n",
    "            \n",
    "            # Build readable name\n",
    "            if len(numerator_parts) > 0 and len(denominator_parts) > 0:\n",
    "                combined_name = '*'.join(numerator_parts) + '/' + '*'.join(denominator_parts)\n",
    "            elif len(numerator_parts) > 0:\n",
    "                combined_name = '*'.join(numerator_parts)\n",
    "            elif len(denominator_parts) > 0:\n",
    "                combined_name = '1/' + '*'.join(denominator_parts)\n",
    "            else:\n",
    "                combined_name = '1'\n",
    "            \n",
    "            # Add the combined term\n",
    "            if self._is_valid_feature(power_product, Phi_columns):\n",
    "                Phi_columns.append(power_product)\n",
    "                Phi_names.append(f'[PowLaw] {combined_name}')\n",
    "            \n",
    "            # Also add partial products (for robustness)\n",
    "            # e.g., q1*q2 alone, without the r^-2\n",
    "            if len(positive_exp_vars) >= 2:\n",
    "                partial_product = np.ones(n_samples)\n",
    "                partial_parts = []\n",
    "                for var_idx, var_name, exp in positive_exp_vars:\n",
    "                    x = X[:, var_idx]\n",
    "                    partial_product *= x\n",
    "                    partial_parts.append(var_name)\n",
    "                \n",
    "                partial_name = '*'.join(partial_parts)\n",
    "                if self._is_valid_feature(partial_product, Phi_columns):\n",
    "                    Phi_columns.append(partial_product)\n",
    "                    Phi_names.append(f'[PowLaw] {partial_name}')\n",
    "            \n",
    "            # Add positive vars with just one inverse term (for exploration)\n",
    "            if len(positive_exp_vars) >= 1 and len(negative_exp_vars) >= 1:\n",
    "                for neg_idx, neg_name, neg_exp in negative_exp_vars:\n",
    "                    x_neg = np.abs(X[:, neg_idx])\n",
    "                    x_neg = np.clip(x_neg, 1e-10, None)\n",
    "                    \n",
    "                    for pos_idx, pos_name, pos_exp in positive_exp_vars:\n",
    "                        x_pos = X[:, pos_idx]\n",
    "                        \n",
    "                        # x_pos / x_neg\n",
    "                        values = x_pos / x_neg\n",
    "                        term_name = f'{pos_name}/{neg_name}'\n",
    "                        if self._is_valid_feature(values, Phi_columns):\n",
    "                            Phi_columns.append(values)\n",
    "                            Phi_names.append(f'[PowLaw] {term_name}')\n",
    "                        \n",
    "                        # x_pos / x_neg^2 (if exp is near -2)\n",
    "                        if neg_exp < -1.5:\n",
    "                            values = x_pos / (x_neg ** 2)\n",
    "                            term_name = f'{pos_name}/{neg_name}^2'\n",
    "                            if self._is_valid_feature(values, Phi_columns):\n",
    "                                Phi_columns.append(values)\n",
    "                                Phi_names.append(f'[PowLaw] {term_name}')\n",
    "    \n",
    "    def _build_polynomial_name(\n",
    "        self,\n",
    "        indices: Tuple[int, ...]\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Build human-readable name for polynomial term.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        indices : Tuple[int, ...]\n",
    "            Tuple of feature indices (may have repeats)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Name like \"x^2\" or \"x*y\"\n",
    "        \"\"\"\n",
    "        counts = Counter(indices)\n",
    "        \n",
    "        parts = []\n",
    "        for idx in sorted(counts.keys()):\n",
    "            name = self._feature_names[idx]\n",
    "            power = counts[idx]\n",
    "            if power == 1:\n",
    "                parts.append(name)\n",
    "            else:\n",
    "                parts.append(f'{name}^{power}')\n",
    "        \n",
    "        return '*'.join(parts)\n",
    "    \n",
    "    def _is_valid_feature(\n",
    "        self,\n",
    "        values: np.ndarray,\n",
    "        existing_columns: List[np.ndarray]\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Check if feature values are valid (finite, non-constant, non-duplicate).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        values : np.ndarray\n",
    "            Feature values to check\n",
    "        existing_columns : List[np.ndarray]\n",
    "            List of existing feature columns\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if valid, False otherwise\n",
    "        \"\"\"\n",
    "        # Ensure 1D array\n",
    "        values = np.asarray(values).flatten()\n",
    "        \n",
    "        # Check finite\n",
    "        if not np.all(np.isfinite(values)):\n",
    "            return False\n",
    "        \n",
    "        # Check non-constant\n",
    "        if np.std(values) < 1e-10:\n",
    "            return False\n",
    "        \n",
    "        # Check non-duplicate\n",
    "        for existing in existing_columns:\n",
    "            if np.allclose(values, existing, rtol=1e-5, atol=1e-10):\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _handle_numerical_issues(\n",
    "        self,\n",
    "        Phi: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Handle NaN and Inf values in feature matrix.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Cleaned feature matrix\n",
    "        \"\"\"\n",
    "        # Replace NaN with 0\n",
    "        Phi = np.nan_to_num(Phi, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "        \n",
    "        # Clip extreme values\n",
    "        Phi = np.clip(Phi, -1e10, 1e10)\n",
    "        \n",
    "        return Phi\n",
    "    \n",
    "    def _normalize_features(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        Phi_names: List[str]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Standardize features to zero mean, unit variance.\n",
    "        Skips the constant column.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        Phi_names : List[str]\n",
    "            Feature names (to identify constant column)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Normalized feature matrix\n",
    "        \"\"\"\n",
    "        # Find constant column index\n",
    "        const_idx = None\n",
    "        for i, name in enumerate(Phi_names):\n",
    "            if name == '[Poly] 1':\n",
    "                const_idx = i\n",
    "                break\n",
    "        \n",
    "        # Create scaler\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        if const_idx is not None:\n",
    "            # Normalize non-constant columns only\n",
    "            non_const_mask = np.ones(Phi.shape[1], dtype=bool)\n",
    "            non_const_mask[const_idx] = False\n",
    "            \n",
    "            if np.sum(non_const_mask) > 0:\n",
    "                Phi_normalized = Phi.copy()\n",
    "                Phi_normalized[:, non_const_mask] = self.scaler.fit_transform(\n",
    "                    Phi[:, non_const_mask]\n",
    "                )\n",
    "                return Phi_normalized\n",
    "        \n",
    "        # Normalize all columns if no constant found\n",
    "        return self.scaler.fit_transform(Phi)\n",
    "    \n",
    "    def build_from_pysr_results(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        feature_names: List[str],\n",
    "        stage2_partial: 'Stage2Results'\n",
    "    ) -> Tuple[np.ndarray, List[str], Dict]:\n",
    "        \"\"\"\n",
    "        Build augmented library from partial Stage2Results.\n",
    "        \n",
    "        Convenience method that extracts parsed_terms and detected_operators\n",
    "        from a Stage2Results object that has PySR and Structure Parsing completed.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        feature_names : List[str]\n",
    "            Feature names\n",
    "        stage2_partial : Stage2Results\n",
    "            Partially populated Stage2Results with PySR output\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str], Dict]\n",
    "            Augmented library matrix, names, and info\n",
    "        \"\"\"\n",
    "        return self.build(\n",
    "            X=X,\n",
    "            feature_names=feature_names,\n",
    "            parsed_terms=stage2_partial.parsed_terms,\n",
    "            detected_operators=stage2_partial.detected_operators,\n",
    "            pysr_r2=stage2_partial.best_pysr_r2 or 0.0\n",
    "        )\n",
    "    \n",
    "    def transform(\n",
    "        self,\n",
    "        X_new: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transform new data using the fitted library structure.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_new : np.ndarray\n",
    "            New feature matrix (n_samples_new, n_features)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Transformed feature matrix (n_samples_new, K)\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If build() has not been called\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            raise RuntimeError('Must call build() before transform()')\n",
    "        \n",
    "        # Rebuild library for new data (without fitting scaler)\n",
    "        n_samples = X_new.shape[0]\n",
    "        Phi_columns = []\n",
    "        \n",
    "        # Regenerate features in same order\n",
    "        for name in self._library_names:\n",
    "            values = self._evaluate_term(X_new, name)\n",
    "            Phi_columns.append(values)\n",
    "        \n",
    "        Phi_new = np.column_stack(Phi_columns)\n",
    "        Phi_new = self._handle_numerical_issues(Phi_new)\n",
    "        \n",
    "        # Apply saved scaler\n",
    "        if self.normalize and self.scaler is not None:\n",
    "            const_idx = None\n",
    "            for i, name in enumerate(self._library_names):\n",
    "                if name == '[Poly] 1':\n",
    "                    const_idx = i\n",
    "                    break\n",
    "            \n",
    "            if const_idx is not None:\n",
    "                non_const_mask = np.ones(Phi_new.shape[1], dtype=bool)\n",
    "                non_const_mask[const_idx] = False\n",
    "                if np.sum(non_const_mask) > 0:\n",
    "                    Phi_new[:, non_const_mask] = self.scaler.transform(\n",
    "                        Phi_new[:, non_const_mask]\n",
    "                    )\n",
    "            else:\n",
    "                Phi_new = self.scaler.transform(Phi_new)\n",
    "        \n",
    "        return Phi_new\n",
    "    \n",
    "    def _evaluate_term(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        name: str\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Evaluate a single term by its name.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        name : str\n",
    "            Term name with source tag\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Evaluated values\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Parse source tag and expression\n",
    "        if name.startswith('[Poly] 1'):\n",
    "            return np.ones(n_samples)\n",
    "        \n",
    "        # Extract expression after tag (v4.1: Added [PowLaw])\n",
    "        for tag in ['[PowLaw] ', '[PySR] ', '[Var] ', '[Poly] ', '[Op] ']:\n",
    "            if name.startswith(tag):\n",
    "                expr_str = name[len(tag):]\n",
    "                break\n",
    "        else:\n",
    "            expr_str = name\n",
    "        \n",
    "        # Try to evaluate using SymPy\n",
    "        try:\n",
    "            local_dict = {n: Symbol(n) for n in self._feature_names}\n",
    "            local_dict.update({\n",
    "                'sqrt': sp.sqrt, 'exp': sp.exp, 'log': sp.log,\n",
    "                'sin': sp.sin, 'cos': sp.cos, 'abs': sp.Abs\n",
    "            })\n",
    "            \n",
    "            expr = sympify(expr_str, locals=local_dict)\n",
    "            func = lambdify(self._feature_symbols, expr, modules=['numpy'])\n",
    "            return func(*[X[:, i] for i in range(X.shape[1])])\n",
    "        except Exception:\n",
    "            # Fallback: return zeros\n",
    "            return np.zeros(n_samples)\n",
    "    \n",
    "    def get_library_names(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get list of library feature names.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "            Feature names with source tags\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If build() has not been called\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            raise RuntimeError('Must call build() before getting library names')\n",
    "        return self._library_names.copy()\n",
    "    \n",
    "    def get_feature_count(self) -> int:\n",
    "        \"\"\"\n",
    "        Get total number of library features.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of features in library\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If build() has not been called\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            raise RuntimeError('Must call build() before getting feature count')\n",
    "        return self._n_library_features\n",
    "    \n",
    "    def print_library_summary(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed library composition report in v4.1 format.\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            print('Library not yet built. Call build() first.')\n",
    "            return\n",
    "        \n",
    "        print('=' * 70)\n",
    "        print('=== Augmented Library Construction (v4.1 Enhanced) ===')\n",
    "        print('=' * 70)\n",
    "        print()\n",
    "        print('Layer Composition:')\n",
    "        print(f\"  Layer 0 (Power-Law):    {self.library_info.get('n_powerlaw_terms', 0):>4} terms\")\n",
    "        print(f\"  Layer 1 (PySR Exact):   {self.library_info['n_pysr_terms']:>4} terms\")\n",
    "        print(f\"  Layer 2 (Variants):     {self.library_info['n_variant_terms']:>4} terms\")\n",
    "        print(f\"  Layer 3 (Polynomial):   {self.library_info['n_poly_terms']:>4} terms\")\n",
    "        print(f\"  Layer 4 (Operator):     {self.library_info['n_op_terms']:>4} terms\")\n",
    "        print('-' * 40)\n",
    "        print(f\"  Total:                  {self.library_info['total_terms']:>4} terms\")\n",
    "        print()\n",
    "        print('Configuration:')\n",
    "        print(f\"  Max polynomial degree: {self.max_poly_degree}\")\n",
    "        print(f\"  PySR R2: {self.library_info['pysr_r2']:.4f}\")\n",
    "        print(f\"  Lazy mode: {self.library_info['lazy_mode']}\")\n",
    "        if self.library_info.get('estimated_exponents'):\n",
    "            print(f\"  Power-law exponents: {self.library_info['estimated_exponents']}\")\n",
    "        if self.library_info['detected_operators']:\n",
    "            print(f\"  Detected operators: {self.library_info['detected_operators']}\")\n",
    "        print()\n",
    "        print('Sample Feature Names:')\n",
    "        # Show up to 3 from each layer\n",
    "        for tag, layer_name in [('[PowLaw]', 'Power-Law'), ('[PySR]', 'PySR'), \n",
    "                                 ('[Var]', 'Variant'), ('[Poly]', 'Polynomial'), \n",
    "                                 ('[Op]', 'Operator')]:\n",
    "            layer_features = [n for n in self._library_names if n.startswith(tag)]\n",
    "            if layer_features:\n",
    "                print(f\"  {layer_name}:\")\n",
    "                for name in layer_features[:3]:\n",
    "                    print(f\"    {name}\")\n",
    "                if len(layer_features) > 3:\n",
    "                    print(f\"    ... ({len(layer_features) - 3} more)\")\n",
    "        print()\n",
    "        print('=' * 70)\n",
    "\n",
    "print('AugmentedLibraryBuilder class defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# BACKWARD COMPATIBILITY ALIAS\n",
    "# ==============================================================================\n",
    "\n",
    "# v3.0 class name alias for backward compatibility\n",
    "FeatureLibraryBuilder = AugmentedLibraryBuilder\n",
    "\n",
    "print('FeatureLibraryBuilder alias defined for backward compatibility.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print('=' * 70)\n",
    "    print(' RUNNING INTERNAL TESTS FOR 05_FeatureLibrary v4.1')\n",
    "    print('=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Layer 1 - PySR Exact Terms\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header('Test 1: Layer 1 - PySR Exact Terms')\n",
    "    \n",
    "    # Generate test data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.uniform(0.1, 2.0, (n_samples, 3))\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Simulate PySR parsed terms: sin(x**2), y*exp(-z), x*y\n",
    "    x_sym, y_sym, z_sym = Symbol('x'), Symbol('y'), Symbol('z')\n",
    "    \n",
    "    term1_expr = sp.sin(x_sym**2)\n",
    "    term1_func = lambdify([x_sym, y_sym, z_sym], term1_expr, modules=['numpy'])\n",
    "    \n",
    "    term2_expr = y_sym * sp.exp(-z_sym)\n",
    "    term2_func = lambdify([x_sym, y_sym, z_sym], term2_expr, modules=['numpy'])\n",
    "    \n",
    "    term3_expr = x_sym * y_sym\n",
    "    term3_func = lambdify([x_sym, y_sym, z_sym], term3_expr, modules=['numpy'])\n",
    "    \n",
    "    parsed_terms = [\n",
    "        (term1_expr, 'sin(x**2)', term1_func),\n",
    "        (term2_expr, 'y*exp(-z)', term2_func),\n",
    "        (term3_expr, 'x*y', term3_func)\n",
    "    ]\n",
    "    \n",
    "    detected_operators = {'sin', 'exp'}\n",
    "    \n",
    "    # Build library with only Layer 1 (disable other layers)\n",
    "    builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=1,  # Minimal polynomial\n",
    "        generate_variants=False,\n",
    "        include_operator_terms=False,\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    Phi, names, info = builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=parsed_terms,\n",
    "        detected_operators=detected_operators,\n",
    "        pysr_r2=0.85\n",
    "    )\n",
    "    \n",
    "    print(f'Library shape: {Phi.shape}')\n",
    "    print(f'Library info: {info}')\n",
    "    print()\n",
    "    print('Feature names:')\n",
    "    for name in names:\n",
    "        print(f'  {name}')\n",
    "    \n",
    "    # Check Layer 1 terms are present\n",
    "    pysr_names = [n for n in names if n.startswith('[PySR]')]\n",
    "    print()\n",
    "    if len(pysr_names) == 3:\n",
    "        print('[PASS] All 3 PySR exact terms added to library')\n",
    "    else:\n",
    "        print(f'[WARNING] Expected 3 PySR terms, got {len(pysr_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Layer 2 - Variant Terms Generation\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header('Test 2: Layer 2 - Variant Terms Generation')\n",
    "    \n",
    "    # Use same data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.uniform(0.1, 2.0, (n_samples, 3))\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Single PySR term: sin(x**2)\n",
    "    x_sym, y_sym, z_sym = Symbol('x'), Symbol('y'), Symbol('z')\n",
    "    term_expr = sp.sin(x_sym**2)\n",
    "    term_func = lambdify([x_sym, y_sym, z_sym], term_expr, modules=['numpy'])\n",
    "    \n",
    "    parsed_terms = [(term_expr, 'sin(x**2)', term_func)]\n",
    "    \n",
    "    # Build with variant generation\n",
    "    builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=1,\n",
    "        generate_variants=True,\n",
    "        max_variants_per_term=3,\n",
    "        include_operator_terms=False,\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    Phi, names, info = builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=parsed_terms,\n",
    "        detected_operators=set(),\n",
    "        pysr_r2=0.70  # Low R2 triggers variant generation\n",
    "    )\n",
    "    \n",
    "    print(f'Library info: {info}')\n",
    "    print()\n",
    "    print('All features:')\n",
    "    for name in names:\n",
    "        print(f'  {name}')\n",
    "    \n",
    "    # Check variants are generated\n",
    "    variant_names = [n for n in names if n.startswith('[Var]')]\n",
    "    print()\n",
    "    if len(variant_names) > 0:\n",
    "        print(f'[PASS] Generated {len(variant_names)} variant terms')\n",
    "        # Check expected variants: sin(y**2), sin(z**2)\n",
    "        expected_variants = ['sin(y**2)', 'sin(z**2)']\n",
    "        found = [v for v in expected_variants if any(v in n for n in variant_names)]\n",
    "        print(f'  Found expected variants: {found}')\n",
    "    else:\n",
    "        print('[WARNING] No variant terms generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: Layer 3 - Polynomial Baseline\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header('Test 3: Layer 3 - Polynomial Baseline')\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.uniform(0.1, 2.0, (n_samples, 3))\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Build with polynomial only (no PySR input)\n",
    "    builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=2,\n",
    "        generate_variants=False,\n",
    "        include_operator_terms=False,\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    Phi, names, info = builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=None,  # No PySR terms\n",
    "        detected_operators=None\n",
    "    )\n",
    "    \n",
    "    print(f'Library info: {info}')\n",
    "    print()\n",
    "    print('Polynomial features:')\n",
    "    for name in names:\n",
    "        print(f'  {name}')\n",
    "    \n",
    "    # Expected: 1 + 3 linear + 6 quadratic = 10 terms\n",
    "    expected_count = 1 + 3 + 6\n",
    "    print()\n",
    "    if info['n_poly_terms'] == expected_count:\n",
    "        print(f'[PASS] Correct polynomial count: {expected_count}')\n",
    "    else:\n",
    "        print(f'[WARNING] Expected {expected_count} polynomial terms, got {info[\"n_poly_terms\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: Layer 4 - Operator-Guided Terms\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header('Test 4: Layer 4 - Operator-Guided Terms')\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.uniform(0.1, 2.0, (n_samples, 3))\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Detected operators\n",
    "    detected_operators = {'sin', 'cos', 'exp'}\n",
    "    \n",
    "    # Build with operator terms\n",
    "    builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=1,\n",
    "        generate_variants=False,\n",
    "        include_operator_terms=True,\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    Phi, names, info = builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=None,\n",
    "        detected_operators=detected_operators\n",
    "    )\n",
    "    \n",
    "    print(f'Library info: {info}')\n",
    "    print()\n",
    "    print('Operator-guided features:')\n",
    "    op_names = [n for n in names if n.startswith('[Op]')]\n",
    "    for name in op_names:\n",
    "        print(f'  {name}')\n",
    "    \n",
    "    # Expected: sin(x,y,z) + cos(x,y,z) + exp(x,-x,y,-y,z,-z) = 3 + 3 + 6 = 12\n",
    "    print()\n",
    "    if info['n_op_terms'] > 0:\n",
    "        print(f'[PASS] Generated {info[\"n_op_terms\"]} operator-guided terms')\n",
    "    else:\n",
    "        print('[WARNING] No operator-guided terms generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Full 4-Layer Library Construction\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header('Test 5: Full 4-Layer Library Construction')\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.uniform(0.1, 2.0, (n_samples, 3))\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    # Simulate complete PySR output\n",
    "    x_sym, y_sym, z_sym = Symbol('x'), Symbol('y'), Symbol('z')\n",
    "    \n",
    "    term1 = sp.sin(x_sym**2)\n",
    "    term2 = y_sym * sp.exp(-z_sym)\n",
    "    \n",
    "    parsed_terms = [\n",
    "        (term1, 'sin(x**2)', lambdify([x_sym, y_sym, z_sym], term1, modules=['numpy'])),\n",
    "        (term2, 'y*exp(-z)', lambdify([x_sym, y_sym, z_sym], term2, modules=['numpy']))\n",
    "    ]\n",
    "    \n",
    "    detected_operators = {'sin', 'exp'}\n",
    "    \n",
    "    # Full build\n",
    "    builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=2,\n",
    "        generate_variants=True,\n",
    "        max_variants_per_term=2,\n",
    "        include_operator_terms=True,\n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    Phi, names, info = builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=parsed_terms,\n",
    "        detected_operators=detected_operators,\n",
    "        pysr_r2=0.80\n",
    "    )\n",
    "    \n",
    "    # Print full summary\n",
    "    builder.print_library_summary()\n",
    "    \n",
    "    # Verification\n",
    "    print()\n",
    "    print('Verification:')\n",
    "    all_checks_pass = True\n",
    "    \n",
    "    if info['n_pysr_terms'] > 0:\n",
    "        print(f'  [PASS] Layer 1: {info[\"n_pysr_terms\"]} PySR terms')\n",
    "    else:\n",
    "        print('  [WARNING] Layer 1: No PySR terms')\n",
    "        all_checks_pass = False\n",
    "    \n",
    "    if info['n_variant_terms'] > 0:\n",
    "        print(f'  [PASS] Layer 2: {info[\"n_variant_terms\"]} variant terms')\n",
    "    else:\n",
    "        print('  [INFO] Layer 2: No variant terms (may be expected)')\n",
    "    \n",
    "    if info['n_poly_terms'] > 0:\n",
    "        print(f'  [PASS] Layer 3: {info[\"n_poly_terms\"]} polynomial terms')\n",
    "    else:\n",
    "        print('  [WARNING] Layer 3: No polynomial terms')\n",
    "        all_checks_pass = False\n",
    "    \n",
    "    if info['n_op_terms'] > 0:\n",
    "        print(f'  [PASS] Layer 4: {info[\"n_op_terms\"]} operator terms')\n",
    "    else:\n",
    "        print('  [INFO] Layer 4: No operator terms')\n",
    "    \n",
    "    # Check no duplicates\n",
    "    has_nan = np.any(np.isnan(Phi))\n",
    "    has_inf = np.any(np.isinf(Phi))\n",
    "    if not has_nan and not has_inf:\n",
    "        print('  [PASS] No NaN/Inf values')\n",
    "    else:\n",
    "        print('  [WARNING] Contains invalid values')\n",
    "        all_checks_pass = False\n",
    "    \n",
    "    print()\n",
    "    if all_checks_pass:\n",
    "        print('All critical checks passed!')\n",
    "    else:\n",
    "        print('Some checks failed - review output above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 6: Lazy Variant Generation (High PySR R2)\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header('Test 6: Lazy Variant Generation (High PySR R2)')\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.uniform(0.1, 2.0, (n_samples, 3))\n",
    "    feature_names = ['x', 'y', 'z']\n",
    "    \n",
    "    x_sym, y_sym, z_sym = Symbol('x'), Symbol('y'), Symbol('z')\n",
    "    term = sp.sin(x_sym**2)\n",
    "    parsed_terms = [(term, 'sin(x**2)', lambdify([x_sym, y_sym, z_sym], term, modules=['numpy']))]\n",
    "    \n",
    "    # High R2 should skip variants\n",
    "    builder = AugmentedLibraryBuilder(\n",
    "        max_poly_degree=1,\n",
    "        generate_variants=True,  # Enabled but should be skipped\n",
    "        lazy_variant_threshold=0.95,\n",
    "        include_operator_terms=False,\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    _, _, info = builder.build(\n",
    "        X, feature_names,\n",
    "        parsed_terms=parsed_terms,\n",
    "        pysr_r2=0.98  # High R2 triggers lazy mode\n",
    "    )\n",
    "    \n",
    "    print(f'PySR R2: 0.98')\n",
    "    print(f'Lazy mode: {info[\"lazy_mode\"]}')\n",
    "    print(f'Variant terms: {info[\"n_variant_terms\"]}')\n",
    "    print()\n",
    "    \n",
    "    if info['lazy_mode'] and info['n_variant_terms'] == 0:\n",
    "        print('[PASS] Lazy mode correctly skipped variant generation')\n",
    "    else:\n",
    "        print('[WARNING] Lazy mode did not work as expected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print('=' * 70)\n",
    "print(' 05_FeatureLibrary.ipynb v4.1 - Module Summary')\n",
    "print('=' * 70)\n",
    "print()\n",
    "print('CLASS: AugmentedLibraryBuilder')\n",
    "print('-' * 70)\n",
    "print()\n",
    "print('Purpose:')\n",
    "print('  Build 5-layer augmented feature library combining physics-guided terms,')\n",
    "print('  PySR discoveries, and baseline polynomial features for E-WSINDy.')\n",
    "print()\n",
    "print('5-Layer Architecture:')\n",
    "print('  Layer 0 [PowLaw]: Power-law guided terms from Stage 1 symmetry (HIGHEST)')\n",
    "print('  Layer 1 [PySR]:   Exact terms from PySR Pareto front')\n",
    "print('  Layer 2 [Var]:    Variant terms via variable substitution')\n",
    "print('  Layer 3 [Poly]:   Polynomial baseline (always included)')\n",
    "print('  Layer 4 [Op]:     Operator-guided simple terms')\n",
    "print()\n",
    "print('Main Methods:')\n",
    "print('  build(X, feature_names, parsed_terms, detected_operators, pysr_r2, estimated_exponents)')\n",
    "print('      Build complete augmented library')\n",
    "print('      Returns: (Phi_aug, library_names, library_info)')\n",
    "print()\n",
    "print('  build_from_pysr_results(X, feature_names, stage2_partial)')\n",
    "print('      Build from partial Stage2Results object')\n",
    "print()\n",
    "print('  transform(X_new)')\n",
    "print('      Transform new data using fitted library structure')\n",
    "print()\n",
    "print('  print_library_summary()')\n",
    "print('      Print detailed library composition report')\n",
    "print()\n",
    "print('Key Parameters:')\n",
    "print('  max_poly_degree: Maximum polynomial degree (default: 3)')\n",
    "print('  generate_variants: Enable Layer 2 variants (default: True)')\n",
    "print('  include_operator_terms: Enable Layer 4 (default: True)')\n",
    "print('  lazy_variant_threshold: Skip variants if R2 >= threshold (default: 0.95)')\n",
    "print()\n",
    "print('Output Dictionary (library_info):')\n",
    "print('  n_powerlaw_terms, n_pysr_terms, n_variant_terms, n_poly_terms, n_op_terms')\n",
    "print('  total_terms, pysr_r2, lazy_mode, detected_operators, estimated_exponents')\n",
    "print()\n",
    "print('Usage Example:')\n",
    "print('-' * 70)\n",
    "print(\"\"\"\n",
    "# Create builder\n",
    "builder = AugmentedLibraryBuilder(\n",
    "    max_poly_degree=3,\n",
    "    generate_variants=True\n",
    ")\n",
    "\n",
    "# Build library with power-law guidance from Stage 1\n",
    "Phi, names, info = builder.build(\n",
    "    X, feature_names,\n",
    "    parsed_terms=[(expr, 'sin(x**2)', func), ...],\n",
    "    detected_operators={'sin', 'exp'},\n",
    "    pysr_r2=0.85,\n",
    "    estimated_exponents={'q1': 1.0, 'r': -2.0}  # From Stage 1 symmetry\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "builder.print_library_summary()\n",
    "\"\"\")\n",
    "print()\n",
    "print('Backward Compatibility:')\n",
    "print('  FeatureLibraryBuilder = AugmentedLibraryBuilder (alias)')\n",
    "print()\n",
    "print('=' * 70)\n",
    "print('Module loaded successfully. Import via: %run 05_FeatureLibrary.ipynb')\n",
    "print('=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

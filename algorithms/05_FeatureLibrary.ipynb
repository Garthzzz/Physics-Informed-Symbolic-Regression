{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_FeatureLibrary - Physics-SR Framework v3.0\n",
    "\n",
    "## Stage 2.1: Feature Library Construction\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Build a comprehensive candidate feature library incorporating:\n",
    "- Polynomial features (up to specified degree)\n",
    "- Trigonometric features (optional)\n",
    "- Rational features (optional)\n",
    "- Interaction terms from Stage 1.4 (iRF discovery)\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "The feature library $\\Phi$ consists of:\n",
    "\n",
    "1. **Base features:** $\\Phi_{\\text{base}} = [1, x_1, x_2, \\ldots, x_p]$\n",
    "\n",
    "2. **Polynomial features:** For degree $d$:\n",
    "   $$\\Phi_{\\text{poly}} = \\{x_1^{i_1} x_2^{i_2} \\cdots x_p^{i_p} : \\sum_j i_j \\leq d\\}$$\n",
    "\n",
    "3. **Trigonometric features:** $\\Phi_{\\text{trig}} = \\{\\sin(x_j), \\cos(x_j)\\}$\n",
    "\n",
    "4. **Interaction features:** From iRF Stage 1.4\n",
    "\n",
    "### Algorithm Reference\n",
    "\n",
    "Framework Section 4.1: Feature Library Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "05_FeatureLibrary.ipynb - Feature Library Construction\n",
    "=======================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v3.0\n",
    "\n",
    "This module provides:\n",
    "- FeatureLibraryBuilder: Construct comprehensive feature libraries\n",
    "- Polynomial, trigonometric, rational, and interaction features\n",
    "- Feature normalization with denormalization support\n",
    "- Integration with iRF interaction terms from Stage 1.4\n",
    "\n",
    "Algorithm:\n",
    "    1. Generate polynomial features up to max_degree\n",
    "    2. Add trigonometric features (optional)\n",
    "    3. Add rational features (optional)\n",
    "    4. Add iRF-guided interaction features\n",
    "    5. Normalize features (optional)\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for Feature Library\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from itertools import combinations_with_replacement\n",
    "from typing import Dict, List, Tuple, Optional, Any, Set\n",
    "\n",
    "print(\"05_FeatureLibrary: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE LIBRARY BUILDER CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class FeatureLibraryBuilder:\n",
    "    \"\"\"\n",
    "    Feature Library Construction for Symbolic Regression.\n",
    "    \n",
    "    Builds a comprehensive candidate feature library that includes:\n",
    "    - Polynomial features: x^1, x^2, x1*x2, etc.\n",
    "    - Trigonometric features: sin(x), cos(x)\n",
    "    - Rational features: x1/x2, 1/x\n",
    "    - iRF-guided interactions from Stage 1.4\n",
    "    \n",
    "    The library is designed to be used with sparse regression methods\n",
    "    (STLSQ, Adaptive Lasso) in Stage 2.2.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    max_poly_degree : int\n",
    "        Maximum polynomial degree (default: 3)\n",
    "    include_trig : bool\n",
    "        Whether to include trigonometric features (default: False)\n",
    "    include_rational : bool\n",
    "        Whether to include rational features (default: False)\n",
    "    include_inverse : bool\n",
    "        Whether to include 1/x terms (default: True)\n",
    "    normalize : bool\n",
    "        Whether to standardize features (default: True)\n",
    "    interaction_only : bool\n",
    "        If True, only include interaction terms (no pure powers)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> builder = FeatureLibraryBuilder(max_poly_degree=2, include_trig=True)\n",
    "    >>> Phi, names = builder.build(X, feature_names)\n",
    "    >>> print(f\"Library size: {Phi.shape[1]} features\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        max_poly_degree: int = DEFAULT_MAX_POLY_DEGREE,\n",
    "        include_trig: bool = False,\n",
    "        include_rational: bool = False,\n",
    "        include_inverse: bool = True,\n",
    "        normalize: bool = True,\n",
    "        interaction_only: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize FeatureLibraryBuilder.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_poly_degree : int\n",
    "            Maximum polynomial degree. Features up to x^d are included.\n",
    "            Default: 3\n",
    "        include_trig : bool\n",
    "            Whether to add sin(x), cos(x) for each variable.\n",
    "            Default: False\n",
    "        include_rational : bool\n",
    "            Whether to add x_i/x_j rational features.\n",
    "            Default: False\n",
    "        include_inverse : bool\n",
    "            Whether to add 1/x terms.\n",
    "            Default: True\n",
    "        normalize : bool\n",
    "            Whether to standardize features to zero mean, unit variance.\n",
    "            Default: True\n",
    "        interaction_only : bool\n",
    "            If True, polynomial features only include interactions (x_i*x_j),\n",
    "            not pure powers (x_i^2).\n",
    "            Default: False\n",
    "        \"\"\"\n",
    "        self.max_poly_degree = max_poly_degree\n",
    "        self.include_trig = include_trig\n",
    "        self.include_rational = include_rational\n",
    "        self.include_inverse = include_inverse\n",
    "        self.normalize = normalize\n",
    "        self.interaction_only = interaction_only\n",
    "        \n",
    "        # Internal state\n",
    "        self._feature_names = None\n",
    "        self._library_names = None\n",
    "        self._n_input_features = None\n",
    "        self._n_library_features = None\n",
    "        self._scaler = None\n",
    "        self._feature_means = None\n",
    "        self._feature_stds = None\n",
    "        self._build_complete = False\n",
    "    \n",
    "    def build(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        feature_names: List[str],\n",
    "        interactions: List[Tuple[str, ...]] = None\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Build the feature library.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input feature matrix of shape (n_samples, n_features)\n",
    "        feature_names : List[str]\n",
    "            Names of input features\n",
    "        interactions : List[Tuple[str, ...]], optional\n",
    "            Specific interactions to include (from iRF Stage 1.4)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            - Phi: Feature library matrix of shape (n_samples, n_library)\n",
    "            - library_names: Names of library features\n",
    "        \"\"\"\n",
    "        self._feature_names = list(feature_names)\n",
    "        self._n_input_features = X.shape[1]\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        all_features = []\n",
    "        all_names = []\n",
    "        \n",
    "        # 1. Constant term\n",
    "        all_features.append(np.ones((n_samples, 1)))\n",
    "        all_names.append('1')\n",
    "        \n",
    "        # 2. Polynomial features\n",
    "        poly_features, poly_names = self._polynomial_features(X)\n",
    "        all_features.append(poly_features)\n",
    "        all_names.extend(poly_names)\n",
    "        \n",
    "        # 3. Trigonometric features (optional)\n",
    "        if self.include_trig:\n",
    "            trig_features, trig_names = self._trigonometric_features(X)\n",
    "            all_features.append(trig_features)\n",
    "            all_names.extend(trig_names)\n",
    "        \n",
    "        # 4. Rational features (optional)\n",
    "        if self.include_rational:\n",
    "            rational_features, rational_names = self._rational_features(X)\n",
    "            all_features.append(rational_features)\n",
    "            all_names.extend(rational_names)\n",
    "        \n",
    "        # 5. Inverse features (optional)\n",
    "        if self.include_inverse:\n",
    "            inverse_features, inverse_names = self._inverse_features(X)\n",
    "            all_features.append(inverse_features)\n",
    "            all_names.extend(inverse_names)\n",
    "        \n",
    "        # 6. iRF-guided interactions (if provided)\n",
    "        if interactions is not None and len(interactions) > 0:\n",
    "            interaction_features, interaction_names = self._interaction_features(\n",
    "                X, interactions\n",
    "            )\n",
    "            all_features.append(interaction_features)\n",
    "            all_names.extend(interaction_names)\n",
    "        \n",
    "        # Combine all features\n",
    "        Phi = np.hstack(all_features)\n",
    "        \n",
    "        # Remove duplicate columns\n",
    "        Phi, all_names = self._remove_duplicates(Phi, all_names)\n",
    "        \n",
    "        # Handle NaN/Inf\n",
    "        Phi = self._handle_invalid_values(Phi)\n",
    "        \n",
    "        # Normalize if requested\n",
    "        if self.normalize:\n",
    "            Phi = self._normalize_features(Phi)\n",
    "        \n",
    "        self._library_names = all_names\n",
    "        self._n_library_features = Phi.shape[1]\n",
    "        self._build_complete = True\n",
    "        \n",
    "        return Phi, all_names\n",
    "    \n",
    "    def _polynomial_features(\n",
    "        self,\n",
    "        X: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Generate polynomial features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            Polynomial features and their names\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        features = []\n",
    "        names = []\n",
    "        \n",
    "        # Linear terms\n",
    "        for i in range(n_features):\n",
    "            features.append(X[:, i])\n",
    "            names.append(self._feature_names[i])\n",
    "        \n",
    "        # Higher degree terms\n",
    "        for degree in range(2, self.max_poly_degree + 1):\n",
    "            for combo in combinations_with_replacement(range(n_features), degree):\n",
    "                # Skip pure powers if interaction_only\n",
    "                if self.interaction_only and len(set(combo)) == 1:\n",
    "                    continue\n",
    "                \n",
    "                # Compute product\n",
    "                product = np.ones(n_samples)\n",
    "                for idx in combo:\n",
    "                    product *= X[:, idx]\n",
    "                \n",
    "                features.append(product)\n",
    "                \n",
    "                # Build name\n",
    "                name = self._build_polynomial_name(combo)\n",
    "                names.append(name)\n",
    "        \n",
    "        return np.column_stack(features), names\n",
    "    \n",
    "    def _build_polynomial_name(\n",
    "        self,\n",
    "        indices: Tuple[int, ...]\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Build human-readable name for polynomial term.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        indices : Tuple[int, ...]\n",
    "            Tuple of feature indices (may have repeats)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Name like \"x1^2\" or \"x1*x2\"\n",
    "        \"\"\"\n",
    "        # Count occurrences of each index\n",
    "        from collections import Counter\n",
    "        counts = Counter(indices)\n",
    "        \n",
    "        parts = []\n",
    "        for idx in sorted(counts.keys()):\n",
    "            name = self._feature_names[idx]\n",
    "            power = counts[idx]\n",
    "            if power == 1:\n",
    "                parts.append(name)\n",
    "            else:\n",
    "                parts.append(f\"{name}^{power}\")\n",
    "        \n",
    "        return \"*\".join(parts)\n",
    "    \n",
    "    def _trigonometric_features(\n",
    "        self,\n",
    "        X: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Generate trigonometric features.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            Trigonometric features and their names\n",
    "        \"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        features = []\n",
    "        names = []\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            # sin(x)\n",
    "            features.append(np.sin(X[:, i]))\n",
    "            names.append(f\"sin({self._feature_names[i]})\")\n",
    "            \n",
    "            # cos(x)\n",
    "            features.append(np.cos(X[:, i]))\n",
    "            names.append(f\"cos({self._feature_names[i]})\")\n",
    "        \n",
    "        return np.column_stack(features), names\n",
    "    \n",
    "    def _rational_features(\n",
    "        self,\n",
    "        X: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Generate rational features (x_i / x_j).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            Rational features and their names\n",
    "        \"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        features = []\n",
    "        names = []\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                if i != j:\n",
    "                    # x_i / x_j with safe division\n",
    "                    ratio = safe_divide(X[:, i], X[:, j])\n",
    "                    features.append(ratio)\n",
    "                    names.append(f\"{self._feature_names[i]}/{self._feature_names[j]}\")\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            return np.empty((X.shape[0], 0)), []\n",
    "        \n",
    "        return np.column_stack(features), names\n",
    "    \n",
    "    def _inverse_features(\n",
    "        self,\n",
    "        X: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Generate inverse features (1/x, 1/x^2).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            Inverse features and their names\n",
    "        \"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        features = []\n",
    "        names = []\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            # 1/x\n",
    "            inv = safe_divide(1.0, X[:, i])\n",
    "            features.append(inv)\n",
    "            names.append(f\"1/{self._feature_names[i]}\")\n",
    "            \n",
    "            # 1/x^2\n",
    "            inv_sq = safe_divide(1.0, X[:, i]**2)\n",
    "            features.append(inv_sq)\n",
    "            names.append(f\"1/{self._feature_names[i]}^2\")\n",
    "        \n",
    "        return np.column_stack(features), names\n",
    "    \n",
    "    def _interaction_features(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        interactions: List[Tuple[str, ...]]\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Generate interaction features from iRF discovery.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input features\n",
    "        interactions : List[Tuple[str, ...]]\n",
    "            List of feature name tuples representing interactions\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            Interaction features and their names\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        features = []\n",
    "        names = []\n",
    "        \n",
    "        # Create mapping from name to index\n",
    "        name_to_idx = {name: i for i, name in enumerate(self._feature_names)}\n",
    "        \n",
    "        for interaction in interactions:\n",
    "            # Compute product of features in interaction\n",
    "            product = np.ones(n_samples)\n",
    "            valid = True\n",
    "            \n",
    "            for feat_name in interaction:\n",
    "                if feat_name in name_to_idx:\n",
    "                    idx = name_to_idx[feat_name]\n",
    "                    product *= X[:, idx]\n",
    "                else:\n",
    "                    valid = False\n",
    "                    break\n",
    "            \n",
    "            if valid:\n",
    "                features.append(product)\n",
    "                name = \"*\".join(sorted(interaction))\n",
    "                names.append(f\"iRF:{name}\")\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            return np.empty((n_samples, 0)), []\n",
    "        \n",
    "        return np.column_stack(features), names\n",
    "    \n",
    "    def _remove_duplicates(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        names: List[str]\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Remove duplicate columns from feature matrix.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        names : List[str]\n",
    "            Feature names\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            Deduplicated features and names\n",
    "        \"\"\"\n",
    "        n_features = Phi.shape[1]\n",
    "        keep_indices = []\n",
    "        seen_hashes = set()\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            col = Phi[:, i]\n",
    "            # Use rounded values for hash to handle floating point\n",
    "            col_hash = hash(tuple(np.round(col, 8)))\n",
    "            \n",
    "            if col_hash not in seen_hashes:\n",
    "                seen_hashes.add(col_hash)\n",
    "                keep_indices.append(i)\n",
    "        \n",
    "        return Phi[:, keep_indices], [names[i] for i in keep_indices]\n",
    "    \n",
    "    def _handle_invalid_values(\n",
    "        self,\n",
    "        Phi: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Handle NaN and Inf values in feature matrix.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Feature matrix with invalid values replaced\n",
    "        \"\"\"\n",
    "        # Replace Inf with large finite values\n",
    "        Phi = np.clip(Phi, -1e10, 1e10)\n",
    "        \n",
    "        # Replace NaN with column mean\n",
    "        for j in range(Phi.shape[1]):\n",
    "            col = Phi[:, j]\n",
    "            nan_mask = np.isnan(col)\n",
    "            if np.any(nan_mask):\n",
    "                col_mean = np.nanmean(col)\n",
    "                if np.isnan(col_mean):\n",
    "                    col_mean = 0.0\n",
    "                Phi[nan_mask, j] = col_mean\n",
    "        \n",
    "        return Phi\n",
    "    \n",
    "    def _normalize_features(\n",
    "        self,\n",
    "        Phi: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Standardize features to zero mean, unit variance.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Phi : np.ndarray\n",
    "            Feature matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Normalized feature matrix\n",
    "        \"\"\"\n",
    "        self._feature_means = np.mean(Phi, axis=0)\n",
    "        self._feature_stds = np.std(Phi, axis=0)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        self._feature_stds[self._feature_stds < EPS_DIV] = 1.0\n",
    "        \n",
    "        # Don't normalize the constant term (first column)\n",
    "        Phi_normalized = Phi.copy()\n",
    "        Phi_normalized[:, 1:] = (\n",
    "            Phi[:, 1:] - self._feature_means[1:]\n",
    "        ) / self._feature_stds[1:]\n",
    "        \n",
    "        return Phi_normalized\n",
    "    \n",
    "    def transform(\n",
    "        self,\n",
    "        X_new: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transform new data using the same library construction.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_new : np.ndarray\n",
    "            New feature matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Transformed feature library\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If build() has not been called\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            raise ValueError(\"Must call build() before transform()\")\n",
    "        \n",
    "        # Rebuild library with new data (without re-fitting scaler)\n",
    "        Phi_new, _ = self.build(\n",
    "            X_new, \n",
    "            self._feature_names,\n",
    "            interactions=None  # Use same structure\n",
    "        )\n",
    "        \n",
    "        return Phi_new\n",
    "    \n",
    "    def get_feature_count(self) -> int:\n",
    "        \"\"\"\n",
    "        Get total number of features in library.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Number of library features\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            raise ValueError(\"Must call build() before getting feature count\")\n",
    "        return self._n_library_features\n",
    "    \n",
    "    def get_library_names(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get list of library feature names.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "            Names of library features\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            raise ValueError(\"Must call build() before getting names\")\n",
    "        return self._library_names.copy()\n",
    "    \n",
    "    def print_library_summary(self) -> None:\n",
    "        \"\"\"\n",
    "        Print a summary of the feature library.\n",
    "        \"\"\"\n",
    "        if not self._build_complete:\n",
    "            print(\"Library not yet built. Call build() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" Feature Library Summary\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Max polynomial degree: {self.max_poly_degree}\")\n",
    "        print(f\"  Include trigonometric: {self.include_trig}\")\n",
    "        print(f\"  Include rational: {self.include_rational}\")\n",
    "        print(f\"  Include inverse: {self.include_inverse}\")\n",
    "        print(f\"  Normalize: {self.normalize}\")\n",
    "        print()\n",
    "        print(f\"Library Statistics:\")\n",
    "        print(f\"  Input features: {self._n_input_features}\")\n",
    "        print(f\"  Library features: {self._n_library_features}\")\n",
    "        print(f\"  Expansion factor: {self._n_library_features / self._n_input_features:.1f}x\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Library Features:\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Group by type\n",
    "        poly_features = [n for n in self._library_names \n",
    "                        if not n.startswith('sin') and not n.startswith('cos') \n",
    "                        and not n.startswith('1/') and not '/' in n\n",
    "                        and not n.startswith('iRF:')]\n",
    "        trig_features = [n for n in self._library_names \n",
    "                        if n.startswith('sin') or n.startswith('cos')]\n",
    "        inverse_features = [n for n in self._library_names \n",
    "                           if n.startswith('1/')]\n",
    "        rational_features = [n for n in self._library_names \n",
    "                            if '/' in n and not n.startswith('1/')]\n",
    "        irf_features = [n for n in self._library_names \n",
    "                       if n.startswith('iRF:')]\n",
    "        \n",
    "        print(f\"  Polynomial ({len(poly_features)}): {poly_features[:5]}...\" \n",
    "              if len(poly_features) > 5 else f\"  Polynomial ({len(poly_features)}): {poly_features}\")\n",
    "        \n",
    "        if trig_features:\n",
    "            print(f\"  Trigonometric ({len(trig_features)}): {trig_features[:4]}...\" \n",
    "                  if len(trig_features) > 4 else f\"  Trigonometric ({len(trig_features)}): {trig_features}\")\n",
    "        \n",
    "        if inverse_features:\n",
    "            print(f\"  Inverse ({len(inverse_features)}): {inverse_features[:4]}...\" \n",
    "                  if len(inverse_features) > 4 else f\"  Inverse ({len(inverse_features)}): {inverse_features}\")\n",
    "        \n",
    "        if rational_features:\n",
    "            print(f\"  Rational ({len(rational_features)}): {rational_features[:4]}...\" \n",
    "                  if len(rational_features) > 4 else f\"  Rational ({len(rational_features)}): {rational_features}\")\n",
    "        \n",
    "        if irf_features:\n",
    "            print(f\"  iRF Interactions ({len(irf_features)}): {irf_features}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 05_FeatureLibrary\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Polynomial Feature Generation\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Polynomial Feature Generation\")\n",
    "    \n",
    "    # Generate simple test data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    X = np.random.randn(n_samples, 3)\n",
    "    feature_names = ['x0', 'x1', 'x2']\n",
    "    \n",
    "    print(f\"Input: {len(feature_names)} features\")\n",
    "    print(f\"Max polynomial degree: 3\")\n",
    "    print()\n",
    "    \n",
    "    # Build library\n",
    "    builder = FeatureLibraryBuilder(\n",
    "        max_poly_degree=3,\n",
    "        include_trig=False,\n",
    "        include_rational=False,\n",
    "        include_inverse=False,\n",
    "        normalize=False\n",
    "    )\n",
    "    Phi, names = builder.build(X, feature_names)\n",
    "    \n",
    "    print(f\"Library size: {Phi.shape[1]} features\")\n",
    "    print(f\"Feature names: {names}\")\n",
    "    print()\n",
    "    \n",
    "    # Expected: 1 + 3 + 6 + 10 = 20 features for degree 3 with 3 variables\n",
    "    # (constant + linear + degree2 + degree3)\n",
    "    expected_count = 1 + 3 + 6 + 10  # C(3+d-1, d) for each degree\n",
    "    print(f\"Expected count: ~{expected_count} (may vary with deduplication)\")\n",
    "    \n",
    "    # Verify constant term\n",
    "    if np.allclose(Phi[:, 0], 1.0):\n",
    "        print(\"[PASS] Constant term is all 1s\")\n",
    "    else:\n",
    "        print(\"[FAIL] Constant term incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Integration with iRF Interactions\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: Integration with iRF Interactions\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    X = np.random.uniform(0.1, 1, (n_samples, 4))\n",
    "    feature_names = ['a', 'b', 'c', 'd']\n",
    "    \n",
    "    # Simulated iRF interactions\n",
    "    interactions = [\n",
    "        ('a', 'b'),      # Pairwise\n",
    "        ('b', 'c', 'd')  # 3-way\n",
    "    ]\n",
    "    \n",
    "    print(f\"Input features: {feature_names}\")\n",
    "    print(f\"iRF interactions: {interactions}\")\n",
    "    print()\n",
    "    \n",
    "    builder = FeatureLibraryBuilder(\n",
    "        max_poly_degree=2,\n",
    "        include_trig=False,\n",
    "        include_inverse=False,\n",
    "        normalize=False\n",
    "    )\n",
    "    Phi, names = builder.build(X, feature_names, interactions=interactions)\n",
    "    \n",
    "    print(f\"Library size: {Phi.shape[1]}\")\n",
    "    print(f\"Feature names:\")\n",
    "    for i, name in enumerate(names):\n",
    "        print(f\"  {i}: {name}\")\n",
    "    \n",
    "    # Check that iRF features are included\n",
    "    irf_features = [n for n in names if n.startswith('iRF:')]\n",
    "    print(f\"\\niRF features: {irf_features}\")\n",
    "    \n",
    "    if len(irf_features) == 2:\n",
    "        print(\"[PASS] Both iRF interactions included\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Expected 2 iRF features, got {len(irf_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: No NaN/Inf Verification\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: No NaN/Inf Verification\")\n",
    "    \n",
    "    # Generate data with potential issues (near-zero values)\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    \n",
    "    X = np.random.uniform(0.01, 1, (n_samples, 2))\n",
    "    # Add some near-zero values\n",
    "    X[0, 0] = 0.0001\n",
    "    X[1, 1] = 0.0001\n",
    "    \n",
    "    feature_names = ['x', 'y']\n",
    "    \n",
    "    print(f\"Testing with near-zero values in data\")\n",
    "    print(f\"Min value in X: {X.min()}\")\n",
    "    print()\n",
    "    \n",
    "    builder = FeatureLibraryBuilder(\n",
    "        max_poly_degree=2,\n",
    "        include_trig=True,\n",
    "        include_rational=True,\n",
    "        include_inverse=True,\n",
    "        normalize=True\n",
    "    )\n",
    "    Phi, names = builder.build(X, feature_names)\n",
    "    \n",
    "    # Check for NaN/Inf\n",
    "    has_nan = np.any(np.isnan(Phi))\n",
    "    has_inf = np.any(np.isinf(Phi))\n",
    "    \n",
    "    print(f\"Library size: {Phi.shape[1]}\")\n",
    "    print(f\"Has NaN: {has_nan}\")\n",
    "    print(f\"Has Inf: {has_inf}\")\n",
    "    \n",
    "    if not has_nan and not has_inf:\n",
    "        print(\"[PASS] No NaN or Inf values in library\")\n",
    "    else:\n",
    "        print(\"[FAIL] Invalid values present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: Normalization Verification\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: Normalization Verification\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    X = np.random.randn(n_samples, 2) * 10 + 5  # Non-zero mean, non-unit std\n",
    "    feature_names = ['x', 'y']\n",
    "    \n",
    "    print(f\"Original data:\")\n",
    "    print(f\"  X mean: {X.mean(axis=0)}\")\n",
    "    print(f\"  X std: {X.std(axis=0)}\")\n",
    "    print()\n",
    "    \n",
    "    builder = FeatureLibraryBuilder(\n",
    "        max_poly_degree=2,\n",
    "        normalize=True\n",
    "    )\n",
    "    Phi, names = builder.build(X, feature_names)\n",
    "    \n",
    "    print(f\"Normalized library (excluding constant term):\")\n",
    "    print(f\"  Mean (should be ~0): {Phi[:, 1:].mean(axis=0)[:3]}...\")\n",
    "    print(f\"  Std (should be ~1): {Phi[:, 1:].std(axis=0)[:3]}...\")\n",
    "    \n",
    "    # Check mean and std\n",
    "    mean_close_to_zero = np.allclose(Phi[:, 1:].mean(axis=0), 0, atol=0.1)\n",
    "    std_close_to_one = np.allclose(Phi[:, 1:].std(axis=0), 1, atol=0.2)\n",
    "    \n",
    "    if mean_close_to_zero and std_close_to_one:\n",
    "        print(\"[PASS] Features properly normalized\")\n",
    "    else:\n",
    "        print(\"[WARNING] Normalization may not be exact for all features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Full Library Summary\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 5: Full Library Summary\")\n",
    "    \n",
    "    # Use warm rain data\n",
    "    X, y, feature_names, _ = generate_warm_rain_data(\n",
    "        n_samples=200, noise_level=0.01\n",
    "    )\n",
    "    \n",
    "    # Build comprehensive library\n",
    "    builder = FeatureLibraryBuilder(\n",
    "        max_poly_degree=3,\n",
    "        include_trig=True,\n",
    "        include_rational=False,  # Skip rational to keep size manageable\n",
    "        include_inverse=True,\n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    # Simulated interactions from iRF\n",
    "    interactions = [('q_c', 'N_d')]\n",
    "    \n",
    "    Phi, names = builder.build(X, feature_names, interactions=interactions)\n",
    "    \n",
    "    builder.print_library_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 05_FeatureLibrary.ipynb - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: FeatureLibraryBuilder\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Build comprehensive candidate feature library for sparse regression.\")\n",
    "print(\"  Includes polynomial, trigonometric, rational, and interaction features.\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  build(X, feature_names, interactions=None)\")\n",
    "print(\"      Build the feature library\")\n",
    "print(\"      Returns: (Phi, names) - feature matrix and names\")\n",
    "print()\n",
    "print(\"  transform(X_new)\")\n",
    "print(\"      Transform new data using same library structure\")\n",
    "print()\n",
    "print(\"  get_feature_count()\")\n",
    "print(\"      Get total number of library features\")\n",
    "print()\n",
    "print(\"  get_library_names()\")\n",
    "print(\"      Get list of feature names\")\n",
    "print()\n",
    "print(\"  print_library_summary()\")\n",
    "print(\"      Print detailed library summary\")\n",
    "print()\n",
    "print(\"Key Parameters:\")\n",
    "print(\"  max_poly_degree: Maximum polynomial degree (default: 3)\")\n",
    "print(\"  include_trig: Include sin(x), cos(x) (default: False)\")\n",
    "print(\"  include_rational: Include x_i/x_j (default: False)\")\n",
    "print(\"  include_inverse: Include 1/x terms (default: True)\")\n",
    "print(\"  normalize: Standardize features (default: True)\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Create builder\n",
    "builder = FeatureLibraryBuilder(\n",
    "    max_poly_degree=3,\n",
    "    include_trig=True,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Build library (with optional iRF interactions)\n",
    "interactions = [('x0', 'x1'), ('x1', 'x2')]  # From Stage 1.4\n",
    "Phi, names = builder.build(X, feature_names, interactions=interactions)\n",
    "\n",
    "print(f\"Library shape: {Phi.shape}\")\n",
    "print(f\"Features: {names[:5]}...\")\n",
    "\n",
    "# Use Phi for sparse regression in Stage 2.2\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 05_FeatureLibrary.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

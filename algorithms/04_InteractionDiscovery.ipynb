{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_InteractionDiscovery - Physics-SR Framework v3.0\n",
    "\n",
    "## Stage 1.4: iRF-Guided Interaction Discovery with Soft Reweighting\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Discover high-order feature interactions using Random Forest with soft reweighting. This addresses the \"0.101 vs 0.099\" arbitrary cutoff problem by using importance as sampling probability rather than binary selection.\n",
    "\n",
    "### Key Innovation\n",
    "\n",
    "**Hard Thresholding Problem:**\n",
    "- Feature with importance 0.101 is selected\n",
    "- Feature with importance 0.099 is completely removed\n",
    "\n",
    "**Soft Reweighting Solution:**\n",
    "- Apply softmax transformation to importance scores\n",
    "- All features remain in the pool with probability proportional to importance\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "Softmax transformation with temperature $\\tau$:\n",
    "$$w_j = \\frac{\\exp(I_j / \\tau)}{\\sum_{k=1}^{p} \\exp(I_k / \\tau)}$$\n",
    "\n",
    "where $I_j$ is the Gini importance of feature $j$.\n",
    "\n",
    "### Implementation Note\n",
    "\n",
    "Following Framework Section 8.3, we use the **Softmax Soft Threshold** approach (simpler than full iterative iRF, recommended for p < 50 features).\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Basu, S., et al. (2018). Iterative random forests to discover predictive and stable high-order interactions. *PNAS*, 115(8), 1943-1948."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "04_InteractionDiscovery.ipynb - iRF-Guided Interaction Discovery\n",
    "=================================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v3.0\n",
    "\n",
    "This module provides:\n",
    "- IRFInteractionDiscoverer: Discover feature interactions using Random Forest\n",
    "- Softmax soft threshold for importance-weighted feature selection\n",
    "- Bootstrap stability assessment for robust interaction identification\n",
    "- Decision path extraction to find co-occurring features in trees\n",
    "\n",
    "Algorithm (Softmax Soft Threshold):\n",
    "    1. Train Random Forest on data\n",
    "    2. Extract Gini importance\n",
    "    3. Apply softmax transformation with temperature parameter\n",
    "    4. Extract interactions from decision paths (co-occurring features)\n",
    "    5. Bootstrap stability assessment to filter genuine interactions\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for Interaction Discovery\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from typing import Dict, List, Tuple, Optional, Any, Set, FrozenSet\n",
    "\n",
    "print(\"04_InteractionDiscovery: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IRF INTERACTION DISCOVERER CLASS\n",
    "# ==============================================================================\n",
    "\n",
    "class IRFInteractionDiscoverer:\n",
    "    \"\"\"\n",
    "    iRF-Guided Interaction Discovery with Softmax Soft Threshold.\n",
    "    \n",
    "    This discoverer identifies high-order feature interactions by:\n",
    "    1. Training Random Forest to capture nonlinear relationships\n",
    "    2. Applying softmax to importance scores (soft threshold)\n",
    "    3. Extracting feature co-occurrences from decision paths\n",
    "    4. Using bootstrap stability to filter genuine interactions\n",
    "    \n",
    "    The softmax approach addresses the arbitrary cutoff problem of hard\n",
    "    thresholding: features with importance 0.101 and 0.099 are treated\n",
    "    similarly rather than one being selected and one being removed.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    temperature : float\n",
    "        Softmax temperature parameter (default: 0.5)\n",
    "        - Lower = more selective (approaches hard threshold)\n",
    "        - Higher = more uniform (includes more features)\n",
    "    selection_threshold : float\n",
    "        Minimum softmax weight for feature selection (default: 0.1)\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples for stability assessment (default: 50)\n",
    "    stability_threshold : float\n",
    "        Minimum bootstrap frequency for stable interaction (default: 0.5)\n",
    "    max_interaction_order : int\n",
    "        Maximum order of interactions to consider (default: 3)\n",
    "    n_estimators : int\n",
    "        Number of trees in Random Forest (default: 200)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> discoverer = IRFInteractionDiscoverer(temperature=0.5)\n",
    "    >>> result = discoverer.discover(X, y, feature_names)\n",
    "    >>> print(result['stable_interactions'])\n",
    "    [('x0', 'x1'), ('x1', 'x2')]  # Discovered interactions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        temperature: float = DEFAULT_SOFTMAX_TEMPERATURE,\n",
    "        selection_threshold: float = 0.1,\n",
    "        n_bootstrap: int = 50,\n",
    "        stability_threshold: float = DEFAULT_STABILITY_THRESHOLD,\n",
    "        max_interaction_order: int = 3,\n",
    "        n_estimators: int = 200,\n",
    "        random_state: int = RANDOM_SEED\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize IRFInteractionDiscoverer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        temperature : float\n",
    "            Softmax temperature. Lower values make selection more selective.\n",
    "            Default: 0.5 (recommended balanced value)\n",
    "        selection_threshold : float\n",
    "            Minimum softmax weight for a feature to be considered.\n",
    "            Default: 0.1\n",
    "        n_bootstrap : int\n",
    "            Number of bootstrap samples for stability assessment.\n",
    "            Default: 50\n",
    "        stability_threshold : float\n",
    "            Minimum bootstrap frequency for an interaction to be stable.\n",
    "            Default: 0.5\n",
    "        max_interaction_order : int\n",
    "            Maximum number of features in an interaction.\n",
    "            Default: 3 (pairwise and 3-way interactions)\n",
    "        n_estimators : int\n",
    "            Number of trees in Random Forest.\n",
    "            Default: 200\n",
    "        random_state : int\n",
    "            Random seed for reproducibility.\n",
    "            Default: 42\n",
    "        \"\"\"\n",
    "        self.temperature = temperature\n",
    "        self.selection_threshold = selection_threshold\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "        self.stability_threshold = stability_threshold\n",
    "        self.max_interaction_order = max_interaction_order\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Internal state\n",
    "        self._feature_names = None\n",
    "        self._rf_model = None\n",
    "        self._raw_importance = None\n",
    "        self._softmax_weights = None\n",
    "        self._selected_features = None\n",
    "        self._all_interactions = None\n",
    "        self._interaction_stability = None\n",
    "        self._stable_interactions = None\n",
    "        self._discovery_complete = False\n",
    "    \n",
    "    def discover(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        feature_names: List[str]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Discover feature interactions using iRF approach.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix of shape (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target vector of shape (n_samples,)\n",
    "        feature_names : List[str]\n",
    "            Names of features corresponding to columns of X\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, Any]\n",
    "            Dictionary containing:\n",
    "            - raw_importance: Dict of feature names to Gini importance\n",
    "            - softmax_weights: Dict of feature names to softmax weights\n",
    "            - selected_features: List of features above selection threshold\n",
    "            - all_interactions: List of all discovered interactions\n",
    "            - interaction_stability: Dict of interactions to stability scores\n",
    "            - stable_interactions: List of interactions above stability threshold\n",
    "            - suggested_terms: List of feature product strings for library\n",
    "        \"\"\"\n",
    "        self._feature_names = list(feature_names)\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Step 1: Train Random Forest\n",
    "        self._rf_model = self._fit_random_forest(X, y)\n",
    "        \n",
    "        # Step 2: Extract and transform importance\n",
    "        self._raw_importance = self._rf_model.feature_importances_\n",
    "        self._softmax_weights = self._softmax_transform(self._raw_importance)\n",
    "        \n",
    "        # Step 3: Select features above threshold\n",
    "        self._selected_features = [\n",
    "            self._feature_names[i] for i in range(n_features)\n",
    "            if self._softmax_weights[i] > self.selection_threshold\n",
    "        ]\n",
    "        \n",
    "        # Step 4: Extract interactions from decision paths\n",
    "        self._all_interactions = self._extract_interactions_from_trees(\n",
    "            self._rf_model\n",
    "        )\n",
    "        \n",
    "        # Step 5: Bootstrap stability assessment\n",
    "        self._interaction_stability = self._bootstrap_stability(X, y)\n",
    "        \n",
    "        # Step 6: Filter stable interactions\n",
    "        self._stable_interactions = [\n",
    "            interaction for interaction, stability \n",
    "            in self._interaction_stability.items()\n",
    "            if stability >= self.stability_threshold\n",
    "        ]\n",
    "        \n",
    "        self._discovery_complete = True\n",
    "        \n",
    "        # Build result dictionary\n",
    "        raw_importance_dict = {\n",
    "            name: float(self._raw_importance[i])\n",
    "            for i, name in enumerate(self._feature_names)\n",
    "        }\n",
    "        \n",
    "        softmax_weights_dict = {\n",
    "            name: float(self._softmax_weights[i])\n",
    "            for i, name in enumerate(self._feature_names)\n",
    "        }\n",
    "        \n",
    "        # Build suggested terms for feature library\n",
    "        suggested_terms = self._build_suggested_terms()\n",
    "        \n",
    "        return {\n",
    "            'raw_importance': raw_importance_dict,\n",
    "            'softmax_weights': softmax_weights_dict,\n",
    "            'selected_features': self._selected_features,\n",
    "            'all_interactions': list(self._all_interactions),\n",
    "            'interaction_stability': dict(self._interaction_stability),\n",
    "            'stable_interactions': self._stable_interactions,\n",
    "            'suggested_terms': suggested_terms,\n",
    "            'n_stable_interactions': len(self._stable_interactions),\n",
    "            'temperature': self.temperature,\n",
    "            'stability_threshold': self.stability_threshold\n",
    "        }\n",
    "    \n",
    "    def _fit_random_forest(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> RandomForestRegressor:\n",
    "        \"\"\"\n",
    "        Fit Random Forest regressor.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        RandomForestRegressor\n",
    "            Fitted Random Forest model\n",
    "        \"\"\"\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_features='sqrt',\n",
    "            max_depth=10,  # Limit depth to avoid overfitting and speed up\n",
    "            min_samples_leaf=5,\n",
    "            n_jobs=-1,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        rf.fit(X, y)\n",
    "        return rf\n",
    "    \n",
    "    def _softmax_transform(\n",
    "        self,\n",
    "        importance: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply softmax transformation to importance scores.\n",
    "        \n",
    "        Softmax with temperature tau:\n",
    "        w_j = exp(I_j / tau) / sum(exp(I_k / tau))\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        importance : np.ndarray\n",
    "            Raw Gini importance scores\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Softmax-transformed weights (sum to 1)\n",
    "        \"\"\"\n",
    "        # Scale by temperature\n",
    "        scaled = importance / self.temperature\n",
    "        \n",
    "        # Numerical stability: subtract max before exp\n",
    "        scaled = scaled - np.max(scaled)\n",
    "        \n",
    "        # Compute softmax\n",
    "        exp_scaled = np.exp(scaled)\n",
    "        weights = exp_scaled / np.sum(exp_scaled)\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def _extract_interactions_from_trees(\n",
    "        self,\n",
    "        rf_model: RandomForestRegressor\n",
    "    ) -> Set[FrozenSet[str]]:\n",
    "        \"\"\"\n",
    "        Extract feature interactions from Random Forest decision paths.\n",
    "        \n",
    "        An interaction is defined as a set of features that co-occur on\n",
    "        the same root-to-leaf path in a decision tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        rf_model : RandomForestRegressor\n",
    "            Fitted Random Forest model\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Set[FrozenSet[str]]\n",
    "            Set of unique feature interactions\n",
    "        \"\"\"\n",
    "        all_interactions = set()\n",
    "        \n",
    "        for tree in rf_model.estimators_:\n",
    "            # Get decision paths for this tree\n",
    "            paths = self._get_decision_paths(tree)\n",
    "            \n",
    "            for path in paths:\n",
    "                # Get unique features in this path\n",
    "                path_features = set(path)\n",
    "                \n",
    "                # Generate all subsets of size 2 to max_order\n",
    "                for order in range(2, min(len(path_features) + 1, \n",
    "                                          self.max_interaction_order + 1)):\n",
    "                    for combo in combinations(sorted(path_features), order):\n",
    "                        # Convert feature indices to names\n",
    "                        interaction = frozenset(\n",
    "                            self._feature_names[i] for i in combo\n",
    "                        )\n",
    "                        all_interactions.add(interaction)\n",
    "        \n",
    "        return all_interactions\n",
    "    \n",
    "    def _get_decision_paths(\n",
    "        self,\n",
    "        tree\n",
    "    ) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Extract all root-to-leaf paths from a decision tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        tree : DecisionTreeRegressor\n",
    "            A single decision tree from the forest\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[List[int]]\n",
    "            List of paths, each path is a list of feature indices\n",
    "        \"\"\"\n",
    "        tree_struct = tree.tree_\n",
    "        n_nodes = tree_struct.node_count\n",
    "        children_left = tree_struct.children_left\n",
    "        children_right = tree_struct.children_right\n",
    "        feature = tree_struct.feature\n",
    "        \n",
    "        paths = []\n",
    "        \n",
    "        def traverse(node_id, current_path):\n",
    "            # Check if leaf node\n",
    "            if children_left[node_id] == children_right[node_id]:\n",
    "                # Leaf node - save path\n",
    "                if len(current_path) > 0:\n",
    "                    paths.append(current_path.copy())\n",
    "                return\n",
    "            \n",
    "            # Internal node - add feature to path\n",
    "            if feature[node_id] >= 0:  # Valid feature index\n",
    "                current_path.append(feature[node_id])\n",
    "            \n",
    "            # Recurse on children\n",
    "            traverse(children_left[node_id], current_path)\n",
    "            traverse(children_right[node_id], current_path)\n",
    "            \n",
    "            # Backtrack\n",
    "            if feature[node_id] >= 0:\n",
    "                current_path.pop()\n",
    "        \n",
    "        traverse(0, [])\n",
    "        return paths\n",
    "    \n",
    "    def _bootstrap_stability(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> Dict[FrozenSet[str], float]:\n",
    "        \"\"\"\n",
    "        Assess interaction stability via bootstrap resampling.\n",
    "        \n",
    "        For each bootstrap sample, train RF and extract interactions.\n",
    "        Stability = frequency of interaction across bootstrap samples.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[FrozenSet[str], float]\n",
    "            Dictionary mapping interactions to stability scores\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        interaction_counts = Counter()\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        \n",
    "        for b in range(self.n_bootstrap):\n",
    "            # Bootstrap resample\n",
    "            indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "            X_boot = X[indices]\n",
    "            y_boot = y[indices]\n",
    "            \n",
    "            # Fit RF on bootstrap sample\n",
    "            rf_boot = RandomForestRegressor(\n",
    "                n_estimators=max(50, self.n_estimators // 4),  # Fewer trees for speed\n",
    "                max_features='sqrt',\n",
    "                max_depth=10,\n",
    "                min_samples_leaf=5,\n",
    "                n_jobs=-1,\n",
    "                random_state=self.random_state + b\n",
    "            )\n",
    "            rf_boot.fit(X_boot, y_boot)\n",
    "            \n",
    "            # Extract interactions\n",
    "            boot_interactions = self._extract_interactions_from_trees(rf_boot)\n",
    "            \n",
    "            # Count occurrences\n",
    "            for interaction in boot_interactions:\n",
    "                interaction_counts[interaction] += 1\n",
    "        \n",
    "        # Compute stability scores\n",
    "        stability_scores = {\n",
    "            interaction: count / self.n_bootstrap\n",
    "            for interaction, count in interaction_counts.items()\n",
    "        }\n",
    "        \n",
    "        return stability_scores\n",
    "    \n",
    "    def _build_suggested_terms(\n",
    "        self\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Build suggested interaction terms for feature library.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "            List of feature product strings (e.g., \"x0*x1\")\n",
    "        \"\"\"\n",
    "        terms = []\n",
    "        for interaction in self._stable_interactions:\n",
    "            # Sort for consistent ordering\n",
    "            sorted_features = sorted(interaction)\n",
    "            term = \" * \".join(sorted_features)\n",
    "            terms.append(term)\n",
    "        return terms\n",
    "    \n",
    "    def get_stable_interactions(\n",
    "        self\n",
    "    ) -> List[Tuple[str, ...]]:\n",
    "        \"\"\"\n",
    "        Get list of stable interactions as tuples.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[str, ...]]\n",
    "            List of stable interactions\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If discovery has not been performed\n",
    "        \"\"\"\n",
    "        if not self._discovery_complete:\n",
    "            raise ValueError(\"Must run discover() before getting interactions\")\n",
    "        \n",
    "        return [tuple(sorted(interaction)) \n",
    "                for interaction in self._stable_interactions]\n",
    "    \n",
    "    def get_interaction_matrix(\n",
    "        self,\n",
    "        X: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"\n",
    "        Compute interaction features from stable interactions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Original feature matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[np.ndarray, List[str]]\n",
    "            - Interaction feature matrix\n",
    "            - Names of interaction features\n",
    "        \"\"\"\n",
    "        if not self._discovery_complete:\n",
    "            raise ValueError(\"Must run discover() before computing interaction matrix\")\n",
    "        \n",
    "        if len(self._stable_interactions) == 0:\n",
    "            return np.empty((X.shape[0], 0)), []\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        interaction_features = []\n",
    "        interaction_names = []\n",
    "        \n",
    "        # Create mapping from feature name to column index\n",
    "        name_to_idx = {name: i for i, name in enumerate(self._feature_names)}\n",
    "        \n",
    "        for interaction in self._stable_interactions:\n",
    "            # Compute product of features in interaction\n",
    "            product = np.ones(n_samples)\n",
    "            sorted_features = sorted(interaction)\n",
    "            \n",
    "            for feat_name in sorted_features:\n",
    "                idx = name_to_idx[feat_name]\n",
    "                product *= X[:, idx]\n",
    "            \n",
    "            interaction_features.append(product)\n",
    "            interaction_names.append(\"*\".join(sorted_features))\n",
    "        \n",
    "        return np.column_stack(interaction_features), interaction_names\n",
    "    \n",
    "    def print_interaction_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print a detailed interaction discovery report.\n",
    "        \"\"\"\n",
    "        if not self._discovery_complete:\n",
    "            print(\"Discovery not yet performed. Run discover() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\" Interaction Discovery Results (iRF with Softmax)\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Temperature: {self.temperature}\")\n",
    "        print(f\"  Selection threshold: {self.selection_threshold}\")\n",
    "        print(f\"  Stability threshold: {self.stability_threshold}\")\n",
    "        print(f\"  Bootstrap samples: {self.n_bootstrap}\")\n",
    "        print(f\"  Max interaction order: {self.max_interaction_order}\")\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Feature Importance (Softmax Weights):\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"{'Feature':<20} {'Raw Importance':<15} {'Softmax Weight':<15} {'Selected'}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Sort by softmax weight\n",
    "        sorted_indices = np.argsort(self._softmax_weights)[::-1]\n",
    "        for idx in sorted_indices:\n",
    "            name = self._feature_names[idx]\n",
    "            raw = self._raw_importance[idx]\n",
    "            softmax = self._softmax_weights[idx]\n",
    "            selected = \"YES\" if name in self._selected_features else \"no\"\n",
    "            print(f\"{name:<20} {raw:<15.4f} {softmax:<15.4f} {selected}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(\" Stable Interactions:\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        if len(self._stable_interactions) == 0:\n",
    "            print(\"  No stable interactions found.\")\n",
    "        else:\n",
    "            # Sort by stability\n",
    "            sorted_interactions = sorted(\n",
    "                self._stable_interactions,\n",
    "                key=lambda x: self._interaction_stability.get(x, 0),\n",
    "                reverse=True\n",
    "            )\n",
    "            \n",
    "            print(f\"{'Interaction':<30} {'Stability Score':<15}\")\n",
    "            print(\"-\" * 50)\n",
    "            for interaction in sorted_interactions:\n",
    "                name = \" * \".join(sorted(interaction))\n",
    "                stability = self._interaction_stability.get(interaction, 0)\n",
    "                print(f\"{name:<30} {stability:<15.3f}\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"Total stable interactions: {len(self._stable_interactions)}\")\n",
    "        print(f\"Total candidate interactions: {len(self._all_interactions)}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 04_InteractionDiscovery\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Known Interactions\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Known Interactions\")\n",
    "    \n",
    "    # Generate data with known interactions\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    x0 = np.random.uniform(0, 1, n_samples)\n",
    "    x1 = np.random.uniform(0, 1, n_samples)\n",
    "    x2 = np.random.uniform(0, 1, n_samples)\n",
    "    x3 = np.random.randn(n_samples)  # Noise feature\n",
    "    \n",
    "    # True equation: y = 3*x0*x1 + x2^2 + noise\n",
    "    # Interaction: (x0, x1)\n",
    "    y = 3 * x0 * x1 + x2**2 + 0.1 * np.random.randn(n_samples)\n",
    "    \n",
    "    X = np.column_stack([x0, x1, x2, x3])\n",
    "    feature_names = ['x0', 'x1', 'x2', 'x3']\n",
    "    \n",
    "    print(f\"True equation: y = 3*x0*x1 + x2^2\")\n",
    "    print(f\"Expected interaction: (x0, x1)\")\n",
    "    print()\n",
    "    \n",
    "    # Run discovery\n",
    "    discoverer = IRFInteractionDiscoverer(\n",
    "        temperature=0.5,\n",
    "        n_bootstrap=30,  # Reduced for faster testing\n",
    "        stability_threshold=0.4\n",
    "    )\n",
    "    result = discoverer.discover(X, y, feature_names)\n",
    "    \n",
    "    # Print report\n",
    "    discoverer.print_interaction_report()\n",
    "    \n",
    "    # Verification\n",
    "    print(\"\\nVerification:\")\n",
    "    stable_interactions = discoverer.get_stable_interactions()\n",
    "    \n",
    "    x0_x1_found = any(\n",
    "        set(interaction) == {'x0', 'x1'}\n",
    "        for interaction in stable_interactions\n",
    "    )\n",
    "    \n",
    "    if x0_x1_found:\n",
    "        print(\"  [PASS] Correctly identified (x0, x1) interaction\")\n",
    "    else:\n",
    "        print(\"  [WARNING] Did not identify (x0, x1) interaction\")\n",
    "        print(f\"  Found interactions: {stable_interactions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: Softmax Temperature Sensitivity\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: Softmax Temperature Sensitivity\")\n",
    "    \n",
    "    # Use same data as Test 1\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    x0 = np.random.uniform(0, 1, n_samples)\n",
    "    x1 = np.random.uniform(0, 1, n_samples)\n",
    "    x2 = np.random.uniform(0, 1, n_samples)\n",
    "    \n",
    "    y = 3 * x0 * x1 + x2**2 + 0.1 * np.random.randn(n_samples)\n",
    "    X = np.column_stack([x0, x1, x2])\n",
    "    feature_names = ['x0', 'x1', 'x2']\n",
    "    \n",
    "    temperatures = [0.1, 0.5, 1.0, 2.0]\n",
    "    \n",
    "    print(f\"Testing different softmax temperatures:\")\n",
    "    print(f\"{'Temperature':<15} {'x0 weight':<12} {'x1 weight':<12} {'x2 weight':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        discoverer = IRFInteractionDiscoverer(\n",
    "            temperature=temp,\n",
    "            n_bootstrap=10  # Minimal for speed\n",
    "        )\n",
    "        result = discoverer.discover(X, y, feature_names)\n",
    "        \n",
    "        weights = result['softmax_weights']\n",
    "        print(f\"{temp:<15} {weights['x0']:<12.4f} {weights['x1']:<12.4f} {weights['x2']:<12.4f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Note: Lower temperature = more selective (approaches hard threshold)\")\n",
    "    print(\"      Higher temperature = more uniform (all features similar weight)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: Bootstrap Stability Verification\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: Bootstrap Stability Verification\")\n",
    "    \n",
    "    # Strong interaction should have high stability\n",
    "    # Spurious interaction should have low stability\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    x0 = np.random.uniform(0, 1, n_samples)\n",
    "    x1 = np.random.uniform(0, 1, n_samples)\n",
    "    x2 = np.random.uniform(0, 1, n_samples)  # Independent\n",
    "    \n",
    "    # Strong interaction: x0*x1\n",
    "    y = 5 * x0 * x1 + 0.1 * np.random.randn(n_samples)\n",
    "    \n",
    "    X = np.column_stack([x0, x1, x2])\n",
    "    feature_names = ['x0', 'x1', 'x2']\n",
    "    \n",
    "    print(f\"True equation: y = 5*x0*x1\")\n",
    "    print(f\"x2 is independent (no true interaction with x0 or x1)\")\n",
    "    print()\n",
    "    \n",
    "    discoverer = IRFInteractionDiscoverer(\n",
    "        temperature=0.5,\n",
    "        n_bootstrap=50,\n",
    "        stability_threshold=0.3\n",
    "    )\n",
    "    result = discoverer.discover(X, y, feature_names)\n",
    "    \n",
    "    print(f\"Interaction Stability Scores:\")\n",
    "    for interaction, stability in sorted(\n",
    "        result['interaction_stability'].items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:10]:  # Top 10\n",
    "        name = \" * \".join(sorted(interaction))\n",
    "        print(f\"  {name}: {stability:.3f}\")\n",
    "    \n",
    "    # Check x0*x1 has higher stability than x0*x2 or x1*x2\n",
    "    print()\n",
    "    x0_x1_stability = result['interaction_stability'].get(\n",
    "        frozenset(['x0', 'x1']), 0\n",
    "    )\n",
    "    x0_x2_stability = result['interaction_stability'].get(\n",
    "        frozenset(['x0', 'x2']), 0\n",
    "    )\n",
    "    \n",
    "    if x0_x1_stability > x0_x2_stability:\n",
    "        print(\"[PASS] True interaction (x0*x1) has higher stability than spurious (x0*x2)\")\n",
    "    else:\n",
    "        print(\"[WARNING] Stability ordering unexpected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: High-order Interaction Detection\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: High-order Interaction Detection\")\n",
    "    \n",
    "    # Generate data with 3-way interaction\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    x0 = np.random.uniform(0.1, 1, n_samples)\n",
    "    x1 = np.random.uniform(0.1, 1, n_samples)\n",
    "    x2 = np.random.uniform(0.1, 1, n_samples)\n",
    "    x3 = np.random.randn(n_samples)  # Noise\n",
    "    \n",
    "    # True equation: y = 2*x0*x1*x2 (3-way interaction)\n",
    "    y = 2 * x0 * x1 * x2 + 0.05 * np.random.randn(n_samples)\n",
    "    \n",
    "    X = np.column_stack([x0, x1, x2, x3])\n",
    "    feature_names = ['x0', 'x1', 'x2', 'x3']\n",
    "    \n",
    "    print(f\"True equation: y = 2*x0*x1*x2\")\n",
    "    print(f\"Expected: 3-way interaction (x0, x1, x2)\")\n",
    "    print()\n",
    "    \n",
    "    discoverer = IRFInteractionDiscoverer(\n",
    "        temperature=0.5,\n",
    "        n_bootstrap=30,\n",
    "        stability_threshold=0.3,\n",
    "        max_interaction_order=3\n",
    "    )\n",
    "    result = discoverer.discover(X, y, feature_names)\n",
    "    \n",
    "    print(f\"Stable interactions found:\")\n",
    "    for interaction in result['stable_interactions']:\n",
    "        name = \" * \".join(sorted(interaction))\n",
    "        stability = result['interaction_stability'].get(interaction, 0)\n",
    "        print(f\"  {name}: {stability:.3f}\")\n",
    "    \n",
    "    # Check if 3-way interaction is found\n",
    "    three_way_found = any(\n",
    "        len(interaction) == 3 and set(interaction) == {'x0', 'x1', 'x2'}\n",
    "        for interaction in result['stable_interactions']\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    if three_way_found:\n",
    "        print(\"[PASS] 3-way interaction (x0, x1, x2) detected\")\n",
    "    else:\n",
    "        print(\"[INFO] 3-way interaction not in stable set (may appear in pairwise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 04_InteractionDiscovery.ipynb - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: IRFInteractionDiscoverer\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Discover feature interactions using Random Forest with softmax\")\n",
    "print(\"  soft threshold. Uses bootstrap stability to filter genuine interactions.\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  discover(X, y, feature_names)\")\n",
    "print(\"      Discover feature interactions\")\n",
    "print(\"      Returns: dict with stable_interactions, softmax_weights, etc.\")\n",
    "print()\n",
    "print(\"  get_stable_interactions()\")\n",
    "print(\"      Get list of stable interactions as tuples\")\n",
    "print()\n",
    "print(\"  get_interaction_matrix(X)\")\n",
    "print(\"      Compute interaction features from stable interactions\")\n",
    "print()\n",
    "print(\"  print_interaction_report()\")\n",
    "print(\"      Print detailed discovery report\")\n",
    "print()\n",
    "print(\"Key Parameters:\")\n",
    "print(\"  temperature: Softmax temperature (0.5 = balanced)\")\n",
    "print(\"  stability_threshold: Min bootstrap frequency (0.5 = appear in 50%)\")\n",
    "print()\n",
    "print(\"Usage Example:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Create discoverer\n",
    "discoverer = IRFInteractionDiscoverer(\n",
    "    temperature=0.5,\n",
    "    stability_threshold=0.5\n",
    ")\n",
    "\n",
    "# Run discovery\n",
    "result = discoverer.discover(X, y, feature_names)\n",
    "\n",
    "# Get stable interactions\n",
    "interactions = result['stable_interactions']\n",
    "print(f\"Found {len(interactions)} stable interactions\")\n",
    "\n",
    "# Compute interaction features for library\n",
    "X_interactions, names = discoverer.get_interaction_matrix(X)\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 04_InteractionDiscovery.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08_AdaptiveLasso - Physics-SR Framework v4.1\n",
    "\n",
    "## Stage 2.5: Adaptive Lasso with Oracle Property\n",
    "\n",
    "**Author:** Zhengze Zhang  \n",
    "**Affiliation:** Department of Statistics, Columbia University  \n",
    "**Contact:** zz3239@columbia.edu  \n",
    "**Date:** January 2026  \n",
    "**Version:** 4.1 (Structure-Guided Feature Library Enhancement + Computational Optimization)\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Achieve the oracle property for variable selection in symbolic regression.\n",
    "This is a **minor update** module for v4.1.\n",
    "\n",
    "### v4.1 Modifications\n",
    "\n",
    "| Feature | v3.0 | v4.1 |\n",
    "|---------|------|------|\n",
    "| Source tracking | None | selection_analysis in output |\n",
    "| Agreement metric | None | compute_agreement() method |\n",
    "| Parameter names | feature_names | library_names (compatible) |\n",
    "\n",
    "### Oracle Property\n",
    "\n",
    "The oracle property guarantees:\n",
    "1. **Selection consistency:** $P(\\text{support} = \\text{true support}) \\to 1$ as $n \\to \\infty$\n",
    "2. **Asymptotic normality:** $\\sqrt{n}(\\hat{\\xi} - \\xi^*) \\xrightarrow{d} N(0, V)$\n",
    "\n",
    "### Key Innovation\n",
    "\n",
    "Adaptive LASSO uses **data-driven weights**:\n",
    "$$w_j = \\frac{1}{(|\\hat{\\beta}_j^{init}| + \\varepsilon)^\\gamma}$$\n",
    "\n",
    "### Reference\n",
    "\n",
    "- Zou, H. (2006). The adaptive lasso and its oracle properties. *JASA*, 101(476), 1418-1429.\n",
    "- Framework v4.0/v4.1 Section 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Header and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "08_AdaptiveLasso.ipynb - Adaptive Lasso with Oracle Property\n",
    "=============================================================\n",
    "\n",
    "Three-Stage Physics-Informed Symbolic Regression Framework v4.1\n",
    "\n",
    "This module provides:\n",
    "- AdaptiveLassoSelector: Adaptive Lasso with data-driven weights\n",
    "- Oracle property for variable selection consistency\n",
    "- Epsilon-stabilization to prevent weight explosion\n",
    "- Cross-validation for lambda selection\n",
    "\n",
    "v4.1 Key Changes from v3.0:\n",
    "- selection_analysis in output (source attribution)\n",
    "- compute_agreement() method for STLSQ comparison\n",
    "- library_names parameter (compatible with feature_names)\n",
    "\n",
    "Author: Zhengze Zhang\n",
    "Affiliation: Department of Statistics, Columbia University\n",
    "Contact: zz3239@columbia.edu\n",
    "\"\"\"\n",
    "\n",
    "# Import core module\n",
    "%run 00_Core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for Adaptive Lasso\n",
    "from sklearn.linear_model import Ridge, LassoCV, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "print(\"08_AdaptiveLasso v4.1: Additional imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ADAPTIVE LASSO SELECTOR CLASS (v4.1 Minor Update)\n",
    "# ==============================================================================\n",
    "\n",
    "class AdaptiveLassoSelector:\n",
    "    \"\"\"\n",
    "    Adaptive Lasso with Oracle Property (v4.1 Minor Update).\n",
    "    \n",
    "    Achieves selection consistency and asymptotic normality.\n",
    "    Uses epsilon-stabilization to handle zero initial estimates.\n",
    "    \n",
    "    v4.1 Enhancements:\n",
    "    - selection_analysis in output (source attribution)\n",
    "    - compute_agreement() method for STLSQ comparison\n",
    "    - Accepts library_names with source tags\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    gamma : float\n",
    "        Weight exponent (default: 1.0). Higher gamma = stronger penalty\n",
    "        on small initial coefficients.\n",
    "    eps : float\n",
    "        Stabilization constant to prevent weight explosion (default: 1e-6)\n",
    "    cv_folds : int\n",
    "        Number of folds for cross-validation (default: 5)\n",
    "    initial_method : str\n",
    "        Method for initial estimate: 'ridge' or 'ols' (default: 'ridge')\n",
    "    ridge_alpha : float\n",
    "        Regularization for initial Ridge estimate (default: 0.1)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    fit(feature_library, y, library_names) -> Dict\n",
    "        Fit Adaptive Lasso model\n",
    "    compute_agreement(support_stlsq, support_alasso) -> float\n",
    "        Compute Jaccard similarity between supports (v4.1)\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    Zou, H. (2006). JASA, 101(476), 1418-1429.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> selector = AdaptiveLassoSelector(gamma=1.0)\n",
    "    >>> result = selector.fit(Phi, y, library_names=names)\n",
    "    >>> print(f\"Selection analysis: {result['selection_analysis']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        gamma: float = DEFAULT_ALASSO_GAMMA,\n",
    "        eps: float = DEFAULT_ALASSO_EPS,\n",
    "        cv_folds: int = DEFAULT_CV_FOLDS,\n",
    "        initial_method: str = 'ridge',\n",
    "        ridge_alpha: float = 0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize AdaptiveLassoSelector.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        gamma : float\n",
    "            Exponent for adaptive weights. gamma=1 is standard,\n",
    "            gamma=2 provides stronger adaptation.\n",
    "            Default: 1.0\n",
    "        eps : float\n",
    "            Stabilization constant to prevent division by zero.\n",
    "            Default: 1e-6\n",
    "        cv_folds : int\n",
    "            Number of cross-validation folds for lambda selection.\n",
    "            Default: 5\n",
    "        initial_method : str\n",
    "            'ridge' or 'ols' for initial estimate.\n",
    "            Default: 'ridge' (more stable)\n",
    "        ridge_alpha : float\n",
    "            Ridge regularization parameter for initial estimate.\n",
    "            Default: 0.1\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.cv_folds = cv_folds\n",
    "        self.initial_method = initial_method\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        \n",
    "        # Internal state\n",
    "        self._coefficients = None\n",
    "        self._support = None\n",
    "        self._library_names = None\n",
    "        self._n_features = None\n",
    "        self._initial_estimate = None\n",
    "        self._adaptive_weights = None\n",
    "        self._optimal_lambda = None\n",
    "        self._fit_complete = False\n",
    "        self._r2_score = None\n",
    "        self._mse = None\n",
    "        self._selection_analysis = None\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        feature_library: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        library_names: List[str] = None,\n",
    "        feature_names: List[str] = None  # Backward compatibility alias\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fit Adaptive Lasso model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_library : np.ndarray\n",
    "            Feature library matrix\n",
    "        y : np.ndarray\n",
    "            Target vector\n",
    "        library_names : List[str], optional\n",
    "            Feature names with source tags for attribution\n",
    "        feature_names : List[str], optional\n",
    "            Backward compatibility alias for library_names\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict\n",
    "            - coefficients: Adaptive Lasso coefficients\n",
    "            - support: Boolean mask of selected terms\n",
    "            - equation: Formatted equation string\n",
    "            - lambda_optimal: Selected regularization parameter\n",
    "            - initial_coef: Initial estimate used for weights\n",
    "            - selection_analysis: Source attribution (v4.1)\n",
    "            - r2_score: R-squared on training data\n",
    "            - mse: Mean squared error\n",
    "        \"\"\"\n",
    "        n_samples, n_features = feature_library.shape\n",
    "        self._n_features = n_features\n",
    "        \n",
    "        # Handle backward compatibility\n",
    "        names = library_names or feature_names\n",
    "        if names is None:\n",
    "            self._library_names = [f'f{i}' for i in range(n_features)]\n",
    "        else:\n",
    "            self._library_names = list(names)\n",
    "        \n",
    "        # Step 1: Compute initial estimate\n",
    "        self._initial_estimate = self._compute_initial_estimate(\n",
    "            feature_library, y\n",
    "        )\n",
    "        \n",
    "        # Step 2: Compute adaptive weights\n",
    "        self._adaptive_weights = self._compute_adaptive_weights(\n",
    "            self._initial_estimate\n",
    "        )\n",
    "        \n",
    "        # Step 3: Fit weighted Lasso\n",
    "        self._coefficients, self._optimal_lambda = self._fit_weighted_lasso(\n",
    "            feature_library, y, self._adaptive_weights\n",
    "        )\n",
    "        \n",
    "        # Determine support\n",
    "        self._support = np.abs(self._coefficients) > 1e-10\n",
    "        \n",
    "        # Compute metrics\n",
    "        y_pred = feature_library @ self._coefficients\n",
    "        self._mse = np.mean((y - y_pred)**2)\n",
    "        ss_tot = np.sum((y - np.mean(y))**2)\n",
    "        ss_res = np.sum((y - y_pred)**2)\n",
    "        self._r2_score = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "        \n",
    "        # Analyze selection sources (v4.1)\n",
    "        self._selection_analysis = self._analyze_selection_sources(\n",
    "            self._support, self._library_names\n",
    "        )\n",
    "        \n",
    "        self._fit_complete = True\n",
    "        \n",
    "        return {\n",
    "            'coefficients': self._coefficients,\n",
    "            'support': self._support,\n",
    "            'equation': self.get_equation(),\n",
    "            'n_active_terms': int(np.sum(self._support)),\n",
    "            'lambda_optimal': self._optimal_lambda,\n",
    "            'optimal_lambda': self._optimal_lambda,  # Alias\n",
    "            'initial_coef': self._initial_estimate,\n",
    "            'initial_estimate': self._initial_estimate,  # Alias\n",
    "            'adaptive_weights': self._adaptive_weights,\n",
    "            'selection_analysis': self._selection_analysis,  # v4.1\n",
    "            'r2_score': self._r2_score,\n",
    "            'r_squared': self._r2_score,  # Alias\n",
    "            'mse': self._mse,\n",
    "            'gamma': self.gamma,\n",
    "            'eps': self.eps\n",
    "        }\n",
    "    \n",
    "    def _analyze_selection_sources(\n",
    "        self,\n",
    "        support: np.ndarray,\n",
    "        library_names: List[str]\n",
    "    ) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Analyze where selected terms originated (v4.1).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        support : np.ndarray\n",
    "            Boolean mask of selected terms\n",
    "        library_names : List[str]\n",
    "            Feature names with source tags\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, int]\n",
    "            Source attribution counts\n",
    "        \"\"\"\n",
    "        sources = {\n",
    "            'from_pysr': 0,\n",
    "            'from_variant': 0,\n",
    "            'from_poly': 0,\n",
    "            'from_op': 0,\n",
    "            'from_unknown': 0,\n",
    "            'total_selected': 0\n",
    "        }\n",
    "        \n",
    "        selected_indices = np.where(support)[0]\n",
    "        sources['total_selected'] = len(selected_indices)\n",
    "        \n",
    "        for idx in selected_indices:\n",
    "            if idx >= len(library_names):\n",
    "                sources['from_unknown'] += 1\n",
    "                continue\n",
    "                \n",
    "            name = library_names[idx]\n",
    "            if name.startswith('[PySR]'):\n",
    "                sources['from_pysr'] += 1\n",
    "            elif name.startswith('[Var]'):\n",
    "                sources['from_variant'] += 1\n",
    "            elif name.startswith('[Poly]'):\n",
    "                sources['from_poly'] += 1\n",
    "            elif name.startswith('[Op]'):\n",
    "                sources['from_op'] += 1\n",
    "            else:\n",
    "                sources['from_unknown'] += 1\n",
    "        \n",
    "        return sources\n",
    "    \n",
    "    def compute_agreement(\n",
    "        self,\n",
    "        support_stlsq: np.ndarray,\n",
    "        support_alasso: np.ndarray = None\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Compute agreement score between STLSQ and Adaptive Lasso (v4.1).\n",
    "        \n",
    "        Uses Jaccard similarity: |intersection| / |union|\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        support_stlsq : np.ndarray\n",
    "            Boolean support mask from E-WSINDy STLSQ\n",
    "        support_alasso : np.ndarray, optional\n",
    "            Boolean support mask from Adaptive Lasso.\n",
    "            If None, uses self._support.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Jaccard similarity in [0, 1]. 1.0 = perfect agreement.\n",
    "        \"\"\"\n",
    "        if support_alasso is None:\n",
    "            if self._support is None:\n",
    "                raise RuntimeError(\"Must call fit() first or provide support_alasso\")\n",
    "            support_alasso = self._support\n",
    "        \n",
    "        # Ensure same length\n",
    "        min_len = min(len(support_stlsq), len(support_alasso))\n",
    "        s1 = support_stlsq[:min_len]\n",
    "        s2 = support_alasso[:min_len]\n",
    "        \n",
    "        intersection = np.sum(s1 & s2)\n",
    "        union = np.sum(s1 | s2)\n",
    "        \n",
    "        return intersection / union if union > 0 else 1.0\n",
    "    \n",
    "    def _compute_initial_estimate(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute initial coefficient estimate.\n",
    "        \n",
    "        Uses Ridge regression for stability.\n",
    "        \"\"\"\n",
    "        if self.initial_method == 'ridge':\n",
    "            ridge = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "            ridge.fit(Phi, y)\n",
    "            return ridge.coef_\n",
    "        else:  # OLS\n",
    "            try:\n",
    "                beta, _, _, _ = np.linalg.lstsq(Phi, y, rcond=None)\n",
    "                return beta\n",
    "            except np.linalg.LinAlgError:\n",
    "                ridge = Ridge(alpha=0.1, fit_intercept=False)\n",
    "                ridge.fit(Phi, y)\n",
    "                return ridge.coef_\n",
    "    \n",
    "    def _compute_adaptive_weights(\n",
    "        self,\n",
    "        beta_init: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute adaptive weights with epsilon stabilization.\n",
    "        \n",
    "        w_j = 1 / (|beta_init[j]| + eps)^gamma\n",
    "        \"\"\"\n",
    "        return 1.0 / (np.abs(beta_init) + self.eps) ** self.gamma\n",
    "    \n",
    "    def _fit_weighted_lasso(\n",
    "        self,\n",
    "        Phi: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        weights: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Fit weighted Lasso via variable transformation.\n",
    "        \"\"\"\n",
    "        sqrt_weights = np.sqrt(weights)\n",
    "        Phi_weighted = Phi / sqrt_weights\n",
    "        \n",
    "        lasso_cv = LassoCV(\n",
    "            cv=self.cv_folds,\n",
    "            fit_intercept=False,\n",
    "            max_iter=10000,\n",
    "            tol=1e-6\n",
    "        )\n",
    "        lasso_cv.fit(Phi_weighted, y)\n",
    "        \n",
    "        beta_weighted = lasso_cv.coef_\n",
    "        beta = beta_weighted / sqrt_weights\n",
    "        \n",
    "        return beta, lasso_cv.alpha_\n",
    "    \n",
    "    def get_equation(self) -> str:\n",
    "        \"\"\"\n",
    "        Get string representation of discovered equation.\n",
    "        \"\"\"\n",
    "        if self._coefficients is None:\n",
    "            return \"\"\n",
    "        \n",
    "        terms = []\n",
    "        for i, (coef, active) in enumerate(zip(self._coefficients, self._support)):\n",
    "            if active:\n",
    "                name = self._library_names[i]\n",
    "                if abs(coef) > 0.001:\n",
    "                    terms.append(f\"{coef:.3f} * {name}\")\n",
    "        \n",
    "        if len(terms) == 0:\n",
    "            return \"0\"\n",
    "        \n",
    "        return \" + \".join(terms)\n",
    "    \n",
    "    def get_active_terms(self) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get list of active terms with coefficients.\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            raise RuntimeError(\"Must call fit() first\")\n",
    "        \n",
    "        active = []\n",
    "        for i, (coef, name) in enumerate(zip(self._coefficients, self._library_names)):\n",
    "            if self._support[i]:\n",
    "                active.append((name, float(coef)))\n",
    "        \n",
    "        return active\n",
    "    \n",
    "    def predict(self, Phi_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict using fitted model.\n",
    "        \"\"\"\n",
    "        if self._coefficients is None:\n",
    "            raise RuntimeError(\"Must call fit() before predict()\")\n",
    "        return Phi_new @ self._coefficients\n",
    "    \n",
    "    def print_alasso_report(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed Adaptive Lasso report in v4.1 format.\n",
    "        \"\"\"\n",
    "        if not self._fit_complete:\n",
    "            print(\"Fit not yet performed. Call fit() first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"=== Adaptive Lasso Results (v4.1) ===\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  Gamma: {self.gamma}\")\n",
    "        print(f\"  Epsilon: {self.eps}\")\n",
    "        print(f\"  CV folds: {self.cv_folds}\")\n",
    "        print(f\"  Initial method: {self.initial_method}\")\n",
    "        print(f\"  Optimal lambda: {self._optimal_lambda:.6f}\")\n",
    "        print()\n",
    "        print(f\"Selected terms: {np.sum(self._support)}\")\n",
    "        print()\n",
    "        \n",
    "        # Print active terms with source tags\n",
    "        for name, coef in self.get_active_terms():\n",
    "            print(f\"  {coef:8.3f} * {name}\")\n",
    "        print()\n",
    "        \n",
    "        # Print selection analysis (v4.1)\n",
    "        print(\"Selection Analysis:\")\n",
    "        print(f\"  from_pysr: {self._selection_analysis['from_pysr']}\")\n",
    "        print(f\"  from_variant: {self._selection_analysis['from_variant']}\")\n",
    "        print(f\"  from_poly: {self._selection_analysis['from_poly']}\")\n",
    "        print(f\"  from_op: {self._selection_analysis['from_op']}\")\n",
    "        print()\n",
    "        \n",
    "        print(f\"R-squared: {self._r2_score:.4f}\")\n",
    "        print(f\"MSE: {self._mse:.6f}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "print(\"AdaptiveLassoSelector class v4.1 defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Internal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST CONTROL FLAG\n",
    "# ==============================================================================\n",
    "\n",
    "_RUN_TESTS = False  # Set to True to run internal tests\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\" RUNNING INTERNAL TESTS FOR 08_AdaptiveLasso v4.1\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 1: Basic Adaptive Lasso with Source Attribution\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 1: Basic Adaptive Lasso with Source Attribution\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    z = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 0.5*x**2 + np.sin(z) + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    # Simulated augmented library with source tags\n",
    "    Phi = np.column_stack([\n",
    "        x**2,\n",
    "        np.sin(z),\n",
    "        np.ones(n_samples),\n",
    "        x,\n",
    "        z,\n",
    "        np.cos(x)\n",
    "    ])\n",
    "    \n",
    "    library_names = [\n",
    "        '[PySR] x**2',\n",
    "        '[PySR] sin(z)',\n",
    "        '[Poly] 1',\n",
    "        '[Poly] x',\n",
    "        '[Poly] z',\n",
    "        '[Op] cos(x)'\n",
    "    ]\n",
    "    \n",
    "    selector = AdaptiveLassoSelector(gamma=1.0)\n",
    "    result = selector.fit(Phi, y, library_names=library_names)\n",
    "    \n",
    "    print(f\"True: y = 0.5*x^2 + sin(z)\")\n",
    "    print()\n",
    "    print(\"Selected terms:\")\n",
    "    for name, coef in selector.get_active_terms():\n",
    "        print(f\"  {coef:8.3f} * {name}\")\n",
    "    print()\n",
    "    print(f\"Selection Analysis: {result['selection_analysis']}\")\n",
    "    print(f\"R-squared: {result['r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 2: compute_agreement Method\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 2: compute_agreement Method\")\n",
    "    \n",
    "    # Test case 1: Perfect agreement\n",
    "    support_stlsq = np.array([True, True, False, False])\n",
    "    support_alasso = np.array([True, True, False, False])\n",
    "    \n",
    "    selector = AdaptiveLassoSelector()\n",
    "    agreement = selector.compute_agreement(support_stlsq, support_alasso)\n",
    "    print(f\"Case 1 - Perfect match: {agreement:.4f}\")\n",
    "    \n",
    "    # Test case 2: Partial agreement\n",
    "    support_stlsq = np.array([True, True, False, False])\n",
    "    support_alasso = np.array([True, False, True, False])\n",
    "    \n",
    "    agreement = selector.compute_agreement(support_stlsq, support_alasso)\n",
    "    print(f\"Case 2 - Partial overlap: {agreement:.4f}\")\n",
    "    \n",
    "    # Test case 3: No agreement\n",
    "    support_stlsq = np.array([True, True, False, False])\n",
    "    support_alasso = np.array([False, False, True, True])\n",
    "    \n",
    "    agreement = selector.compute_agreement(support_stlsq, support_alasso)\n",
    "    print(f\"Case 3 - No overlap: {agreement:.4f}\")\n",
    "    \n",
    "    # Expected: 1.0, 0.333, 0.0\n",
    "    print()\n",
    "    print(\"[INFO] Jaccard similarity: |intersection| / |union|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 3: Oracle Property Verification\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 3: Oracle Property Verification\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 300\n",
    "    \n",
    "    # Sparse ground truth: 3 of 20 features active\n",
    "    n_features = 20\n",
    "    true_support = np.zeros(n_features, dtype=bool)\n",
    "    true_support[:3] = True\n",
    "    true_coefs = np.zeros(n_features)\n",
    "    true_coefs[:3] = [2.0, 1.5, -1.0]\n",
    "    \n",
    "    # Generate data\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = X @ true_coefs + 0.1*np.random.randn(n_samples)\n",
    "    \n",
    "    library_names = [f'[Poly] f{i}' for i in range(n_features)]\n",
    "    \n",
    "    selector = AdaptiveLassoSelector(gamma=1.0)\n",
    "    result = selector.fit(X, y, library_names=library_names)\n",
    "    \n",
    "    recovered_support = result['support']\n",
    "    \n",
    "    # Compute support recovery accuracy\n",
    "    correct = np.sum(recovered_support == true_support)\n",
    "    accuracy = correct / n_features * 100\n",
    "    \n",
    "    print(f\"True active features: {np.where(true_support)[0]}\")\n",
    "    print(f\"Recovered active: {np.where(recovered_support)[0]}\")\n",
    "    print(f\"Support recovery accuracy: {accuracy:.1f}%\")\n",
    "    print()\n",
    "    \n",
    "    if accuracy > 90:\n",
    "        print(\"[PASS] Oracle property - support recovery > 90%\")\n",
    "    else:\n",
    "        print(f\"[INFO] Support recovery: {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 4: Agreement with Simulated STLSQ\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 4: Agreement with Simulated STLSQ\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    z = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 2*x + 0.5*x**2 + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([np.ones(n_samples), x, x**2, x**3, z, z**2])\n",
    "    library_names = ['[Poly] 1', '[Poly] x', '[Poly] x^2', '[Poly] x^3', '[Poly] z', '[Poly] z^2']\n",
    "    \n",
    "    # Fit Adaptive Lasso\n",
    "    selector = AdaptiveLassoSelector(gamma=1.0)\n",
    "    result = selector.fit(Phi, y, library_names=library_names)\n",
    "    \n",
    "    # Simulate STLSQ support (typically agrees well)\n",
    "    support_stlsq = np.array([False, True, True, False, False, False])\n",
    "    \n",
    "    agreement = selector.compute_agreement(support_stlsq)\n",
    "    \n",
    "    print(f\"STLSQ support: {np.where(support_stlsq)[0]}\")\n",
    "    print(f\"ALasso support: {np.where(result['support'])[0]}\")\n",
    "    print(f\"Agreement score: {agreement:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    if agreement > 0.8:\n",
    "        print(\"[PASS] Agreement with STLSQ > 0.8\")\n",
    "    else:\n",
    "        print(f\"[INFO] Agreement: {agreement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TEST 5: Full Report Output\n",
    "# ==============================================================================\n",
    "\n",
    "if _RUN_TESTS:\n",
    "    print()\n",
    "    print_section_header(\"Test 5: Full Report Output\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    \n",
    "    x = np.random.uniform(0.1, 2, n_samples)\n",
    "    z = np.random.uniform(0.1, 2, n_samples)\n",
    "    y = 0.5*x**2 + np.sin(z) + 0.01*np.random.randn(n_samples)\n",
    "    \n",
    "    Phi = np.column_stack([x**2, np.sin(z), np.ones(n_samples), x, z])\n",
    "    library_names = ['[PySR] x**2', '[PySR] sin(z)', '[Poly] 1', '[Poly] x', '[Poly] z']\n",
    "    \n",
    "    selector = AdaptiveLassoSelector(gamma=1.0)\n",
    "    result = selector.fit(Phi, y, library_names=library_names)\n",
    "    \n",
    "    # Print full report\n",
    "    selector.print_alasso_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Module Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODULE SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" 08_AdaptiveLasso.ipynb v4.1 - Module Summary\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CLASS: AdaptiveLassoSelector (v4.1 Minor Update)\")\n",
    "print(\"-\" * 70)\n",
    "print()\n",
    "print(\"Purpose:\")\n",
    "print(\"  Adaptive Lasso with oracle property for variable selection.\")\n",
    "print(\"  Achieves selection consistency and asymptotic normality.\")\n",
    "print()\n",
    "print(\"v4.1 Modifications:\")\n",
    "print(\"  - selection_analysis in output (source attribution)\")\n",
    "print(\"  - compute_agreement() method for STLSQ comparison\")\n",
    "print(\"  - library_names parameter (backward compatible)\")\n",
    "print()\n",
    "print(\"Main Methods:\")\n",
    "print(\"  fit(feature_library, y, library_names=None) -> Dict\")\n",
    "print(\"      Returns: coefficients, support, selection_analysis, r2_score, ...\")\n",
    "print()\n",
    "print(\"  compute_agreement(support_stlsq, support_alasso=None) -> float\")\n",
    "print(\"      Returns: Jaccard similarity in [0, 1]\")\n",
    "print()\n",
    "print(\"  get_equation() -> str\")\n",
    "print(\"      Get string representation with source tags\")\n",
    "print()\n",
    "print(\"  print_alasso_report()\")\n",
    "print(\"      Print detailed results with selection analysis\")\n",
    "print()\n",
    "print(\"Key Parameters:\")\n",
    "print(\"  gamma: Weight exponent (1.0 = standard, 2.0 = stronger)\")\n",
    "print(\"  eps: Stabilization constant (default: 1e-6)\")\n",
    "print()\n",
    "print(\"Usage Example (with augmented library):\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "# Build augmented library (from 05_FeatureLibrary)\n",
    "builder = AugmentedLibraryBuilder(max_poly_degree=3)\n",
    "Phi, names, info = builder.build(X, feature_names, ...)\n",
    "\n",
    "# Fit Adaptive Lasso with source attribution\n",
    "selector = AdaptiveLassoSelector(gamma=1.0)\n",
    "result = selector.fit(Phi, y, library_names=names)\n",
    "\n",
    "# Check source attribution\n",
    "print(f\"Selection Analysis: {result['selection_analysis']}\")\n",
    "\n",
    "# Compare with STLSQ\n",
    "agreement = selector.compute_agreement(stlsq_result['support'])\n",
    "print(f\"Agreement with STLSQ: {agreement:.4f}\")\n",
    "\"\"\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Module loaded successfully. Import via: %run 08_AdaptiveLasso.ipynb\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
